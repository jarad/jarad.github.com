\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\title{M8S2 - Regression In Practice}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=7, fig.height=5, 
               size='small', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=FALSE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library("tidyverse")
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@



\begin{document}


\begin{frame}
\titlepage
\end{frame}


\begin{frame}
\frametitle{Outline}

\begin{enumerate}
\item Assumptions
  \begin{itemize}
  \item Independence
  \item Normality
  \item Constant variance
  \item Linearity \pause
  \end{itemize}
\item Regression analysis steps
  \begin{enumerate}
  \item Determine scientific questions, i.e. why are you collecting data
  \item Collect data (at least two variables per individual)
  \item Identify explanatory and response variables
  \item Plot the data
  \item Run regression
  \item Assess regression assumptions
  \item Interpret regression output
  \end{enumerate}
\end{enumerate}


\end{frame}





\section{Assumptions}
\begin{frame}
\frametitle{Regression assumptions}

Regression model
\[ 
y_i = \beta_0 + \beta_1 x_i +\epsilon_i 
\qquad 
\epsilon_i \stackrel{iid}{\sim} N(0,\sigma^2)
\]
\pause
Regression assumptions are
\begin{itemize}
\item Errors are \alert{independent}
\item Errors are \alert{normally distributed}
\item Errors are identically distributed with a mean of 0 and \alert{constant variance} of $\sigma^2$
\item \alert{Linear} relationship between explanatory variable and mean of the response
\end{itemize}
\end{frame}


\subsection{Linearity}
\begin{frame}
\frametitle{Assessing linearity assumption}

Look for non-linearity in 
\begin{itemize}
\item response vs explanatory plot
\item residuals vs explanatory plot
\item residuals vs predicted value plot
\end{itemize}

\pause

<<fig.height=4>>=
n <- 30
x <- runif(n,0,8)
y <- x^2 + rnorm(n)
m <- lm(y~x)
residuals <- residuals(m)
predicted <- fitted(m)
response <- y
explanatory <- x

opar <- par(mfrow=c(1,3), mar=c(5,4,0,0)+0.1)
plot(explanatory, response, pch=19); abline(m, col='red')
plot(explanatory, residuals, pch=19); abline(h=0)
plot(predicted, residuals, pch=19); abline(h=0)
par(opar)
@
\end{frame}

\subsection{Constant variance}
\begin{frame}
\frametitle{Assessing constant variance assumption}

Look for a trumpet horn pattern 
\begin{itemize}
\item residuals vs explanatory plot
\item residuals vs predicted value plot
\end{itemize}

\pause

<<fig.height=4>>=
n <- 30
x <- runif(n,0,8)
y <- x + rnorm(n, 0, x^2)
m <- lm(y~x)
residuals <- residuals(m)
predicted <- fitted(m)
response <- y
explanatory <- x

opar <- par(mfrow=c(1,3), mar=c(5,4,0,0)+0.1)
plot(explanatory, response, pch=19); abline(m, col='red')
plot(explanatory, residuals, pch=19); abline(h=0)
plot(predicted, residuals, pch=19); abline(h=0)
par(opar)
@

\end{frame}


\subsection{Normality}
\begin{frame}
\frametitle{Assessing normality assumption}

Deviations from a straight line in a normal quantile plot (qq-plot)

\pause

<<fig.height=4>>=
n <- 30
x <- runif(n,0,8)
y <- x + rt(n, 1)
m <- lm(y~x)
residuals <- residuals(m)
predicted <- fitted(m)
response <- y
explanatory <- x


opar <- par(mfrow=c(1,2))
plot(explanatory, response, pch=19); abline(m, col='red')
qqnorm(residuals, pch=19); qqline(residuals)
par(opar)
@

\end{frame}



\subsection{Independence}
\begin{frame}
\frametitle{Assessing the independence assumption}

The main ways that the independence assumption is violated are 
\pause
\begin{itemize}[<+->]
\item temporal effects
\item spatial effects
\item clustering effects
\end{itemize}

\pause

Each of these requires a relatively sophisticated plot or analysis 
\pause 
and thus, for this course, we will assess the independence assumption using 
the context of the problem.
\pause
If one of the above effects are present in the problem, then there \alert{may}
be a violation of the independence assumption.

\end{frame}



\begin{frame}
\frametitle{Influential individuals}

In addition to violation of model assumptions, 
we should be on the lookout for individuals who are influential.

\vspace{0.1in} \pause

Recall
\begin{itemize}
\item if the explanatory variable value is far from the other explanatory variable
values, then the individual has high \alert{leverage}\pause, and
\item if removing an observation changes the intercept or slope a lot, then 
the individual has high \alert{influence}.
\end{itemize}

\end{frame}


\begin{frame}
\frametitle{Regression analysis procedure}
\begin{enumerate}
\item Determine hypotheses, i.e. why are you collecting data
\item Collect data (at least two variables per individual)
\item Identify explanatory and response variables
\item Plot the data
\item Run regression
\item Assess regression assumptions
\item Interpret regression output
\end{enumerate}
\end{frame}




\section{Gas mileage}
\begin{frame}
\frametitle{Gas mileage}

To understand changes in our 2011 Toyota Sienna, 
we record the miles driven and amount of fuel consumed since our last fill-up.
\pause
From this we can calculate the miles per gallon (mpg) since out last fill-up. 
\pause
Understanding changes in mpg through time may give us an indication of 
problems with our car.

\pause

In the following analysis, 
we use 
\begin{itemize}
\item miles per gallon (mpg) as our response variable
\item days since purchase (day) as our explanatory variable
\end{itemize}

\end{frame}


\subsection{Data sheet}
\begin{frame}
\frametitle{Example data sheet}
\includegraphics{data/20180608}
\end{frame}


\subsection{Plot}
\begin{frame}
\frametitle{Plot}
\setkeys{Gin}{width=0.7\textwidth}
\begin{center}
\includegraphics{data/gas_plot}
\end{center}
\end{frame}


\subsection{Regression output}
\begin{frame}
\frametitle{Regression}
\setkeys{Gin}{width=0.4\textwidth}
\begin{center}
\includegraphics{data/gas_regression}
\end{center}
\end{frame}


\subsection{Residual plots}
\begin{frame}
\frametitle{Residuals}
\setkeys{Gin}{width=0.5\textwidth}
\begin{center}
\includegraphics{data/gas_residuals}
\end{center}
\end{frame}


\subsection{Normal quantile plot}
\begin{frame}
\frametitle{Normal quantile plot}
\begin{center}
\includegraphics{data/gas_qqplot}
\end{center}
\end{frame}


\subsection{Regression output}
\begin{frame}
\frametitle{Regression}
\setkeys{Gin}{width=\textwidth}
\begin{center}
\includegraphics{data/gas_regressionFit}
\end{center}
\end{frame}



\subsection{Interpretation}
\begin{frame}
\frametitle{Interpretation}

\begin{itemize}
\item When the car was purchased (day 0), the predicted miles per gallons was
18.6 mpg. 
\item Each additional day that passes, the miles per gallons increases by 
0.0008 mpg on average. Over the course of a year, this is an increase of 
0.29 mpg on average.
\item Only 2.9\% of the variability in miles per gallon is explained by day.
\end{itemize}
\end{frame}


\subsection{Confidence intervals}
\begin{frame}
\frametitle{Confidence intervals}

To construct a $100(1-\alpha)$\% confidence interval, we use the generic 
formula
\[
\mbox{estimate } \pm t_{n-2,\alpha/2} \cdot \mbox{ SE(estimate)}
\]
\pause
Suppose we are interested in 90\% confidence intervals for the intercept and 
slope. 
\pause
We have 
\[ 
t_{275,0.05} < t_{100,0.05} = 1.66.
\]
\pause
Thus, a 90\% confidence interval for the intercept is 
\[ 
18.567468 \pm 1.66 \times 0.373457 = (17.9,19.2)
\]
\pause
and a 90\% confidence interval for the slope is 
\[
0.0008083 \pm 1.66 \times 0.00028 = (0.0003,0.0013).
\]
\end{frame}


\begin{frame}
\frametitle{Confidence interval interpretation}

\scriptsize

\begin{itemize}[<+->]
\item Intercept:
  \begin{itemize} \scriptsize
  \item We are 90\% confident the true mean miles per gallon on the day of 
  purchase (day 0) was between 17.9 and 19.2 miles per gallon.
  \item If we repeat this confidence interval construction procedure, 
  on average 90\% of the intervals constructed will contain the true value.
  \item If we construct 100 intervals, on average 90 of the intervals will 
  contain the true value.
  \end{itemize}
\item Slope:
  \begin{itemize} \scriptsize
  \item We are 90\% confident the average daily increase in miles per gallon 
  is between 0.0003 and 0.0013 miles per gallon.
  \item If we repeat this confidence interval construction procedure, 
  on average 90\% of the intervals constructed will contain the true value.
  \item If we construct 100 intervals, on average 90 of the intervals will 
  contain the true value.
  \end{itemize}
\end{itemize}

\pause

Bayesian interpretation of credible intervals:
\begin{itemize}[<+->]
\item Intercept: We believe with 90\% probability that the true mean miles per gallon on 
the day of purchase (day 0) was between 17.9 and 19.2 miles per gallon.
\item Slope: We believe with 90\% probability that the average daily increase in miles
per gallon is between 0.0003 and 0.0013 miles per gallon.
\end{itemize}


\end{frame}



\subsection{Hypothesis tests}
\begin{frame}
\frametitle{Hypothesis tests}
JMP reports two \pvalue{}s:
\begin{center}
\includegraphics{data/gas_estimates}
\end{center}

\pause

These correspond to the hypothesis tests
\[ \begin{array}{ll}
\mbox{Intercept} & H_0: \beta_0 = 0 \quad \mbox{ vs }\quad H_a: \beta_0 \ne 0 \\
\mbox{day} & H_0: \beta_1 = 0 \quad \mbox{ vs }\quad H_a: \beta_1 \ne 0 
\end{array} \]
\pause
To obtain the one-sided \pvalue{}s, 
\pause
you need to divided the \pvalue{} in half 
\pause 
and, if the alternative is \alert{not} consistent with the estimate, 
\pause 
subtract from 1.
\pause
Example one-sided \pvalue{}s are
\[ \begin{array}{ll}
\mbox{Hypotheses} & \mbox{\pvalue} \pause \\
H_0: \beta_0 = 0  \mbox{ vs } H_a: \beta_0 > 0 & \pause < 0.0001 \pause \\
H_0: \beta_1 = 0  \mbox{ vs } H_a: \beta_1 < 0 & \pause 0.9979
\end{array} \]
\end{frame}



\begin{frame}
\frametitle{Hypothesis test decision and conclusion}

At significance level $\alpha=0.1$: 
\pause
\begin{itemize}[<+->]
\item Intercept: $H_0: \beta_0 = 0 \mbox{ vs } H_a: \beta_0 > 0$
  \begin{itemize}
  \item Decision: Since $p<0.0001<0.1$, we reject the null hypothesis.
  \item Conclusion: There is statistically significant evidence that the mean 
  miles per gallon on day of purchase (day 0) is greater than 0.
  \end{itemize}
\item Slope: $H_0: \beta_1 = 0 \mbox{ vs } H_a: \beta_1 < 0$
  \begin{itemize}
  \item Decision: Since $p=0.9979>0.1$, we fail to reject the null hypothesis.
  \item Conclusion: There is insufficient evidence that the average daily change
  in miles per gallon is less than 0.
  \end{itemize}
\end{itemize}

\end{frame}



\end{document}
