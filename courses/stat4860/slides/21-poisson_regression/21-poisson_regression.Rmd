---
layout: page
title: "Poisson regression"
author: "Jarad Niemi"
date: "`r Sys.Date()`"
header-includes:
- \usepackage{blkarray}
- \usepackage{amsmath}
output: 
  html_document:
      toc: true
      toc_float: true
---

```{r setup, include=FALSE, purl=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

[R code](21-poisson_regression.R)

```{r}
library("tidyverse"); theme_set(theme_bw())
library("Sleuth3")
library("ggResidpanel")
library("emmeans")
```

# Poisson Regression

## Model

Let $Y_i$ be a Poisson response variable.
Assume
\[ 
Y_i \stackrel{ind}{\sim} Po(\lambda_i), \quad
\eta_i = \log\left(\lambda_i \right) = 
\beta_0 + \beta_1X_{i,1} + \cdots + \beta_{p-1} X_{i,p-1}
\]

If we invert, then
\[
E[Y_i] = e^{\beta_0 + \beta_1X_{i,1} + \cdots + \beta_{p-1} X_{i,p-1}}.
\]

### glm()

To fit a Poisson regression model in R, 
you use the `glm()` function with argument `family = "poisson"`.

```{r}
summary(ex1509)
```
```{r}
ggplot(ex1509, aes(x = Year, y = Sunspots)) + 
  geom_point() + 
  geom_smooth() # smoother, not lm
```

Poisson regression is closer to analysis using the logarithm of the response.
But when using count data, some of the counts may be zero. 
A common approach is to add 1 to the count, 
but here we just plotted the data as is because there are only 3 zeros out of 
311 data points.

```{r}
ggplot(ex1509, aes(x = Year, y = Sunspots)) + 
  geom_point() + 
  scale_y_log10() + 
  geom_smooth()
```
These data are not the best demonstration of Poisson regression because there
is a clear temporal pattern.
With that being said, if you are just interested in the overall trend of 
sunspots through time, Poisson regression is still a reasonable approach. 

```{r}
m <- glm(Sunspots ~ Year, 
         data = ex1509,
         family = poisson)
```


## Parameter estimation

The maximum likelihood estimator for this model is not available in closed form
and thus we use an iterative algorithm to find the answers. 
But we don't have to worry about these details. 

```{r}
coef(m)
```
This MLE can be used to determine asymptotic confidence intervals.

```{r}
confint(m)
```
The fact that the interval for the coefficient for Year does not include zero
provides evidence that (assuming the remaining model assumptions are true) 
the coefficient for Year is unlikely to be zero. 


## Testing

We can also compute p-values for a single parameter being zero or a collection
of parameters being zero. 

```{r}
summary(m)$coefficients
```

A small p-value here indicates evidence against the model that has that 
coefficient equal to 0. 
But remember that other aspects of the model could be problematic, 
e.g. independence, constant probability (within a group), etc. 

The p-value above is based on a Wald test. 
An alternative is based on a likelihood ratio test. 

```{r}
anova(m, test = "LRT")
```

Unlike with the linear regression (which is based on the normal distribution)
the p-values here don't match exactly. 



## Predictions

When computing predictions, we need to be explicit about whether we want 
predictions on the linear part, i.e. $\eta_i$, or the response, 
i.e. $\lambda_i = E[Y_i]$. 
By default, the `predict()` function provides predictions on the linear part. 

```{r}
p <- bind_cols(ex1509, 
               predict(m, newdata = ex1509, se.fit = TRUE)) %>%
  mutate(
    lcl = fit - qnorm(.975)*se.fit,
    ucl = fit + qnorm(.975)*se.fit,
    
    # convert to expected count
    fit = exp(fit),
    lcl = exp(lcl),
    ucl = exp(ucl)
  ) %>%
  select(-residual.scale)

head(p)
```

```{r}
ggplot(p, aes(x = Year, 
              y = Sunspots,
              ymin = lcl,
              ymax = ucl)) + 
  geom_point() + 
  geom_ribbon(fill = "blue", alpha = 0.5) +
  geom_line(aes(y = fit), color = "blue")
```


### emmeans()

Another alternative is to use the `emmeans::emmeans()` function. 

```{r}
emmeans(m, pairwise ~ Year, type = "response", 
        at = list(Year = c(quantile(ex1509$Year, c(0,.5,1)))))
```


## Diagnostics

It is more difficult to assess model assumptions in logistic regression 
models.

```{r}
resid_panel(m)
resid_xpanel(m)
```



# Examples

## Number of species

```{r}
case0801
```

Due to the large ratio of max to min area, 
I would start with a logarithm for Area. 
Because we are considering a Poisson regression model which includes a 
logarithmic link function, we should plot Species on a log scale. 

```{r}
g <- ggplot(case0801, aes(x = Area, y = Species)) + 
  geom_point() +
  scale_x_log10() + 
  scale_y_log10()

g
```

Looks pretty linear. 

```{r}
m <- glm(Species ~ log(Area), 
         data = case0801,
         family = "poisson")
```

```{r}
summary(m)
confint(m)
```

```{r}
p <- bind_cols(case0801,
               predict(m, se.fit = TRUE)) %>% # defaults to observed data
  mutate(
    lcl = fit - qnorm(.975)*se.fit,
    ucl = fit + qnorm(.975)*se.fit,
    
    fit = exp(fit),
    lcl = exp(lcl),
    ucl = exp(ucl)
  )
```

```{r}
g + geom_ribbon(data = p, 
              aes(
                x = Area,
                ymin = lcl,
                ymax = ucl
              ),
              fill = "blue",
              alpha = 0.5) +
  geom_line(data = p,
            aes(
              x = Area,
              y = fit
            ), color = "blue") +
  labs(
    x = "Island Area (sq. miles)",
    y = "Number of Species",
    title = "Number of Reptile and Amphibian Species v Island Area"
  )
```




## Warpbreaks

```{r}
summary(warpbreaks)
```

```{r}
g <- ggplot(warpbreaks, 
       aes(x = tension,
           y = breaks,
           color = wool,
           shape = wool)) +
  geom_point(position = position_jitterdodge(dodge.width = 0.1)) +
  scale_y_log10()
g
```

```{r}
m <- glm(breaks ~ wool * tension,
         data = warpbreaks,
         family = "poisson")
```

```{r}
resid_panel(m, qqbands = TRUE, smoother = TRUE)
```

```{r}
anova(m, test = "LRT")
```
```{r}
nd <- warpbreaks %>%
  select(wool, tension) %>%
  unique()

p <- bind_cols(nd, 
               predict(m, nd, se.fit = TRUE)) %>%
  mutate(
    lcl = fit - qnorm(.975)*se.fit,
    ucl = fit + qnorm(.975)*se.fit,
    
    # Convert to expected count scale
    fit = exp(fit),
    lcl = exp(lcl),
    ucl = exp(ucl)
  )

g + 
  geom_pointrange(
    data = p,
    aes(y = fit,
        ymin = lcl,
        ymax = ucl),
    position = position_dodge(width = 0.1)
  ) + 
  geom_line(
    data = p,
    aes(y = fit, group = wool)
  ) +
  labs(
    x = "Tension",
    y = "Number of breaks",
    title = "Number of Breaks vs Tension and Wool Type",
    color = "Wool",
    shape = "Wool"
  )
```

```{r}
tension <- emmeans(m, pairwise ~ tension, type = "response")
confint(tension)

wool    <- emmeans(m, pairwise ~ wool,    type = "response")
confint(wool)
```

Perhaps you didn't want to compare the number of breaks for one explanatory 
variable *averaged over* the levels of the other explanatory variable.
Instead, you wanted to compare the number of breaks for one 
explanatory variable *at* the levels of the other explanatory variable. 

```{r}
tension <- emmeans(m, pairwise ~ tension | wool, type = "response")
confint(tension)


# Compare wool 
wool    <- emmeans(m, pairwise ~ wool | tension, type = "response")
confint(wool)


# Get all the comparisons
both    <- emmeans(m, pairwise ~ wool + tension, type = "response")
confint(both)
```
