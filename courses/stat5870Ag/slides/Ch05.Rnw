\documentclass[handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

% Theme settings
\usetheme{AnnArbor}\usecolortheme{beaver}
\setbeamertemplate{navigation symbols}{}


% Document settings
\newcommand{\lecturetitle}{One-way ANOVA}
\title[\lecturetitle]{STAT 401A - Statistical Methods for Research Workers}
\subtitle{\lecturetitle}
\author[Jarad Niemi]{Jarad Niemi (Dr. J)}
\institute[Iowa State]{Iowa State University}
\date[\today]{last updated: \today}


\setkeys{Gin}{width=0.6\textwidth}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

<<options, echo=FALSE, warning=FALSE>>=
opts_chunk$set(comment=NA, fig.width=6, fig.height=5, size='tiny', out.width='0.6\\textwidth', fig.align='center', message=FALSE)
library(plyr)
library(ggplot2)
library(xtable)
library(Sleuth3)
@


\begin{document}

\begin{frame}
\maketitle
\end{frame}

\section{Multi-group data}
\begin{frame}[fragile]
\frametitle{Lifetime (months) of mice on different diets}

<<echo=FALSE>>=
ggplot(case0501, aes(x=Diet, y=Lifetime))+geom_boxplot()
@
\end{frame}

\subsection{Assumptions}
\begin{frame}
\frametitle{One-way ANOVA model/assumptions}

\[ Y_{ij} \stackrel{ind}{\sim} N\left(\mu_j, \sigma^2\right) \]
for $j=1,\ldots,J$ and $i=1,\ldots,n_j$. 
  
	{\color{gray} \small ($n_j$ means there can be different \# of observations in each group)}

\vspace{0.2in} \pause

Assumptions:
\begin{itemize}
\item Normality
  \begin{itemize}
  \item Not skewed
  \item Not heavy-tailed
  \end{itemize}
\item Common variance for all groups
\item Independence
  \begin{itemize}
  \item No cluster effects
  \item No serial effects
  \item No spatial effects
  \end{itemize}
\end{itemize}

\end{frame}

\begin{frame}[fragile]
\frametitle{ANOVA assumptions graphically}
<<echo=FALSE>>=
set.seed(1)
mu = rnorm(4)
curve(dnorm(x,mu[1]),-4,6, axes=F, frame=T, xlab="", ylab="", lwd=2)
for (i in 2:length(mu)) curve(dnorm(x, mu[i]), add=TRUE, lwd=2, col=i, lty=i)
@
\end{frame}

\begin{frame}
\frametitle{What if you want to compare two groups?}

We may still be interested in comparing two groups. 

\vspace{0.2in} \pause

Statistical hypothesis: Is there a difference in mean lifetimes between the mice in two groups, e.g. NP and N/N85?

\vspace{0.2in} \pause

Statistical question: What is the difference in mean lifetimes between the mice in two groups, e.g. NP and N/N85?

\end{frame}




\begin{frame}
\frametitle{Two-group analysis}
  Begin with the two group (equal variance) model:

	\[ Y_{ij} \stackrel{ind}{\sim} N\left(\mu_j, \sigma^2\right) \]
	
	\vspace{0.2in} \pause
	
  with	$j=1,2$ and $i=1,\ldots,n_j$ \pause
  
  To perform a hypothesis test or a CI for the difference in means, \pause the relevant quantities are:
  \begin{itemize}[<+->]
  \item $\overline{Y}_2-\overline{Y}_1$
  \item $SE(\overline{Y}_2-\overline{Y}_1) = s_p \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$
  \item $t$ distribution with $n_1+n_2-2$ degrees of freedom
  \end{itemize}
  \pause where 
  \[ s_p^2 = \frac{ (n_1-1)s_1^2 + (n_2-1)s_2^2 }{n1+n_2-2} \]
  \pause What if you have more than two groups?
\end{frame}



\begin{frame}
\frametitle{Multi-group analysis}
  The multi-group (equal variance) model:

  \[ Y_{ij} \stackrel{ind}{\sim} N\left(\mu_j, \sigma^2\right) \]
	
	\vspace{0.2in} \pause
	
  but now	$j=1,\alert{\ldots,J}$ and $i=1,\ldots,n_j$ \pause
	
	{\color{gray}($n_j$ means there can be different \# of observations in each group)} \pause
  
  To perform a hypothesis test or a CI for the difference in means, \pause the relevant quantities are:
  \begin{itemize}[<+->]
  \item $\overline{Y}_2-\overline{Y}_1$
  \item $SE(\overline{Y}_2-\overline{Y}_1) = s_p \sqrt{\frac{1}{n_1}+\frac{1}{n_2}}$
  \item $t$ distribution with $n_1+n_2\alert{+\cdots+n_J-J}$ degrees of freedom
  \end{itemize}
  \pause where 
  \[ s_p^2 = \frac{ (n_1-1)s_1^2 + (n_2-1)s_2^2 \alert{+ \cdots + (n_J-1)s_J^2} }{n1+n_2\alert{+\cdots+n_J-J}} \]
\end{frame}





\begin{frame}
\frametitle{Hypothesis test for comparison of two means (in multi-group data)}
  If $Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2)$ for $j=1,\ldots,J$ and we want to test the hypothesis
	\begin{itemize}
	\item $H_0: \mu_1=\mu_2$
	\item $H_1: \mu_1\ne \mu_2$
	\end{itemize}
	\pause then we compute:
	\[ t = \frac{\overline{Y}_1-\overline{Y}_2}{SE(\overline{Y}_1-\overline{Y}_2)} \]
	\pause where 
	\[ SE(\overline{Y}_1-\overline{Y}_2) = s_p \sqrt{\frac{1}{n_1}+\frac{1}{n_2}} \]
	\pause and
	\[ s_p^2 = \frac{(n_1-1)s_1^2 + (n_2-1)s_2^2+\cdots+(n_J-1)s_J^2}{n_1+n_2+\cdots+n_J - J }. \]
  \pause 
  Then we compare $t$ to a $t$ distribution with $n_1+n_2+\cdots+n_J-J$ degrees of freedom. 
\end{frame}



\subsection{Example}
\begin{frame}[fragile]
\frametitle{Diet effect on mice lifetime}
<<echo=FALSE, results='asis'>>=
sm = ddply(case0501, .(Diet), summarize,
          n = length(Lifetime),
          mean = mean(Lifetime),
          sd = sd(Lifetime))
tab = xtable(sm, digits=c(NA,NA,0,1,1), caption="Summary statistics for mice lifetime (months) on different diets")
print(tab, caption.placement="top")
@

\pause

Test for difference in mean lifetime between NP and N/N85, i.e. 
\[ H_0: \mu_4=\mu_1 \mbox{ vs } H_1: \mu_4\ne \mu_1. \]
\end{frame}


\begin{frame}
\frametitle{Showing work}

{\small
\[ \begin{array}{rl}
\overline{Y}_1-\overline{Y}_4 &= 32.7-27.4 = 5.3 \\
df &= 57+60+71+49+56+56-6 = 343 \\
s_p^2 &= \frac{(57-1)5.1^2 + (60-1)6.7^2+(71-1)7.8^2+(49-1)6.1^2+(56-1)6.7^2+(56-1)7.0^2}{57+60+71+49+56+56-6} \\
&= \frac{15314}{343} = 44.6 \\
s_p &= \sqrt{s_p^2} = \sqrt{44.6} = 6.7 \\
SE(\overline{Y}_1-\overline{Y}_4) &= s_p\sqrt{\frac{1}{n_1}+\frac{1}{n_4}} = 6.7\sqrt{\frac{1}{57}+\frac{1}{49}} = 1.3 \\
t &= \frac{\overline{Y}_1-\overline{Y}_4}{SE(\overline{Y}_1-\overline{Y}_4) } =\frac{5.3}{1.2} = 4.1 \\
p &= 2P(t_{343}<-|t|) = 2P(t_{343}<-4.1) = 0.000052 
\end{array} \]
}
So we reject the null hypothesis that there is no difference between mean lifetime of mice on the NP and N/N85 diets.

\end{frame}



% \begin{frame}[fragile]
% <<echo=FALSE>>=
% sm = ddply(case0501, .(Diet), summarize,
%           n = length(Lifetime),
%           mean = mean(Lifetime),
%           sd = sd(Lifetime))
% sm
% @
% 
% \pause 
% 
% <<>>=
% g1 = which(sm$Diet == "NP")
% g2 = which(sm$Diet == "N/N85")
% (sp = with(sm, sqrt(sum((n-1)*sd^2)/sum(n-1))))
% (se = sp*sqrt(1/sm$n[g1]+1/sm$n[g2]))
% (t = (sm$mean[g1]-sm$mean[g2])/se)
% (p = 2*pt(-abs(t), sum(sm$n-1)))
% @
% 
% confidence interval
% 
% <<>>=
% (t_critical_value = qt(.975,sum(sm$n-1)))
% (sm$mean[g1]-sm$mean[g2]) + c(-1,1)*t_critical_value*se
% @
% 
% \end{frame}



\begin{frame}[fragile]
\frametitle{Confidence interval for the difference of two means (in multi-group data)}

  If $Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2)$ for $j=1,\ldots,J$, a $100(1-\alpha)$\% confidence interval for $\mu_1-\mu_2$ is 
	\pause 
	\[ \overline{Y}_1-\overline{Y}_2 \pm t_{n_1+n_2+\cdots+n_J-J}(1-\alpha/2) SE(\overline{Y}_1-\overline{Y}_2) \]
	\pause where the $t$ critical value, $t_{n_1+n_2+\cdots+n_J-J}(1-\alpha/2)$, needs to be calculated using a statistical software.

  \vspace{0.2in} \pause
  
  A 95\% confidence interval for the difference in mean lifetime for N/N85 minus NP ($\mu_1-\mu_4$) is 
  \[ 5.3 \pm 1.96\times 1.3 = (2.8,7.8). \]
  The statistical conclusion would be 
  \begin{quote}
  In this study, mice on the N/N85 diet lived an average of 5.3 months longer than mice on the NP diet (95\% CI (2.8,7.8)). 
  \end{quote}

\end{frame}




\frame[containsverbatim]{\frametitle{}

\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  
PROC GLM DATA=mice;
  CLASS diet;
  MODEL lifetime = diet;
  LSMEANS diet / ADJUST=T CL;
  RUN;
\end{verbatim}
}

\frame[containsverbatim]{\frametitle{}
\tiny
\begin{verbatim}
                                        The GLM Procedure
                                       Least Squares Means

                                             lifetime      LSMEAN
                                diet           LSMEAN      Number

                                N/N85      32.6912281           1
                                N/R40      45.1166667           2
                                N/R50      42.2971831           3
                                NP         27.4020408           4
                                R/R50      42.8857143           5
                                lopro      39.6857143           6


                              Least Squares Means for effect diet
                              Pr > |t| for H0: LSMean(i)=LSMean(j)

                                  Dependent Variable: lifetime

    i/j              1             2             3             4             5             6

       1                      <.0001        <.0001        <.0001        <.0001        <.0001
       2        <.0001                      0.0166        <.0001        0.0731        <.0001
       3        <.0001        0.0166                      <.0001        0.6223        0.0293
       4        <.0001        <.0001        <.0001                      <.0001        <.0001
       5        <.0001        0.0731        0.6223        <.0001                      0.0117
\end{verbatim}
}

\frame[containsverbatim]{\frametitle{}
\tiny
\begin{verbatim}
                lifetime
                       diet           LSMEAN      95% Confidence Limits

                       N/N85       32.691228       30.951394    34.431062
                       N/R40       45.116667       43.420886    46.812447
                       N/R50       42.297183       40.738291    43.856075
                       NP          27.402041       25.525547    29.278535
                       R/R50       42.885714       41.130415    44.641014
                       lopro       39.685714       37.930415    41.441014
                
                               Least Squares Means for Effect diet

                                   Difference
                                      Between    95% Confidence Limits for
                       i    j           Means       LSMean(i)-LSMean(j)

                       1    2      -12.425439      -14.854984    -9.995893
                       1    3       -9.605955      -11.942013    -7.269897
                       1    4        5.289187        2.730232     7.848142
                       1    5      -10.194486      -12.665943    -7.723030
                       1    6       -6.994486       -9.465943    -4.523030
                       2    3        2.819484        0.516048     5.122919
                       2    4       17.714626       15.185417    20.243835
                       2    5        2.230952       -0.209692     4.671597
                       2    6        5.430952        2.990308     7.871597
                       3    4       14.895142       12.455599    17.334686
                       3    5       -0.588531       -2.936130     1.759068
                       3    6        2.611469        0.263870     4.959068
                       4    5      -15.483673      -18.053169   -12.914178
                       4    6      -12.283673      -14.853169    -9.714178
                       5    6        3.200000        0.717632     5.682368
\end{verbatim}
}





\subsection{One-way ANOVA F-test}
\begin{frame}[fragile]
\frametitle{One-way ANOVA F-test}

  Are any of the means different?

  \vspace{0.2in} \pause
  
  Hypotheses in English:
  \begin{itemize}
  \item[$H_0$:] all the means are the same
  \item[$H_1$:] at least one of the means is different
  \end{itemize}

  \vspace{0.2in} \pause

  Statistical hypotheses:
	\[ \begin{array}{ll@{\qquad\qquad}l}
	H_0: & \mu_j=\mu \mbox{ for all } j & \uncover<3->{Y_{ij} \stackrel{iid}{\sim} N(\mu, \sigma^2)} \\
	H_1: & \mu_j\ne\mu_{j'} \mbox{ for some $j$ and $j'$} & \uncover<3->{Y_{ij} \stackrel{ind}{\sim} N\left(\mu_j, \sigma^2\right)}
	\end{array}	\]
  
  \pause
  
  An ANOVA table organizes the relevant quantities for this test and computes the pvalue. 
\end{frame}



\subsection{ANOVA table}
\frame{\frametitle{ANOVA table}
\footnotesize
	A start of an ANOVA table:
	\[ \begin{array}{llcc}
	\mbox{Source of variation} & 
	\mbox{Sum of squares} &
	\mbox{d.f.} & \mbox{Mean square}  \\
	\hline
	\mbox{Factor A (Between groups)} &  
	SSA=\sum_{j=1}^{J} n_j \left(\overline{Y}_j-\overline{Y}\right)^2 & 
	J-1 & 
	\frac{SSA}{J-1} \phantom{\left(=s_p^2\right)} \\
	\mbox{Error (Within groups)} & 
	SSE=\sum_{j=1}^{J} \sum_{i=1}^{n_j} \left(Y_{ij}-\overline{Y}_j\right)^2 & 
	n-J &  
	\frac{SSE}{n-J} \left(=s_p^2\right) \\
	\hline
	\mbox{Total} & 
	SST=\sum_{j=1}^{J} \sum_{i=1}^{n_j} \left(Y_{ij}-\overline{Y}\right)^2 &
	n-1 \\
	\end{array} \]
	where 
	\begin{itemize}
	\item $J$ is the number of groups, 
	\item $n_j$ is the number of observations in group $j$, 
	\item $n=\sum_{j=1}^J n_j$ (total observations), 
	\item $\overline{Y}_j = \frac{1}{n_j}\sum_{i=1}^{n_j} Y_{ij}$ (average in group $j$), 
	\item and $\overline{Y} = \frac{1}{n}\sum_{j=1}^J \sum_{i=1}^{n_j} Y_{ij}$ (overall average).
	\end{itemize}
}

\frame{\frametitle{ANOVA table}
  {\tiny
	An easier to remember ANOVA table:
	
	\vspace{0.1in}
	
	\begin{tabular}{llcccc}
	Source of variation & Sum of squares & df & Mean square & F-statistic & p-value \\
	\hline
	Factor A (between groups) & SSA & $J-1$ & MSA = SSA/$J-1$ & MSA/MSE & \mbox{(see below)} \\
	Error (within groups) & SSE & $n-J$ & MSE = SSE/$n-J$ \\
	\hline
	Total & SST=SSA+SSE & $n-1$ 
	\end{tabular}
	}
	
	\vspace{0.3in}
	 
	Under $H_0$, 
	\begin{itemize}
	\item the quantity MSA/MSE has an F-distribution with $J-1$ numerator and $n-J$ denominator degrees of freedom,
	\item larger values of MSA/MSE indicate evidence against $H_0$, and
	\item the p-value is determined by $P(F_{J-1,n-J}>MSA/MSE)$.
	\end{itemize}
}


\begin{frame}[fragile]
\frametitle{F-distribution}

<<F-distribution, echo=FALSE>>=
df = c(5,300)
curve(df(x,df[1], df[2]), 0, 4, main=expression(F[list(5,300)]),
      xlab="x",
      ylab="Probability density function",
      lwd=2)
xx = c(2, seq(2, 4,by=.01), 4)
yy = c(0, df(xx[-c(1,length(xx))], df[1], df[2]), 0)
polygon(xx,yy, col='red', border=NA)
@

\end{frame}



\begin{frame}[fragile]
\frametitle{One-way ANOVA F-test (by hand)}
{\tiny 
<<echo=FALSE, results='asis'>>=
sm2 = rbind(sm, data.frame(Diet="Total", n=nrow(case0501), mean=mean(case0501$Lifetime), sd=NA))
tab = xtable(sm2, digits=c(NA,NA,0,1,1), caption="Summary statistics for mice lifetime (months) on different diets")
print(tab, caption.placement="top", hline.after=c(-1,0,6,7))
@

\pause 

So 
\[ \begin{array}{rl}
SSA =& 57\times (32.7-38.8)^2+60\times (45.1-38.8)^2+71\times (42.3-38.8)^2 + 49\times (27.4-38.8)^2 \\
&+ 56\times (42.9-38.8)^2 + 56\times(39.7-38.8)^2 = 12734 \pause \\
SST =& (35.5-38.8)^2 + (35.4-38.8)^2 + (34.9-38.8)^2 + \cdots + (19.6-38.8)^2 + (47.6-38.8)^2 = 28031 \pause \\
SSE =& SST-SSA = 28031 - 12734 = 15297 \\
J-1 =& 5 \\
n-J =& 349-6 = 343 \\
n-1 =& 348 \\
MSA =& SSA/J-1 = 12734/5 = 2547 \\
MSE =& SSE/n-J = 15297/343 = 44.6 = s_p^2 \\
F =& MSA/MSE = 2547/44.6 = 57.1 \\
p =& P(F_{5,343}>57.1) < 0.0001
\end{array} \]
}
\end{frame}




\begin{frame}[fragile]
\frametitle{As a picture}

<<echo=FALSE>>=
ggplot(case0501, aes(x=Diet, y=Lifetime)) + geom_jitter(size=3) + geom_hline(data=sm2, aes(yintercept=mean[7]), col='red', size=2) + geom_errorbar(data=sm, aes(y=mean, ymin=mean, ymax=mean), col='blue', size=2)
@

\end{frame}



\frame[containsverbatim]{\frametitle{SAS code and output for one-way ANOVA}
{\tiny
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  
PROC GLM DATA=mice;
  CLASS diet;
  MODEL lifetime = diet;
  RUN;

                                        The GLM Procedure

Dependent Variable: lifetime

                                               Sum of
       Source                      DF         Squares     Mean Square    F Value    Pr > F
       Model                        5     12733.94181      2546.78836      57.10    <.0001
       Error                      343     15297.41532        44.59888
       Corrected Total            348     28031.35713
\end{verbatim}

}
}


\begin{frame}[fragile]
\frametitle{R code and output for one-way ANOVA}
<<>>=
m = lm(Lifetime~Diet, case0501)
anova(m)
@
\end{frame}




\section{General F-tests}
\begin{frame}
\frametitle{General F-tests}

The one-way ANOVA F-test is an example of a general hypothesis testing framework that uses F-tests. 
\pause 
This framework can be used to test 
\begin{itemize}
\item composite alternative hypotheses\pause or, equivalently,
\item a full vs a reduced model. \pause 
\end{itemize}

The general idea is to balance the amount of variability remaining when moving from the reduced model to the full model measured using the sums of squared errors (SSEs) relative to the amount of complexity, i.e. parameters, added to the model. 

\end{frame}


\subsection{Simple vs Composite Hypotheses}
\frame{\frametitle{Simple vs Composite Hypotheses}
  Suppose \[ Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2) \]
	for $j=1,\ldots,3$ \pause then a \alert{simple hypothesis} is 
	\begin{itemize}
	\item $H_0: \mu_1=\mu_2$
	\item $H_1: \mu_1\ne \mu_2$
	\end{itemize}
	\pause and a \alert{composite hypothesis} is 
	\begin{itemize}
	\item $H_0: \mu_1=\mu_2=\mu_3$
	\item $H_1: \mu_j\ne \mu_{j'}$ for some $j$ and $j'$
	\end{itemize}
	\pause since there are four possibilities under $H_1$
	\begin{itemize}[<+->]
	\item $\mu_1=\mu_2\ne\mu_3$
	\item $\mu_2=\mu_3\ne\mu_1$
	\item $\mu_3=\mu_1\ne\mu_2$
	\item none of $\mu_1,\mu_2,\mu_3$ are equal
	\end{itemize}
}




\subsection{Composite hypotheses}
\frame{\frametitle{Testing Composite hypotheses}
	If $Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2)$ for $j=1,\ldots,J$ and we want to test the \alert{composite hypothesis} 
	\begin{itemize}
	\item $H_0: \mu_j=\mu$ for all $j$
	\item $H_1: \mu_j\ne \mu_{j'}$ for some $j$ and $j'$
	\end{itemize}
	
	\vspace{0.2in} \pause
	
	 think about this as two models: \pause
	\begin{itemize}
	\item $H_0: Y_{ij} \stackrel{ind}{\sim} N(\mu,\sigma^2)$ \uncover<6->{\alert{(reduced)}}\pause
	\item $H_1: Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2)$ \uncover<5->{\alert{(full)}}
	\end{itemize}
	
	\vspace{0.2in} \pause
	
	\uncover<7->{We can use an F-test to calculate a p-value for tests of this type.}	
}


\begin{frame}
\frametitle{Nested models: full vs reduced}

\begin{definition}
Two models are \alert{nested} if the \alert{reduced} model is a special case of the \alert{full} model. 
\end{definition}

\vspace{0.2in} \pause

For example, consider the full model 
\[ Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2). \]
\pause One special case of this model occurs when $\mu_j=\mu$ \pause and thus 
\[ Y_{ij} \stackrel{ind}{\sim} N(\mu,\sigma^2). \]
is a reduced model and these two models are nested. 

\end{frame}


\frame{
\frametitle{Calculating the sum of squared residuals (errors)}

  \vspace{-0.2in}

  \[ \begin{array}{|l|c|c|}
	\hline && \\
	\mbox{Model}& Full & Reduced \\ &&\\ \hline && \\
	\mbox{Assumption} & 
	\uncover<2->{H_1:  Y_{ij} \stackrel{ind}{\sim} N\left(\mu_j, \sigma^2\right)} & \uncover<6->{
	H_0:  Y_{ij} \stackrel{iid}{\sim} N(\mu, \sigma^2)} \\ && \\ \hline && \\
	\mbox{Mean} & 
	\uncover<3->{\hat{\mu}_j = \overline{Y}_j = \frac{1}{n_j} \sum_{i=1}^{n_j} Y_{ij}} & 
	\uncover<7->{\hat{\mu} = \overline{Y} = \frac{1}{n} \sum_{j=1}^{J} \sum_{i=1}^{n_j} Y_{ij}} \\ && \\ \hline && \\
	\mbox{Residual}  & 
	\uncover<4->{r_{ij} = Y_{ij}-\hat{\mu}_j = Y_{ij}-\overline{Y}_j} & 
	\uncover<8->{r_{ij} = Y_{ij}-\hat{\mu} = Y_{ij}-\overline{Y}} \\ &&\\ \hline && \\
	\mbox{SSE} & 
	\uncover<5->{\sum_{j=1}^{J} \sum_{i=1}^{n_j} r_{ij}^2}  & 
	\uncover<9->{\sum_{j=1}^{J} \sum_{i=1}^{n_j} r_{ij}^2}  \\ &&\\\hline
	\end{array} \]
}



\frame{\frametitle{General F-tests}
\small
	Do the following
	\begin{enumerate}[1.]
	\item Calculate 
	\[ \begin{array}{r} 
	\multicolumn{1}{l}{\mbox{Extra sum of squares =}}\\
	 \mbox{ Residual sum of squares (reduced) - Residual sum of squares (full)} 
	\end{array} \] \pause 
	\item Calculate 
	\[ \begin{array}{r}
	\multicolumn{1}{l}{\mbox{Extra degrees of freedom =}} \\ 
	\mbox{ \# of mean parameters (full) - \# of mean parameters (reduced)} \end{array} \] \pause
	\item Calculate F-statistics
	\[ \mbox{F} = \frac{\mbox{Extra sum of squares / Extra degrees of freedom}}{\hat{\sigma}^2_{full}} \] \pause 
	\item Pvalue is $P(F_{ndf,ddf} > F)$
		\begin{itemize}
		\item numerator degrees of freedom (nnd) = Extra degrees of freedom
		\item denominator degrees of freedom (ddf) = n - \# of mean parameters (full)
		\end{itemize}
	\end{enumerate}
}

\subsection{Example}
\frame{\frametitle{Example}
	Recall the mice data set. 
  
  \pause 
  
  Consider the hypothesis that all diets have a common mean lifetime except NP.
	
	\vspace{0.2in} \pause
	
	Let
	\[ Y_{ij} \stackrel{ind}{\sim} N(\mu_j,\sigma^2) \]
	with $j=1$ being the NP group \pause then the hypotheses are
	\begin{itemize}
	\item $H_0: \mu_j=\mu$ for $j\ne 1$
	\item $H_1: \mu_j\ne\mu_{j'}$ for some $j,j'=2,\ldots,6$
	\end{itemize}
	
	\vspace{0.2in} \pause
	
	As models:
	\begin{itemize}
	\item $H_0: Y_{i1}\sim N(\mu_1,\sigma^2)$ and $Y_{ij}\sim N(\mu,\sigma^2)$ for $j\ne 1$
	\item $H_1: Y_{ij}\sim N(\mu_j,\sigma^2)$
	\end{itemize}
}


\begin{frame}[fragile]
\frametitle{As a picture}

<<echo=FALSE>>=
sm3 = sm 
sm3$mean[-which(sm3$Diet=="NP")] = mean(case0501$Lifetime[case0501$Diet!="NP"])
ggplot(case0501, aes(x=Diet, y=Lifetime)) + geom_jitter(size=3) + geom_errorbar(data=sm, aes(y=mean, ymin=mean, ymax=mean), col='blue', size=2) + geom_errorbar(data=sm3, aes(y=mean, ymin=mean, ymax=mean), col='red', size=2)
@

\end{frame}


\frame[containsverbatim]{\frametitle{}
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  IF diet='NP' THEN NP=1; ELSE NP=0;

PROC PRINT DATA=mice; RUN;
  
PROC GLM DATA=mice;
  CLASS diet;
  MODEL lifetime = diet;
  TITLE 'Full Model';
  RUN;

PROC GLM DATA=mice;
  CLASS NP;
  MODEL lifetime = NP;
  TITLE 'Reduced Model';
  RUN;
\end{verbatim}
}

\frame[containsverbatim]{\frametitle{}
\tiny
\begin{verbatim}
                                           Full Model        

                                        The GLM Procedure

Dependent Variable: lifetime

                                               Sum of
       Source                      DF         Squares     Mean Square    F Value    Pr > F
       Model                        5     12733.94181      2546.78836      57.10    <.0001
       Error                      343     15297.41532        44.59888
       Corrected Total            348     28031.35713
                                           
                                
                                           
                                          Reduced Model     

                                        The GLM Procedure

Dependent Variable: lifetime

                                               Sum of
       Source                      DF         Squares     Mean Square    F Value    Pr > F
       Model                        1      7401.77817      7401.77817     124.50    <.0001
       Error                      347     20629.57896        59.45124
       Corrected Total            348     28031.35713
\end{verbatim}
}

\frame{\frametitle{General F-test calculations}
 	\[\begin{array}{rl}
	ESS & = 20629.57896 - 15297.41532 = 5332.164 \\
	Edf &= 5 -1 = 4 \\
	F &= (ESS/Edf)/\hat{\sigma}^2_{full} = (5332.164/4)/44.59888 = 29.88956 
	\end{array}\]
	
	\vspace{0.2in} \pause
	
	Finally, we calculate the pvalue (using statistical software): 
	\[ P(F_{4,343}>F) <0.0001 \]

	\vspace{0.2in} \pause
	
	Since this is very small, we reject the null hypothesis that the reduced model is adequate. \pause So there is evidence that the mean is not the same for all the non-NP groups.
}


\begin{frame}[containsverbatim]
\frametitle{Making SAS do the calculations}
{\tiny
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  IF diet='NP' THEN NP=1; ELSE NP=0;

PROC GLM DATA=mice;
  CLASS diet NP;
  MODEL lifetime = NP diet(NP);
  RUN;
  
                                       The GLM Procedure
 
Dependent Variable: lifetime   

                                              Sum of
      Source                      DF         Squares     Mean Square    F Value    Pr > F
      Model                        5     12733.94181      2546.78836      57.10    <.0001
      Error                      343     15297.41532        44.59888                     
      Corrected Total            348     28031.35713                                     



      Source                      DF     Type III SS     Mean Square    F Value    Pr > F
      NP                           1     7256.758693     7256.758693     162.71    <.0001
      diet(NP)                     4     5332.163640     1333.040910      29.89    <.0001
\end{verbatim}
}
\end{frame}



\begin{frame}[fragile]
\frametitle{Making R do the calculations}

<<>>=
case0501$NP = factor(case0501$Diet == "NP")

modR = lm(Lifetime~NP,   case0501)
modF = lm(Lifetime~Diet, case0501)
anova(modR,modF)
@

\end{frame}


\subsection{Another example}
\begin{frame}
\frametitle{Are there differences in means amongst low calorie diets?}

Let $Y_{ij}$ be the lifetime in months for mouse $i$ in group $j$ where the groups are N/N85 (j=1), N/R40 (j=2), N/R50 (j=3), NP (j=4), R/R50 (j=5), and lopro (j=6). \pause Assume 
\[ Y_{ij} \stackrel{ind}{\sim} N(\mu_j, \sigma^2) \]
and test the hypotheses
\begin{itemize}
\item[$H_0$:] $\mu_2=\mu_3=\mu_5=\mu_6$
\item[$H_1$:] at least one of $\mu_2,\mu_3,\mu_5,\mu_6$ is different from the rest
\end{itemize}

\vspace{0.2in} \pause

Implicitly, we are allowing $\mu_1$ and $\mu_4$ to be different from the others. 

\end{frame}



\begin{frame}[containsverbatim]
\frametitle{Making SAS do the calculations}
{\tiny
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  IF diet='N/N85' THEN local=1; ELSE local=2; /* ccurently, if diet='NP' then local=2 */
  IF diet='NP' THEN local=0;                  /* now,       if diet='NP' then local=0 */

/* I needed to run this PROC PRINT to set the data up appropriately 
PROC PRINT DATA=mice; RUN;
*/

PROC GLM DATA=mice;
  CLASS diet local;
  MODEL lifetime = local diet(local);
  RUN;
  
                                       The GLM Procedure
 
Dependent Variable: lifetime   

                                              Sum of
      Source                      DF         Squares     Mean Square    F Value    Pr > F
      Model                        5     12733.94181      2546.78836      57.10    <.0001
      Error                      343     15297.41532        44.59888                     
      Corrected Total            348     28031.35713                                     

      Source                      DF       Type I SS     Mean Square    F Value    Pr > F
      local                        2     11868.52098      5934.26049     133.06    <.0001
      diet(local)                  3       865.42083       288.47361       6.47    0.0003
\end{verbatim}
}
\end{frame}



\begin{frame}[fragile]
\frametitle{Making R do the calculations}

<<>>=
case0501$local = ifelse(case0501$Diet=='N/N85', 1, 2) # NP is 2 here 
case0501$local[case0501$Diet=='NP'] = 0               # now NP is 1
case0501$local = factor(case0501$local)
mod1 = lm(Lifetime~1,     case0501)
modR = lm(Lifetime~local, case0501)
modF = lm(Lifetime~Diet,  case0501)
anova(mod1, modR, modF)

anova(modF) # To get the pooled estimate of the variance for the full model
@

\end{frame}


\subsection{Summary}
\frame{\frametitle{Summary}
	\begin{itemize}[<+->]
	\item Use t-tests for simple hypothesis tests and CIs
	\item Use F-tests for composite hypothesis tests
    \begin{itemize}
    \item One-way ANOVA F-test
    \item General F-tests
    \end{itemize}
	\end{itemize}
  
  \vspace{0.2in} \pause 
  
  Think about F-tests as comparing models.
}



\end{document}
