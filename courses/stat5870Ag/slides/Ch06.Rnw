\documentclass[handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

% Theme settings
\usetheme{AnnArbor}\usecolortheme{beaver}
\setbeamertemplate{navigation symbols}{}


% Document settings
\newcommand{\lecturetitle}{One-way ANOVA (contrasts and multiple comparisons)}
\title[\lecturetitle]{STAT 401A - Statistical Methods for Research Workers}
\subtitle{\lecturetitle}
\author[Jarad Niemi]{Jarad Niemi (Dr. J)}
\institute[Iowa State]{Iowa State University}
\date[\today]{last updated: \today}


\setkeys{Gin}{width=0.6\textwidth}
\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

<<options, echo=FALSE, warning=FALSE>>=
opts_chunk$set(comment=NA, fig.width=6, fig.height=5, size='tiny', out.width='0.6\\textwidth', fig.align='center', message=FALSE)
library(plyr)
library(ggplot2)
library(xtable)
library(Sleuth3)
@


\begin{document}



\begin{frame}
\maketitle
\end{frame}


\section{Contrasts}
\begin{frame}[fragile]
\frametitle{Mice lifetimes}
<<echo=FALSE>>=
ggplot(case0501, aes(x=Diet, y=Lifetime))+geom_boxplot()
@
\end{frame}




\frame{\frametitle{Simple hypothesis}	
	Consider the one-way ANOVA model: $Y_{ij} \sim N(\mu_j,\sigma^2)$ where $j=1,\ldots,J$.
	
	\vspace{0.2in} \pause
	
	Here are a few simple alternative hypotheses:
  
	\begin{enumerate}
	\item Mean lifetimes for N/R50 and R/R50 diet are different. \pause
	\item Mean lifetimes for N/R40 is different than for N/R50 and R/R50 combined. \pause
	\item Mean lifetimes for high calorie (NP and N/N85) diets is different than for low calorie diets combined.
	\end{enumerate}

	\vspace{0.2in} \pause 
	
	$H_0: \gamma=0 \qquad H_1: \gamma \ne 0:$ \pause
	\[ \begin{array}{rl}
	\gamma_1 &=  \mu_{R/R50}-\mu_{N/R50} \pause\\
	\gamma_2 &= \mu_{N/R40}-\frac{1}{2}(\mu_{N/R50}+\mu_{R/R50}) \pause\\
	\gamma_3 &= \frac{1}{4}(\mu_{N/R50}+\mu_{R/R50}+\mu_{N/R40}+\mu_{lopro})-\frac{1}{2}(\mu_{NP}+\mu_{N/N85}) \\
	\end{array} \]
}


\begin{frame}
\frametitle{Contrasts}

\begin{definition}
A \alert{linear combination} of group means has the form 
\[ \gamma = C_1\mu_1+C_2\mu_2 +\ldots + C_J\mu_J  \]
where $C_j$ are known coefficients and $\mu_j$ are the unknown population means.
\end{definition}

\vspace{0.2in} \pause 

\begin{definition}
A linear combination with $C_1+C_2+\cdots+C_J=0$ is a \alert{contrast}. 
\end{definition}

\vspace{0.2in} \pause 

\begin{remark}
Contrast interpretation is usually best if $|C_1|+|C_2|+\cdots+|C_J|=2$, i.e. the positive sum to 1 and the negative coefficients sum to -1. 
\end{remark}

\end{frame}



\begin{frame}[fragile]
\frametitle{Inference on contrasts}

	\[ \gamma = C_1 \mu_1 + C_2 \mu_2 + \cdots + C_J \mu_J \] 
	
	\pause 
	
	Estimated by 
	\[ g = C_1 \overline{Y}_1 + C_2 \overline{Y}_2 + \cdots + C_J \overline{Y}_J \] 
	
	\pause
	
	with standard error
	\[ SE(g) = s_p \sqrt{\frac{C_1^2}{n_1}+\frac{C_2^2}{n_2}+\cdots+\frac{C_J^2}{n_J}} \]
	
	\pause
	
	t-statistic (compare to $t_{n-J}$) and CI:
	\[ t = \frac{g}{SE(g)}  \pause \qquad g \pm t_{n-J}(1-\alpha/2) SE(g) \]
\end{frame}


\begin{frame}[fragile]
\frametitle{Contrasts for mice lifetime dataset}

For these contrasts: 
\begin{enumerate}
	\item Mean lifetimes for N/R50 and R/R50 diet are different. 
	\item Mean lifetimes for N/R40 is different than for N/R50 and R/R50 combined.
	\item Mean lifetimes for high calorie (NP and N/N85) diets is different than for low calorie diets combined.
\end{enumerate}

\pause 
	
	$H_0: \gamma=0 \qquad H_1: \gamma \ne 0:$ 
  \[ \begin{array}{rl}
	\gamma_1 &=  \mu_{R/R50}-\mu_{N/R50} \pause\\
	\gamma_2 &= \mu_{N/R40}-\frac{1}{2}(\mu_{N/R50}+\mu_{R/R50}) \pause\\
	\gamma_3 &= \frac{1}{4}(\mu_{N/R50}+\mu_{R/R50}+\mu_{N/R40}+\mu_{lopro})-\frac{1}{2}(\mu_{NP}+\mu_{N/N85}) \\
	\end{array} \]

\pause

{\tiny
<<echo=FALSE, results='asis'>>=
K = rbind("early rest - none @ 50kcal"=c( 0, 0,-1, 0, 1, 0),
          "40kcal/week - 50kcal/week" =c( 0, 2,-1, 0,-1, 0) / 2,
          "lo cal - hi cal"           =c(-2, 1, 1,-2, 1, 1) / 4)
colnames(K) = levels(case0501$Diet)
print(xtable(K))
@
}
\end{frame}



\begin{frame}[fragile]
\frametitle{Mice liftime examples}
<<echo=FALSE,results='asis'>>=
sm = ddply(case0501, .(Diet), summarise, 
           n = length(Lifetime),
           mean = mean(Lifetime),
           sd = sd(Lifetime))

print(xtable(sm))
@

\pause 

Contrasts:
<<echo=FALSE, results='asis'>>=
m = lm(Lifetime~Diet, case0501)
sp = summary(m)$sigma

g = rowSums(K%*%sm$mean)
SEg = rowSums(sp*sqrt(K^2%*%(1/sm$n)))

df = sum(sm$n-1)
t = g/SEg
p = 2*pt(-abs(t),df)
L = g-qt(.975,df)*SEg
U = g+qt(.975,df)*SEg

tests = data.frame(g=g,"SE(g)"=SEg,t=t,p=p,L=L,U=U, check.names=FALSE)

print(xtable(tests))
@
\end{frame}





\subsection{SAS}
\frame[containsverbatim]{\frametitle{}
\tiny
	\begin{verbatim}
DATA case0501;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $ ;

PROC MEANS DATA=case0501;
  CLASS diet;
  VAR lifetime;
  RUN;

                                      The MEANS Procedure
                                Analysis Variable : lifetime 
 
                  N
    diet        Obs      N            Mean         Std Dev         Minimum         Maximum
    --------------------------------------------------------------------------------------
    N/N85        57     57      32.6912281       5.1252972      17.9000000      42.3000000
    N/R40        60     60      45.1166667       6.7034058      19.6000000      54.6000000
    N/R50        71     71      42.2971831       7.7681947      18.6000000      51.9000000
    NP           49     49      27.4020408       6.1337010       6.4000000      35.5000000
    R/R50        56     56      42.8857143       6.6831519      24.2000000      50.7000000
    lopro        56     56      39.6857143       6.9916945      23.4000000      49.7000000
    --------------------------------------------------------------------------------------
	\end{verbatim}
}


\frame[containsverbatim]{\frametitle{}
\tiny
	\begin{verbatim}
PROC GLM;
  CLASS diet;
  MODEL lifetime = diet / CLPARM;
  ESTIMATE 'early rest - none @ 50kcal' diet  0  1 -1  0  0  0 ;
  ESTIMATE '40kcal/week - 50kcal/week'  diet  0  2 -1  0 -1  0 / DIVISOR = 2;
  ESTIMATE 'lo cal - hi cal'            diet -2  1  1 -2  1  1 / DIVISOR = 4 ;
  RUN;
  QUIT;


                                       The GLM Procedure

                                              Sum of
      Source                      DF         Squares     Mean Square    F Value    Pr > F
      Model                        5     12733.94181      2546.78836      57.10    <.0001
      Error                      343     15297.41532        44.59888                     
      Corrected Total            348     28031.35713                                     

                                                         Standard
       Parameter                         Estimate           Error    t Value    Pr > |t|
       early rest - none @ 50kcal       0.5885312      1.19355007       0.49      0.6223
       40kcal/week - 50kcal/week        2.5252180      1.04854904       2.41      0.0166
       lo cal - hi cal                 12.4496851      0.78001425      15.96      <.0001

                    Parameter                       95% Confidence Limits
                    early rest - none @ 50kcal      -1.7590676    2.9361299
                    40kcal/week - 50kcal/week        0.4628224    4.5876136
                    lo cal - hi cal                 10.9154718   13.9838985
	\end{verbatim}
}


\subsection{R}
\begin{frame}[fragile]

<<warning=FALSE>>=
library(multcomp)
m = lm(Lifetime~Diet-1, case0501) # The -1 indicates no intercept (see Ch 7)
summary(m)
K
@

\end{frame}




\begin{frame}[fragile]

<<warning=FALSE>>=
t = glht(m, linfct=K)
summary(t)
confint(t, calpha=univariate_calpha())
@

\end{frame}






\subsection{Summary}
\frame{\frametitle{Summary}
	\begin{itemize}
	\item Contrasts are linear combinations that sum to zero
	\item t-test tools are used to calculate pvalues and confidence intervals 
	\end{itemize}
}



\section{Multiple Comparisons}
\begin{frame}[containsverbatim]
\frametitle{SAS code and output for one-way ANOVA}
{\tiny
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  
PROC GLM DATA=mice;
  CLASS diet;
  MODEL lifetime = diet;
  LSMEANS diet / ADJUST=T;
  RUN;

                                        The GLM Procedure

Dependent Variable: lifetime

                                               Sum of
       Source                      DF         Squares     Mean Square    F Value    Pr > F
       Model                        5     12733.94181      2546.78836      57.10    <.0001
       Error                      343     15297.41532        44.59888
       Corrected Total            348     28031.35713
\end{verbatim}
}
\end{frame}






\subsection{Pairwise comparisons}
\frame[containsverbatim]{\frametitle{SAS code and output for pairwise comparisons}
\tiny
\begin{verbatim}
                                        The GLM Procedure
                                       Least Squares Means

                                             lifetime      LSMEAN
                                diet           LSMEAN      Number

                                N/N85      32.6912281           1
                                N/R40      45.1166667           2
                                N/R50      42.2971831           3
                                NP         27.4020408           4
                                R/R50      42.8857143           5
                                lopro      39.6857143           6


                              Least Squares Means for effect diet
                              Pr > |t| for H0: LSMean(i)=LSMean(j)

                                  Dependent Variable: lifetime

    i/j              1             2             3             4             5             6

       1                      <.0001        <.0001        <.0001        <.0001        <.0001
       2        <.0001                      0.0166        <.0001        0.0731        <.0001
       3        <.0001        0.0166                      <.0001        0.6223        0.0293
       4        <.0001        <.0001        <.0001                      <.0001        <.0001
       5        <.0001        0.0731        0.6223        <.0001                      0.0117
       6        <.0001        <.0001        0.0293        <.0001        0.0117


NOTE: To ensure overall protection level, only probabilities associated with pre-planned
      comparisons should be used.
\end{verbatim}
}
                  
                            
                  

\subsection{Statistical testing errors}
\begin{frame}
\frametitle{Statistical testing errors}


\begin{definition}
A \alert{type I error} occurs when a true null hypothesis is rejected.
\end{definition}

\vspace{0.1in} \pause

\begin{definition}
A \alert{type II error} occurs when a false null hypothesis is not rejected. \pause \alert{Power} is one minus the type II error probability. 
\end{definition}

\vspace{0.1in} \pause

\begin{remark}
We set $\alpha$ to control the type I error probability. \pause If we set $\alpha=0.05$, then we will incorrectly reject a true null hypothesis 5\% of the time.
\end{remark}

\vspace{0.1in} \pause

\begin{definition}
The \alert{familywise error rate} is the probability of rejecting at least one true null hypothesis.
\end{definition}
\end{frame}





\begin{frame}
\frametitle{Type I error for all pairwise comparisons of $J$ groups}
  How many combinations when choosing 2 items out of $J$? \pause
	\[ {J\choose 2} \pause = \frac{J!}{2!(J-2)!}. \]
  If $J=6$, then there are 15 different comparison of means. \pause If we set $\alpha=0.05$ as our significance level, then individually each test will only incorrectly reject 5\% of the time. 
  
	\vspace{0.2in} \pause 
  
  If we have 15 tests and use $\alpha=0.05$, what is the familywise error rate? \pause
	\[ 1-(1-0.05)^{15} \pause = 1-(0.95)^{15} = 1-0.46 = 0.54 \]
	
	\pause 
  
  So there is a greater than 50\% probability of falsely rejecting a true null hypothesis! 
\end{frame}




\subsection{Bonferroni correction}
\begin{frame}[fragile]
\frametitle{Bonferroni correction}

\begin{definition}
If we do $m$ tests and want the familywise error rate to be $\alpha$, the \alert{Bonferroni correction} uses $\alpha/m$ for each individual test. \pause The familywise error rate, for independent tests, is $1-(1-\alpha/,m)^m$. 
\end{definition}
\pause
<<echo=FALSE>>=
m = 1:20
plot(m, 1-(1-.05/m)^m, ylim=c(0,0.05), type="l", lwd=2,
     xlab="Number of tests", ylab="Familywise error rate", main="Bonferroni familywise error rate")
lines(m, 1-(1-.01/m)^m, lty=2, col=2, lwd=2)
legend("right", paste("alpha=",c(.05,.01)), lwd=2, lty=1:2, col=1:2)
@

\end{frame}



\frame[containsverbatim]{\frametitle{SAS code and output for pairwise comparisons}
Compare the unadjusted pvalues to $\alpha/15=0.05/15=0.0033$. 
\tiny
\begin{verbatim}
                              Least Squares Means for effect diet
                              Pr > |t| for H0: LSMean(i)=LSMean(j)

                                  Dependent Variable: lifetime

    i/j              1             2             3             4             5             6

       1                      <.0001        <.0001        <.0001        <.0001        <.0001
       2        <.0001                      0.0166        <.0001        0.0731        <.0001
       3        <.0001        0.0166                      <.0001        0.6223        0.0293
       4        <.0001        <.0001        <.0001                      <.0001        <.0001
       5        <.0001        0.0731        0.6223        <.0001                      0.0117
       6        <.0001        <.0001        0.0293        <.0001        0.0117


NOTE: To ensure overall protection level, only probabilities associated with pre-planned
      comparisons should be used.
\end{verbatim}
Now 2-3, 3-6, and 5-6 are no longer significant. 
}



\frame[containsverbatim]{\frametitle{SAS code and output for one-way ANOVA}
If you use SAS to do the adjustment, compare pvalues to $\alpha=0.05$. 
\tiny
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  
PROC GLM DATA=mice;
  CLASS diet;
  MODEL lifetime = diet;
  LSMEANS diet / ADJUST=BON;
  RUN;

                              Least Squares Means for effect diet
                              Pr > |t| for H0: LSMean(i)=LSMean(j)

                                  Dependent Variable: lifetime

    i/j              1             2             3             4             5             6

       1                      <.0001        <.0001        0.0009        <.0001        <.0001
       2        <.0001                      0.2488        <.0001        1.0000        0.0002
       3        <.0001        0.2488                      <.0001        1.0000        0.4402
       4        0.0009        <.0001        <.0001                      <.0001        <.0001
       5        <.0001        1.0000        1.0000        <.0001                      0.1751
       6        <.0001        0.0002        0.4402        <.0001        0.1751
\end{verbatim}
}



\begin{frame}
\frametitle{Comments on the Bonferroni correction}

\begin{remark}
The Bonferroni correction can be used in any situation. \pause In particular, it can be used on unadjusted pvalues reported in an article that has many tests by comparing their pvalues to $\alpha/m$ where $m$ is the number of tests they perform.
\end{remark}

\vspace{0.2in} \pause

\begin{remark}
The Bonferroni correction is (in general) the most conservative multiple comparison adjustment we will discuss, i.e. it will lead to the least null hypothesis rejections. 
\end{remark}

\end{frame}






\subsection{Constructing multiple confidence intervals}
\begin{frame}
\frametitle{Constructing multiple confidence intervals}

\begin{remark}
A $100(1-\alpha)$\% confidence interval should contain the true value $100(1-\alpha)$\% of the time.
\end{remark}

\vspace{0.2in} \pause

\begin{remark}
An error occurs if the confidence interval does not contain the true value. 
\end{remark}

\vspace{0.2in} \pause

Just like the Type I error and familywise error rate, we can ask what is the probability at least one confidence interval does not cover the true value. 

\vspace{0.2in} \pause

The procedures we will talk about for confidence intervals have equivalent approaches for hypothesis testing (pvalues). \pause Within these procedures we still have the equivalence between pvalues and CIs.

\end{frame}



\frame{\frametitle{Constructing multiple confidence intervals}
	Confidence interval for the difference between group $j$ and group $j'$:\pause
	\[ \overline{Y}_j - \overline{Y}_{j'} \pm M \,s_p \sqrt{\frac{1}{n_j}+\frac{1}{n_{j'}}} \]
	\pause where $M$ is a multiplier that depends on the adjustment procedure: 
	
	\vspace{0.2in} \pause
	
	{\small
	\begin{center}
	\begin{tabular}{|l|c|l|}
	\hline
	Procedure & M & \multicolumn{1}{c|}{Use}  \\
	\hline\pause
	LSD & $t_{n-J}(1-\alpha/2)$ & After significant $F$-test \\
	&& (no adjustment) \pause \\
	Dunnett & multivariate $t$ & Compare all groups to control \pause \\
	Tukey-Kramer & $q_{J,n-J}(1-\alpha)/\sqrt{2}$ & All pairwise comparisons \pause \\
	Scheff\'e & $\sqrt{(J-1)F_{(J-1,n-J)}(1-\alpha)}$ & All contrasts \pause \\
	\alert{Bonferroni} & $t_{n-J}(1-(\alpha/m)/2)$ &$m$ tests \\
	&  & (most generic) \\
	\hline
	\end{tabular}
	\end{center}
	}
}




\subsection{Example - Tukey adjustment}
\frame[containsverbatim]{\frametitle{SAS code and output for one-way ANOVA}
\tiny
\begin{verbatim}
DATA mice;
  INFILE 'case0501.csv' DSD FIRSTOBS=2;
  INPUT lifetime diet $;
  
PROC GLM DATA=mice;
  CLASS diet;
  MODEL lifetime = diet;
  LSMEANS diet / CL ADJUST=TUKEY;
  RUN;
                                        The GLM Procedure
                                       Least Squares Means
                        Adjustment for Multiple Comparisons: Tukey-Kramer

                                  Dependent Variable: lifetime
 
    i/j              1             2             3             4             5             6
       1                      <.0001        <.0001        0.0008        <.0001        <.0001
       2        <.0001                      0.1565        <.0001        0.4684        0.0002
       3        <.0001        0.1565                      <.0001        0.9964        0.2460
       4        0.0008        <.0001        <.0001                      <.0001        <.0001
       5        <.0001        0.4684        0.9964        <.0001                      0.1168
       6        <.0001        0.0002        0.2460        <.0001        0.1168              
\end{verbatim}
}



\subsection{Example - Tukey adjustment}
\frame[containsverbatim]{\frametitle{SAS code and output for one-way ANOVA}
\tiny
\begin{verbatim}
                                        The GLM Procedure
                                       Least Squares Means
                        Adjustment for Multiple Comparisons: Tukey-Kramer


                               Least Squares Means for Effect diet
 
                                   Difference         Simultaneous 95%
                                      Between      Confidence Limits for
                       i    j           Means       LSMean(i)-LSMean(j)
                       1    2      -12.425439      -15.965442    -8.885435
                       1    3       -9.605955      -13.009741    -6.202169
                       1    4        5.289187        1.560626     9.017749
                       1    5      -10.194486      -13.795557    -6.593416
                       1    6       -6.994486      -10.595557    -3.393416
                       2    3        2.819484       -0.536769     6.175736
                       2    4       17.714626       14.029406    21.399846
                       2    5        2.230952       -1.325223     5.787128
                       2    6        5.430952        1.874777     8.987128
                       3    4       14.895142       11.340571    18.449714
                       3    5       -0.588531       -4.009133     2.832070
                       3    6        2.611469       -0.809133     6.032070
                       4    5      -15.483673      -19.227592   -11.739755
                       4    6      -12.283673      -16.027592    -8.539755
                       5    6        3.200000       -0.416969     6.816969
\end{verbatim}
}




\begin{frame}
\frametitle{False Discovery Rate}

\begin{remark}
Not wanting to make a single mistake is pretty conservative.
\end{remark}

\pause

In high-throughput fields a more common multiple comparison adjustment is false discovery rate.

\vspace{0.2in} \pause

\begin{definition}
\alert{False discovery rate} procedures try to control the expected proportion of incorrectly rejected null hypotheses.
\end{definition}
\end{frame}


\subsection{Summary}
\begin{frame}
\frametitle{How to incorporate multiple comparison adjustments}

\begin{enumerate}
\item Determine what tests are going to be run (before looking at the data) or what confidence intervals are going to be constructed.
\item Determine which multiple comparison adjustment is the most relevant
\item Use/state that adjustment and interpret your results
\end{enumerate}

\end{frame}




\section{Data analysis: sulfur effect on scab disease in potatoes}
\frame{\frametitle{Sulfur effect on scab disease in potatoes}
\begin{quote}
The experiment was conducted to investigate the effect of sulfur on controlling scab disease in potatoes. There were seven treatments: control, plus spring and fall application of 300, 600, 1200 lbs/acre of sulfur. The response variable was percentage of the potato surface area covered with scab averaged over 100 random selected potatoes. A completely randomized design was used with 8 replications of the control and 4 replications of the other treatments. 
\end{quote}
{\tiny 
Cochran and Cox. (1957) Experimental Design (2nd ed). pg96 and Agron. J. 80:712-718 (1988)
}

\vspace{0.2in} \pause

Scientific question:
\begin{itemize}[<+->]
\item Does sulfur have any impact at all?
\item Is there a difference between spring and fall?
\item Is there an effect of increased sulfur {\footnotesize (expect more sulfur causes less scab)}?
\end{itemize}
}


\subsection{Exploratory}
\begin{frame}[fragile]
\frametitle{Data}
<<echo=FALSE>>=
d = read.csv("potato.csv")
d
d$sulfur = as.numeric(gsub("\\D","",d$trt))*100
d$sulfur[is.na(d$sulfur)] = 0
d$application = NA
d$application[grep("F",d$trt)] = "fall"
d$application[grep("S",d$trt)] = "spring"
d$application = factor(d$application)

d$trt = factor(d$trt, levels=c("F12","F6","F3","O","S3","S6","S12"), ordered=TRUE)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Design}
<<echo=FALSE>>=
plot(0,0, xlab="Sulfur (lbs/acre)", ylab="Application", main="Treatment visualization",
     type="n", axes=F,
     xlim=c(-100,1500), ylim=c(.5,2.5))
axis(1, c(0,300,600,1200), lwd=0)
axis(2, c(1,2), c("spring","fall"), lwd=0)
xc = c(0,300,300,600,600,1200,1200)
yc = c(1.5,1,2,1,2,1,2)
rect(xc-100,yc-.4,xc+100,yc+.4)
text(xc,yc, c(8,rep(4,6)))
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Design}
<<echo=FALSE>>=
plot(0,0, xlab="col", ylab="row", main="Completely randomized design\n potato scab experiment",
     xlim=range(d$col)+c(-.5,.5), ylim=range(d$row)+c(-.5,.5), axes=F, type="n")
text(d$col, d$row, d$trt)
axis(1, 1:8, lwd=0)
axis(2, 1:4, lwd=0)
segments(1:9-.5,0.5,1:9-.5,4.5)
segments(0.5,1:5-.5,8.5,1:5-.5)
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Data}
<<echo=FALSE>>=
qplot(trt, inf, data=d, geom=c("boxplot","jitter"), xlab="Sulfur", ylab="Scab percent")
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Data}
<<echo=FALSE>>=
qplot(sulfur, inf, data=d, color=application, geom="jitter", xlab="Sulfur", ylab="Scab percent")
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Data}
<<echo=FALSE>>=
qplot(col, inf, data=d, color=application, geom="jitter", xlab="Column ID", ylab="Scab percent")
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Data}
<<echo=FALSE>>=
qplot(row, inf, data=d, color=application, geom="jitter", xlab="Row ID", ylab="Scab percent")
@
\end{frame}




\subsection{Model}
\frame{\frametitle{Model}
$Y_{ij}$: avg \% of surface area covered with scab for plot $i$ in treatment $j$ for $j=1,\ldots,7$. 

\vspace{0.2in} \pause 

Assume $Y_{ij} \stackrel{ind}{\sim} N(\mu_j, \sigma^2)$. 

\vspace{0.2in} \pause

Hypotheses:
\begin{itemize}[<+->]
\item Difference amongst any means: One-way ANOVA F-test
\item \emph{Any effect}: Control vs sulfur
\item \emph{Fall vs spring}: Contrast comparing fall vs spring applications
\item \emph{Sulfur level}: Linear trend contrast
\end{itemize}
}


\begin{frame}
\frametitle{Control vs sulfur}

\[ \begin{array}{rl} 
\gamma &= \frac{1}{6} (\mu_{F12}+ \mu_{F6} + \mu_{F3} + \mu_{S3} + \mu_{S6} + \mu_{S12})- \mu_O \pause \\ \\
 &= \frac{1}{6} (\mu_{F12}+ \mu_{F6} + \mu_{F3} + \mu_{S3} + \mu_{S6} + \mu_{S12}- 6\mu_O)  
\end{array} \] 

\end{frame}



\frame{\frametitle{Fall vs spring contrast}

\begin{itemize}
\item \emph{Fall vs spring}: Contrast comparing fall vs spring applications \pause 

\[ \begin{array}{rl} 
\gamma &= \frac{1}{3} (\mu_{F12}+ \mu_{F6} + \mu_{F3})+ 0 \mu_O -\frac{1}{3} (\mu_{S3} + \mu_{S6} + \mu_{S12}) \pause \\ \\
&= \frac{1}{3} \mu_{F12} + \frac{1}{3} \mu_{F6} + \frac{1}{3} \mu_{F3} + 0 \mu_O -\frac{1}{3} \mu_{S3} -\frac{1}{3} \mu_{S6} -\frac{1}{3} \mu_{S12} \pause \\ \\
&= \frac{1}{3} \left[\mu_{F12} + \mu_{F6} + \mu_{F3} + 0 \mu_O -1 \mu_{S3} -1 \mu_{S6} -1 \mu_{S12} \right] 
\end{array} \] 

\end{itemize}	
}


\frame{\frametitle{Sulfur level: linear trend contrasts}

\begin{itemize}[<+->]
\item The unique sulfur levels ($X_i$) are 0, 3, 6, and 12. \pause 
\item So the linear trend contrast ($X_i-\overline{X}$) is
\[ \begin{array}{ccccc}
X_i & 0 & 3 & 6 & 12 \\
\hline
X_i-\overline{X} & -\frac{21}{4} & -\frac{9}{4} & \frac{3}{4} & \frac{27}{4} 
\end{array} \]
\item But 3, 6, and 12 are duplicated, so we need the average of the groups 

\pause

\[ \begin{array}{rl}
\gamma &= -\frac{21}{4} \mu_0 - \frac{9}{4} \mu_3 + \frac{3}{4} \mu_6 + \frac{27}{4} \mu_{12} \pause \\ \\
&= -\frac{21}{4} \mu_0 - \frac{9}{4} \left( \frac{\mu_{S3}+\mu_{F3}}{2} \right) + \frac{3}{4} \left( \frac{\mu_{S6}+\mu_{F6}}{2} \right) + \frac{27}{4} \left( \frac{\mu_{S12}+\mu_{F12}}{2} \right) \pause \\ \\
&= \frac{1}{8} \left[ -42\mu_0 -9\mu_{S3}-9\mu_{F3}  + 3 \mu_{S6}+ 3\mu_{F6}  + 27 \mu_{S12}+ 27 \mu_{F12} \right]
\end{array} \]
	
\end{itemize}
	

}


\begin{frame}
\frametitle{Contrasts}

\begin{center}
\begin{tabular}{c|ccccccc|c}
Trt & F12 & F6 & F3 & O & S3 & S6 & S12 & Div \\
\hline
Sulfur v control & 1 & 1 & 1 & -6 & 1  & 1 & 1 & 6 \\
Fall v Spring & 1 & 1 & 1 & 0 & -1  & -1 & -1 & 3 \\
Linear Trend & 27 & 3 & -9 & -42 & -9 & 3 & 27 & 8 \\
\hline  
\end{tabular}
\end{center}


\end{frame}



\frame[containsverbatim]{\frametitle{SAS code}
\tiny 
\begin{verbatim}
DATA d;
  INFILE 'potato.csv' DSD FIRSTOBS=2;
  INPUT scabp treatment $ row col;
  sulfur = 0;
  IF treatment in ("F3","S3") THEN sulfur=300;
  IF treatment in ("F6","S6") THEN sulfur=600;
  IF treatment in ("F12","S12") THEN sulfur=1200;
  application = "NA    ";
  IF treatment in ("F3","F6","F12") THEN application="fall";
  IF treatment in ("S3","S6","S12") THEN application="spring";

PROC PRINT DATA=d (OBS=10); RUN; 

PROC MEANS;
  CLASS treatment;
  VAR scabp;
  RUN;
\end{verbatim}
}

\frame[containsverbatim]{\frametitle{SAS code}
\tiny 
\begin{verbatim}
                Obs    scabp    treatment    row    col    sulfur    application

                  1       9        F3         4      1       300       fall     
                  2      12        O          4      2         0       NA       
                  3      18        S6         4      3       600       spring   
                  4      10        F12        4      4      1200       fall     
                  5      24        S6         4      5       600       spring   
                  6      17        S12        4      6      1200       spring   
                  7      30        S3         4      7       300       spring   
                  8      16        F6         4      8       600       fall     
                  9      10        O          3      1         0       NA       
                 10       7        S3         3      2       300       spring   
                                         
                                         

                                       The MEANS Procedure

                                   Analysis Variable : scabp 
 
                    N
     treatment    Obs     N            Mean         Std Dev         Minimum         Maximum
     --------------------------------------------------------------------------------------
     F12            4     4       5.7500000       2.8722813       4.0000000      10.0000000
     F3             4     4       9.5000000       4.9328829       4.0000000      16.0000000
     F6             4     4      15.5000000       3.7859389      10.0000000      18.0000000
     O              8     8      22.6250000       8.3655330      10.0000000      32.0000000
     S12            4     4      14.2500000       4.8562674       7.0000000      17.0000000
     S3             4     4      16.7500000      10.7819293       7.0000000      30.0000000
     S6             4     4      18.2500000       4.9244289      12.0000000      24.0000000
     --------------------------------------------------------------------------------------
\end{verbatim}
}




\frame[containsverbatim]{\frametitle{SAS code}
\tiny 
\begin{verbatim}
PROC GLM DATA=d PLOTS=(DIAGNOSTICS RESIDUALS);
  CLASS treatment;
  MODEL scabp = treatment / CLPARM;
  LSMEANS treatment / CL;
  ESTIMATE 'sulfur - control' treatment 1 1 1 -6 1 1 1 / DIVISOR=6;
  ESTIMATE 'fall - spring' treatment 1 1 1 0 -1 -1 -1 / DIVISOR=3;
  ESTIMATE 'linear trend'  treatment 27 -9 3 -42 27 -9 3 / DIVISOR=8;
  OUTPUT OUT=dres P=predicted R=residuals;
  RUN;

PROC GPLOT DATA=dres;
  PLOT residuals*predicted;
  PLOT residuals*sulfur;
  PLOT residuals*application;
  PLOT residuals*row;
  PLOT residuals*col;
  RUN;
\end{verbatim}
}



\subsection{Diagnostics}
\frame{\frametitle{Diagnostics}
	\begin{center}
	\includegraphics{PotatoDiagnosticsPanel}
	\end{center}
}





\subsection{Results}
\frame[containsverbatim]{\frametitle{SAS output}
\tiny 
\begin{verbatim}
                                        The GLM Procedure

                                     Class Level Information
 
                         Class          Levels    Values

                         treatment           7    F12 F3 F6 O S12 S3 S6 


                             Number of Observations Read          32
                             Number of Observations Used          32
                                        
                                        

 
Dependent Variable: scabp   

                                               Sum of
       Source                      DF         Squares     Mean Square    F Value    Pr > F
       Model                        6      972.343750      162.057292       3.61    0.0103
       Error                       25     1122.875000       44.915000                     
       Corrected Total             31     2095.218750                                     

                       R-Square     Coeff Var      Root MSE    scabp Mean
                       0.464077      42.80633      6.701865      15.65625

\end{verbatim}
}



\frame[containsverbatim]{\frametitle{SAS output}
\tiny 
\begin{verbatim}
                     treatment    scabp LSMEAN      95% Confidence Limits

                     F12              5.750000       -1.151375    12.651375
                     F3               9.500000        2.598625    16.401375
                     F6              15.500000        8.598625    22.401375
                     O               22.625000       17.744991    27.505009
                     S12             14.250000        7.348625    21.151375
                     S3              16.750000        9.848625    23.651375
                     S6              18.250000       11.348625    25.151375



                                        The GLM Procedure
 
Dependent Variable: scabp   

                                         Standard
 Parameter                 Estimate         Error  t Value  Pr > |t|    95% Confidence Limits
 sulfur - control        -9.2916667     2.7360251    -3.40    0.0023   -14.9266158   -3.6567175
 fall - spring           -6.1666667     2.7360251    -2.25    0.0332   -11.8016158   -0.5317175
 linear trend           -68.1562500    21.0269359    -3.24    0.0034  -111.4620350  -24.8504650
\end{verbatim}
}



\subsection{Analysis in R}
\begin{frame}[fragile]
\frametitle{}
<<potato_in_R>>=
library(multcomp)
K = rbind("sulfur - control" = c(1, 1, 1, -6, 1, 1, 1)/6,
          "fall - spring"    = c(1,1,1,0,-1,-1,-1)/3,
          "linear trend"     = c(27,3,-9,-42,-9,3,27)/8)
m = lm(inf~trt,d)
anova(m)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{}
<<>>=
par(mfrow=c(2,3))
plot(m,1:6)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{}
<<>>=
g = glht(lm(inf~trt-1,d), linfct=K) # notice the -1 in the model
summary(g, test=adjusted(type="none")) # unadjusted pvalues
confint(g, calpha=univariate_calpha()) # unadjusted confidence intervals
@
\end{frame}


\begin{frame}[fragile]
\frametitle{}
<<>>=
plot(d$col,residuals(m))
@
\end{frame}






\section{Summary}
\frame{\frametitle{Summary}
	For this particular data analysis
	\begin{itemize}[<+->]
	\item Significant differences in means between the groups (ANOVA $F_{6,25}=3.61$ p=0.01)
  \item Sulfur had a significant impact on scab (p=0.002)
	\item Fall was better than spring (p=0.03, 95\% CI (0.53, 11.8))
	\item Linear trend in sulfur was significant(p=0.003) 
	
	\vspace{0.2in}\pause
	
	\item Concerned about spatial correlation among columns
	\item Consider a transformation of the response 
		\begin{itemize}
		\item CI for F12 (-1.2, 12.7)
		\item Non-constant variance (residuals vs predicted, sulfur, application)
		\end{itemize}
	\end{itemize}
}


% \frame{\frametitle{Summary}
% 	Statistical analysis process (post-design):
% 	\begin{enumerate}[<+->]
% 	\item Determine scientific questions of interest
% 	\item Determine what data were collected
% 	\item Exploratory analysis of data
% 	\item Create statistical analysis to answer questions
% 	\item Check model assumptions
% 	\item Answer scientific questions
% 	\item Improve future data collection
% 	\end{enumerate}
% }




\end{document}
