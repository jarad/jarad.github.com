\documentclass[t,aspectratio=169,handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

\input{../../frontmatter}
\input{../../commands}

\title{R01 - Simple linear regression}

% \setbeamertemplate{background}
% {\includegraphics[width=\paperwidth,height=\paperheight,keepaspectratio]{video_overlay}}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=4.5, 
               size='tiny', 
               out.width='\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=TRUE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, echo=FALSE>>=
library("tidyverse")
library("scales")
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\begin{document}

\begin{frame}
\maketitle
\end{frame}




\section{Simple linear regression}
\subsection{Telomere length}
\begin{frame}
\frametitle{Telomere length}

\footnotesize

{\tiny \url{http://www.pnas.org/content/101/49/17312}}

\pause

\bc
\begin{quote}
People who are stressed over long periods tend to look haggard, \pause and it is commonly thought that psychological stress leads to premature aging [as measured by decreased telomere length]

\pause ...

examine the importance of ... caregiving stress (...number of years since a child's diagnosis [of a chronic disease]) [on telomere length]

\pause ...

Telomere length values were measured from DNA by a quantitative PCR assay that determines the relative ratio of telomere repeat copy number to single-copy gene copy number (T/S ratio) in experimental samples as compared with a reference DNA sample.
\end{quote}
\nc\ec

\end{frame}


\begin{frame}
\frametitle{Data}

\vspace{-0.2in}

<<telomere_data, echo=FALSE>>=
# From `abd` package
Telomeres <- structure(list(years = c(1L, 1L, 1L, 2L, 2L, 2L, 2L, 3L, 2L, 
4L, 4L, 5L, 5L, 3L, 4L, 4L, 5L, 5L, 5L, 6L, 6L, 6L, 6L, 6L, 7L, 
6L, 8L, 8L, 8L, 7L, 7L, 8L, 8L, 8L, 10L, 10L, 12L, 12L, 9L), 
    telomere.length = c(1.63, 1.24, 1.33, 1.5, 1.42, 1.36, 1.32, 
    1.47, 1.24, 1.51, 1.31, 1.36, 1.34, 0.99, 1.03, 0.84, 0.94, 
    1.03, 1.14, 1.17, 1.23, 1.25, 1.31, 1.34, 1.36, 1.22, 1.32, 
    1.28, 1.26, 1.18, 1.03, 1.1, 1.13, 0.98, 0.85, 1.05, 1.15, 
    1.14, 1.24)), .Names = c("years", "telomere.length"), class = "data.frame", row.names = c(NA, 
-39L)) %>%
  dplyr::mutate(jittered_years = jitter(years)) # used for plotting
@

\bc
<<telomere_plot, dependson="telomere_data", echo=FALSE>>=
g = ggplot(Telomeres, aes(x=jittered_years, y=telomere.length)) + 
  geom_point() + 
  labs(title = "Telomere length vs years post diagnosis",
       x = "Years since diagnosis (jittered)", y = "Telomere length") + 
  theme_bw()

g
@
\nc\ec
\end{frame}


\begin{frame}
\frametitle{Data with regression line}

\vspace{-0.2in}

\bc
<<telomere_plot_with_regression_line, dependson="telomere_plot", echo=FALSE>>=
g = g + geom_smooth(method='lm', se=FALSE)  
g
@
\nc\ec
\end{frame}

  

\subsection{Model}
\frame{\frametitle{Simple Linear Regression}
  The \alert{simple linear regression} model is 
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_i, \sigma^2) \]
	where $Y_i$ and $X_i$ are the response and explanatory variable, respectively, 
	for individual $i$.
	
	\vspace{0.1in} \pause
	
	Terminology (all of these are equivalent):
	\bc
	\begin{center}
	\begin{tabular}{ll}
	\hline
	response & explanatory \\
	outcome & covariate \\
	dependent & independent \\
	endogenous & exogenous \\
	\hline
	\end{tabular}
	\end{center}
	\nc\ec
}



\begin{frame}
\frametitle{Simple linear regression - visualized}

\vspace{-0.2in}

\bc
<<slr_viz, echo = FALSE>>=
xx = 0:9
d = expand.grid(mean = xx,
                x = seq(-3, 3, length = 101)) %>%
  dplyr::mutate(y = mean + dnorm(x),
                x = mean + x)

slr_viz = ggplot(d, aes(x=x, y=y, group = mean)) + 
  geom_hline(yintercept = xx, color = "gray") +
  geom_abline(intercept = 0, slope = 1, color = "blue") + 
  geom_line(color = "magenta", size = 2) + 
  coord_flip() +
  labs(title = "Simple linear regression model",
       x = "Response variable",
       y = "Explanatory variable") +
  theme_bw() 

slr_viz +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank(),
        axis.text.y=element_blank(),
        axis.ticks.y=element_blank(),
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank())
@
\nc\ec
\end{frame}




\subsection{Parameter interpretation}
\frame{\frametitle{Parameter interpretation}

\small

Recall:
\[ E[Y_i|X_i=x] = \beta_0 + \beta_1 x \qquad Var[Y_i|X_i=x] = \sigma^2 \]

\vspace{-0.1in} \pause
	
\bc
\begin{itemize}
\item	If $X_i=0$, then $E[Y_i|X_i=0] = \beta_0$. \pause 
	
$\beta_0$ is the \alert{expected} response when the explanatory variable is zero. \pause 
	
\item If $X_i$ increases from $x$ to $x+1$, then 
\[ \begin{array}{rl}
E[Y_i|X_i=x+1] &= \beta_0+\beta_1x+\beta_1 \pause \\
\uncover<6->{-} E[Y_i|X_i=x\phantom{\,+\,1}] &= \beta_0+\beta_1 x  \pause \\
\hline
&= \phantom{\beta_0+\beta_1x+}\beta_1 \pause
\end{array} \]
	
$\beta_1$ is the \alert{expected} increase in the response for each unit 
increase in the explanatory variable.
	
\pause
	
\item 
	
$\sigma$ is the standard deviation of the response for a fixed value of the 
explanatory variable.
\end{itemize}
\nc\ec
}



\begin{frame}
\frametitle{Simple linear regression - visualized}

\vspace{-0.2in}

\bc
<<echo=FALSE, dependson = "slr_viz">>=
slr_viz + 
  scale_y_continuous(breaks = scales::pretty_breaks())
@
\nc\ec
\end{frame}


\subsection{Parameter estimation}
\frame{\frametitle{}
	\small

	Remove the mean:
	\[ Y_i = \beta_0+\beta_1 X_i +e_i \qquad e_i \stackrel{iid}{\sim} N(0,\sigma^2) \]
	
	 \pause
	
	So the error is
	\[ e_i = Y_i - (\beta_0+\beta_1X_i) \]
	\pause which we approximate by the \alert{residual}
	\[ r_i = \hat{e}_i = Y_i - (\hat{\beta}_0+\hat{\beta}_1X_i) \]
	\pause The least squares (minimize $\sum_{i=1}^n r_i^2$), 
	maximum likelihood, and 
	Bayesian estimators (prior $1/\sigma^2$) \pause are 
	
	\vspace{-0.2in} \pause
	
	\bc
	\[ \begin{array}{rl}
  \hat{\beta}_1 &= SXY/SXX \\
	\hat{\beta}_0 &= \overline{Y}-\hat{\beta}_1\overline{X} \\ 
	\hat{\sigma}^2 &=  SSE/(n-2) \qquad df=n-2 \pause \\
  \\
  \overline{X} &= \frac{1}{n} \sum_{i=1}^n X_i \\
	\overline{Y} &= \frac{1}{n} \sum_{i=1}^n Y_i \pause \\ 
  \\
  SXY &= \sum_{i=1}^n (X_i-\overline{X})(Y_i-\overline{Y}) \\
	SXX &= \sum_{i=1}^n (X_i-\overline{X})(X_i-\overline{X}) = \sum_{i=1}^n (X_i-\overline{X})^2 \\
	SSE &= \sum_{i=1}^n r_i^2 
	\end{array} \]
	\nc\ec
}


\begin{frame}
\frametitle{Residuals}
\vspace{-0.2in}
\bc
<<dependson="telomere_plot_with_regression_line", echo=FALSE>>=
g
@
\nc\ec
\end{frame}

\begin{frame}
\frametitle{Residuals}
\vspace{-0.2in}
\bc
<<residual_plot, dependson="telomere_plot_with_regression_line", echo=FALSE>>=
m <- lm(telomere.length ~ years, data = Telomeres)
residuals =  Telomeres %>%
  mutate(predict = predict(m),
         residuals = residuals(m))

g +  geom_segment(aes(xend = jittered_years, yend = predict), 
                  data = residuals, color = "red") 
@
\nc\ec
\end{frame}


\subsection{Standard errors}
\frame{\frametitle{}
\small
	How certain are we about $\hat{\beta}_0$ and $\hat{\beta}_1$? 
	
	\vspace{0.2in} \pause
	
	\bc
	We quantify this uncertainty using their standard errors (or posterior scale parameters): \pause
	\[ \begin{array}{rlll}
	SE(\hat\beta_0) &= \hat{\sigma} \sqrt{\frac{1}{n} + \frac{\overline{X}^2}{(n-1)s_X^2}} & df=n-2 \pause\\ 
	SE(\hat\beta_1) &= \hat{\sigma} \sqrt{\phantom{\frac{1}{n} +\,\, }\frac{1}{(n-1)s_X^2}} & df=n-2 \pause\\ 
	\\
	s_X^2 &= SXX/(n-1) \\ 
	s_Y^2 &= SYY/(n-1) \pause \\
	SYY &=  \sum_{i=1}^n (Y_i-\overline{Y})^2 \pause \\
	\\
	r_{XY} &= \frac{SXY/(n-1)}{s_Xs_Y} &\pause \mbox{correlation coefficient} \pause \\
	R^2 &= r^2_{XY} \pause = \frac{SST-SSE}{SST} \pause & \mbox{coefficient of determination} \pause \\
	SST &= SYY = \sum_{i=1}^n (Y_i-\overline{Y})^2 \pause 
	\end{array} \]
The coefficient of determination ($R^2$) is the proportion of the total response variation explained by the model.
\nc\ec
}



\begin{frame}
\frametitle{Default Bayesian analysis of the simple linear regression model}

\small

If we assume the default prior $p(\beta_0,\beta_1,\sigma^2)\propto 1/\sigma^2$,
then the marginal posteriors for the mean parameters are 
\[ 
\beta_j|y \sim t_{n-2}(\hat\beta_j, SE(\hat\beta_j)^2).
\]
\pause
We can construct a $100(1-a)\%$ two-sided credible interval for $\beta_j$ via
\[ 
\hat{\beta}_j \pm t_{n-2,1-a/2} SE(\hat\beta_j)
\]
\pause
where $P(T_{n-2} < t_{n-2,1-a/2}) = 1-a/2$ for $T_{n-2} \sim t_{n-2}$.

\vspace{0.2in} \pause

\bc
We can compute posterior probabilities via 
\[ \begin{array}{rl}
P(\beta_j<b_j|y) &= P\left(T_{n-2}<\frac{\hat{\beta_j}-b_j}{SE(\hat\beta_j)}\right) \\
P(\beta_j>b_j|y) &= P\left(T_{n-2}>\frac{\hat{\beta_j}-b_j}{SE(\hat\beta_j)}\right).
\end{array} \]
\nc\ec
\end{frame}




\subsection{\pvalue{}s and confidence intervals}
\begin{frame}
\frametitle{\pvalue{}s and confidence interval}

\small

\vspace{-0.1in}

We can construct a $100(1-a)\%$ two-sided confidence interval for $\beta_j$ via
\[ 
\hat{\beta}_j \pm t_{n-2,1-a/2} SE(\hat\beta_j).
\]

\vspace{0.1in} \pause

\bc
We can compute one-sided \pvalue{}s, \pause \\
e.g. $H_0:\beta_j\ge b_j$ vs $H_A: \beta_j < b_j$ has
\[ 
\mbox{\pvalue{}} = 
P\left(T_{n-2}>\frac{\hat{\beta_j}-b_j}{SE(\hat\beta_j)}\right) 
\]
\pause
and $H_0:\beta_j\le b_j$ vs $H_A: \beta_j > b_j$ has
\[
\mbox{\pvalue{}} = 
P\left(T_{n-2}<\frac{\hat{\beta_1}-b_j}{SE(\hat\beta_j)}\right)
\]
\pause
software default is usually $b_j = 0$.
\nc\ec
\end{frame}






\subsection{by hand}
\begin{frame}[fragile]
\frametitle{Calculations ``by hand'' in R}
\bc
<<hand_calculations, dependson="telomere_data", echo=TRUE>>=
n    = nrow(Telomeres)
Xbar = mean(Telomeres$years)
Ybar = mean(Telomeres$telomere.length)
s_X  = sd(Telomeres$years)
s_Y  = sd(Telomeres$telomere.length)
r_XY = cor(Telomeres$telomere.length, Telomeres$years)

SXX = (n-1)*s_X^2
SYY = (n-1)*s_Y^2
SXY = (n-1)*s_X*s_Y*r_XY

beta1 = SXY/SXX
beta0 = Ybar - beta1 * Xbar

R2  = r_XY^2
SSE = SYY*(1-R2)

sigma2 = SSE/(n-2)
sigma  = sqrt(sigma2)

SE_beta0 = sigma*sqrt(1/n + Xbar^2/((n-1)*s_X^2))
SE_beta1 = sigma*sqrt(           1/((n-1)*s_X^2))
@
\nc\ec
\end{frame}


\begin{frame}[fragile]
\frametitle{Calculations ``by hand'' in R (continued)}
\bc
<<pvalues_and_CIs, dependson="hand_calculations", echo=TRUE>>=
# 95% CI for beta0
beta0 + c(-1,1)*qt(.975, df = n-2) * SE_beta0

# 95% CI for beta1
beta1 + c(-1,1)*qt(.975, df = n-2) * SE_beta1

# pvalue for H0: beta0 >= 0 and P(beta0<0|y)
pt(beta0/SE_beta0, df = n-2)

# pvalue for H1: beta1 >= 0 and P(beta1<0|y)
pt(beta1/SE_beta1, df = n-2)
@
\nc\ec
\end{frame}







\begin{frame}[fragile]
\frametitle{Calculations by hand}
\tiny

\bc
\[ \begin{array}{rl}
SXX &
= (n-1) s_x^2
= (\Sexpr{n}-1)\times \Sexpr{s_X}^2
= \Sexpr{(n-1)*s_X^2} \\

SYY &
= (n-1) s_Y^2
= (\Sexpr{n}-1)\times \Sexpr{s_Y}^2
= \Sexpr{(n-1)*s_Y^2} \\

SXY &
= (n-1) s_X s_Y r_{XY}
= (\Sexpr{n}-1) \times \Sexpr{s_X} \times \Sexpr{s_Y} \times \Sexpr{r_XY}
= \Sexpr{(n-1)*s_X*s_Y*r_XY} \\

\hat{\beta}_1 &
= SXY/SXX
= \Sexpr{SXY}/\Sexpr{SXX}
= \Sexpr{beta1} \\

\hat{\beta}_0 &
= \overline{Y}-\hat{\beta}_1\overline{X}
= \Sexpr{Ybar} - (\Sexpr{beta1})\times \Sexpr{Xbar}
= \Sexpr{beta0} \\

R^2 &
= r_{XY}^2
= (\Sexpr{r_XY})^2
= \Sexpr{R2} \\

SSE &
= SYY(1-R^2)
= \Sexpr{SYY}(1-\Sexpr{R2})
= \Sexpr{SSE} \\

\hat{\sigma}^2 &
= SSE/(n-2)
= \Sexpr{SSE}/(\Sexpr{n}-2)
= \Sexpr{sigma2} \\

\hat{\sigma} &
= \sqrt{\hat{\sigma}^2}
= \sqrt{\Sexpr{sigma2}}
= \Sexpr{sigma} \\

SE(\hat{\beta}_0) &
= \hat{\sigma}\sqrt{\frac{1}{n} + \frac{\overline{X}^2}{(n-1)s_x^2}}
=  \Sexpr{sigma} \sqrt{\frac{1}{\Sexpr{n}}
  + \frac{\Sexpr{Xbar}^2}{(\Sexpr{n}-1)*\Sexpr{s_X}^2}}
= \Sexpr{SE_beta0} \\

SE(\hat{\beta}_1) &
= \hat{\sigma}\sqrt{\frac{1}{(n-1)s_x^2}}
=  \Sexpr{sigma} \sqrt{\frac{1}{(\Sexpr{n}-1)*\Sexpr{s_X}^2}}
= \Sexpr{SE_beta1} \\

p_{H_A:\beta_0\ne 0} &
= 2P\left(T_{n-2} < -\left| \frac{\hat\beta_0}{SE(\hat\beta_0)} \right|\right)
= 2P(t_{\Sexpr{n-2}} < \Sexpr{-abs(beta0/SE_beta0)})
= \Sexpr{2*pt(-abs(beta0/SE_beta0),n-2)} \\

p_{H_A:\beta_1\ne 0} &
= 2P\left(T_{n-2} < -\left| \frac{\hat\beta_1}{SE(\hat\beta_1)} \right|\right)
= 2P(t_{\Sexpr{n-2}} < \Sexpr{-abs(beta1/SE_beta1)})
= \Sexpr{2*pt(-abs(beta1/SE_beta1),n-2)} \\

CI_{95\%\, \beta_0} &
= \hat{\beta}_0 \pm t_{n-2,1-a/2} SE(\hat{\beta}_0) \\
&= \Sexpr{beta0} \pm \Sexpr{qt(.975,n-2)}\times  \Sexpr{SE_beta0}
= (\Sexpr{beta0 - qt(.975,n-2) * SE_beta0},
   \Sexpr{beta0 + qt(.975,n-2) * SE_beta0}) \\

CI_{95\%\, \beta_1} &
= \hat{\beta}_1 \pm t_{n-2,1-a/2} SE(\hat{\beta}_1) \\
&= \Sexpr{beta1} \pm \Sexpr{qt(.975,n-2)}\times  \Sexpr{SE_beta1}
= (\Sexpr{beta1 - qt(.975,n-2) * SE_beta1},
   \Sexpr{beta1 + qt(.975,n-2) * SE_beta1}) \\
\end{array} \]
\nc\ec
\end{frame}


\subsection{in R}
\begin{frame}[fragile]
\frametitle{Regression in R}

\vspace{-0.3in}

\bc
<<regression_in_r, dependson="telomere_data", echo=TRUE>>=
m = lm(telomere.length ~ years, Telomeres)
summary(m)
confint(m)
@
\nc\ec
\end{frame}





\subsection{Conclusion}
\begin{frame}
\frametitle{Conclusion}

Telomere ratio at the time of diagnosis of a child's chronic illness is estimated to be 1.37 with a 95\% credible interval of (1.25, 1.48). \pause For each year since diagnosis, the telomere ratio decreases \alert{on average} by 0.026 with a 95\% credible interval of (0.008, 0.045) . \pause The proportion of variability in telomere length described by a linear regression on years since diagnosis is 18.5\%. 

\vspace{0.2in} \pause

\bc
{\tiny \url{http://www.pnas.org/content/101/49/17312}}
\begin{quote}
The correlation between chronicity of caregiving and mean telomere length is $-0.445$ (P $<$0.01). [$R^2=0.198$ was shown in the plot.]
\end{quote}

\pause

{\tiny 
\begin{remark}
I'm guessing our analysis and that reported in the paper don't match exactly due to a discrepancy in the data.
\end{remark}
}
\nc\ec
\end{frame}



\subsection{Summary}
\frame{\frametitle{Summary}
\begin{itemize} \small
\item The \alert{simple linear regression} model is 
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_i, \sigma^2) \]
	where $Y_i$ and $X_i$ are the response and explanatory variable, respectively, 
	for individual $i$.

	\vspace{0.1in} \pause
	
\item Know how to use R to obtain $\hat{\beta}_0$, $\hat{\beta}_1$, 
$\hat{\sigma}^2$, $R^2$, \pvalue{}s, CIs, etc. \pause
\end{itemize}
	\bc
\begin{itemize} \small
\item Interpret regression output: \pause
	\begin{itemize} \scriptsize
	\item $\beta_0$ is the expected value for the response when the explanatory variable is 0.
	\item $\beta_1$ is the expected increase in the response for each unit increase in the explanatory variable.
	\item $\sigma$ is the standard deviation of responses around their mean.
	\item $R^2$ is the proportion of the total variation of the response variable explained by the model.
	\end{itemize}
\end{itemize}
\nc\ec
}



\end{document}



