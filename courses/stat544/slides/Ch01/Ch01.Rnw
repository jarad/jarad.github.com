\documentclass[handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

\input{../frontmatter}
\input{../commands}

\title{Probability and Inference}

\newenvironment{remark}[1][Remark]{\begin{trivlist}
\item[\hskip \labelsep {\bfseries #1}]}{\end{trivlist}}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE>>=
library("dplyr")
library("tidyr")
library("ggplot2")
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\begin{document}

\begin{frame}
\maketitle
\end{frame}


\begin{frame}
\frametitle{Outline}
\begin{itemize}
\item Quick review of probability
  \begin{itemize}
  \item Kolmogorov's axioms
  \item Bayes' Rule
  \item Application to Down's syndrome screening
  \end{itemize}
\item Bayesian statistics
  \begin{itemize}
  \item Condition on what is known
  \item Describe uncertainty using probability
  \item Exponential example
  \end{itemize}
\item What is probability?
  \begin{itemize}
  \item Frequency interpretation 
  \item Personal belief
  \end{itemize}
\item Why or why not Bayesian?
\end{itemize}
\end{frame}


\section{Quick review of probability}
\subsection{Set theory}

\begin{frame}
\frametitle{Events}
  \begin{definition}
  The set, $\Omega$, of all possible outcomes of a particular experiment is called the \alert{sample space} for the experiment.
	\end{definition} 
	
	\pause
	
	\begin{definition}
	An \alert{event} is any collection of possible outcomes of an experiment, that is, any subset of $\Omega$ (including $\Omega$ itself).
	\end{definition}
\end{frame}


\begin{frame}
\frametitle{Craps}
  \href{http://en.wikipedia.org/wiki/Craps}{Craps}: \pause
	\begin{itemize}[<+->]
	\item $\Omega=\{(1,1),(1,2),\ldots,(1,6),(2,1),(2,2),\ldots,(6,6)\}$ 
  \item Come-out roll win: the sum of the dice is 7 or 11
  \item Come-out roll loss: the sum of the dice is 2, 3, or 12
  \item Come-out roll establishes a point: the sum of the dice is 4, 5, 6, 8, 9, or 10 
  
  
  \vspace{0.1in}
  
	\item Events:
		\begin{itemize}
		\item the come-out roll wins  
		\item the come-out roll loses 
		\item the come-out roll establishes a point
		\end{itemize}
	\end{itemize}
\end{frame}


\frame{\frametitle{Pairwise disjoint}
	\begin{definition}
	Two events $A_1$ and $A_2$ are \alert{disjoint} (or \alert{mutually exclusive}) if both $A_1$ and $A_2$ cannot occur simultaneously, i.e. $A_i\cap A_j = \emptyset$. \pause The events $A_1, A_2,\ldots$ are \alert{pairwise disjoint} (or \alert{mutually exclusive}) if $A_i$ and $A_j$ cannot occur simultaneously for all $i\ne j$, i.e. $A_1\cap A_2 = \emptyset$. 
	\end{definition}
	
	\vspace{0.2in} \pause
	
	Craps pairwise disjoint examples:
	\begin{itemize}[<+->]
  \item Win ($A_1$), Loss ($A_2$)
  \item Win ($A_1$), Loss ($A_2$), Point ($A_3$)
  \item $A_1 = (1,1), A_2 = (1,2), \ldots, A_6 = (1,6), A_7 = (2,1), \ldots, A_{12} = (2,6), \ldots, A_{36} = (6,6)$
	\end{itemize}
}



\subsection{Axioms of probability}
\frame{\frametitle{Kolmogorov's axioms of probability}
  \begin{definition}
	Given a sample space $\Omega$ and event space $E$, a \alert{probability} is a function $P:E\to \mathbb{R}$ that satisfies \pause 
	\begin{enumerate}[1.]
	\item $P(A)\ge 0$ for any $A\in E$ \pause
	\item $P(\Omega)=1$ \pause
	\item If $A_1, A_2,\ldots\in E$ are pairwise disjoint, then $P(A_1\mbox{ or }A_2\mbox{ or }\ldots) = \sum_{i=1}^\infty P(A_i)$. 
	\end{enumerate}
	\end{definition}
}

\frame{\frametitle{Craps come-out roll probabilities}
The following table provides the probability mass function for the sum of the 
two dice if we \emph{believe} the probability of each elementary outcome is equal:
  
  \vspace{0.1in} \pause
  
{\small
  \begin{tabular}{l|ccccccccccc|c}
  Outcome & 2 & 3 & 4 & 5 & 6 & 7 & 8 & 9 & 10 & 11 & 12 & Sum \\
  \hline
  Combinations & 1 & 2 & 3 & 4 & 5 & 6 & 5 & 4 & 3 & 2 & 1 & 36 \pause \\
  Probability & $\frac{1}{36}$  & $\frac{2}{36}$  & $\frac{3}{36}$  & $\frac{4}{36}$  & $\frac{5}{36}$  & $\frac{6}{36}$  & $\frac{5}{36}$  & $\frac{4}{36}$  & $\frac{3}{36}$  & $\frac{2}{36}$  & $\frac{1}{36}$  & 1 \\[1.1ex]
  \hline
  \end{tabular}
}
  
  \vspace{0.2in} \pause
  
	Craps probability examples:
	\begin{itemize}[<+->]
	\item P(Win) = P(7 or 11) = 8/36 = 2/9
	\item P(Loss) = P(2, 3, or 12) = 4/36 = 1/9
  \item P(Point) = P(4, 5, 6, 8, 9 or 10) = 6/9
	\end{itemize}
}


\frame{\frametitle{Partition}
  \begin{definition}
  A set of events, $\{A_1,A_2,\ldots\}$, is a \alert{partition} of the sample space $\Omega$ \pause if and only if 
  \begin{itemize}[<+->]
  \item the events in $\{A_1,A_2,\ldots\}$ are pairwise disjoint and
  \item $\cup_{i=1}^\infty A_i = \Omega$.
  \end{itemize}
  \end{definition}
  
  \vspace{0.2in} \pause 
  
  Craps partition examples:
	\begin{itemize}[<+->]
  \item Win ($A_1$), Loss ($A_2$), Point ($A_3$)
  \item $A_1 = (1,1), A_2 = (1,2), \ldots, A_6 = (1,6), A_7 = (2,1), \ldots, A_{12} = (2,6), \ldots, A_{36} = (6,6)$
	\end{itemize}
}





\subsection{Conditional probability}
\frame{\frametitle{Conditional probability}
	\begin{definition}
	If $A$ and $B$ are events in $E$, and $P(B)>0$, \pause then the 
	\alert{conditional probability of A given B}, written $P(A|B)$, \pause is 
	\[ P(A|B) = \frac{P(A \mbox{ and } B)}{P(B)} \]
	\end{definition}
	
	\vspace{0.2in} \pause

  \begin{example}[Craps conditional probability]
	\[ P(7|\mbox{Win}) \pause
	= \frac{P(7\mbox{ and Win})}{P(\mbox{Win})} \pause
	= \frac{P(7)}{P(\mbox{Win})} \pause 
	= \frac{6/36}{8/36} \pause 
	= \frac{6}{8} \]
	\end{example}
}


\begin{frame}
\frametitle{Law of Total Probability}

\begin{corollary}[Law of Total Probability]
Let $A_1,A_2,\ldots$ be a partition of $\Omega$ and $B$ is another event in 
$\Omega$. \pause
The \alert{Law of Total Probability} states that 
\[ 
P(B) = \sum_{i=1}^\infty P(B\mbox{ and }A_i) \pause = \sum_{i=1}^\infty P(B|A_i)P(A_i).
\]
\end{corollary}

\pause

\begin{example}[Craps Win Probability]
Let $A_i$ be the event that the sum of two die rolls is $i$. 
\pause
Then 
\[ 
P(\mbox{Win}) \pause = \sum_{i=2}^{12} P(\mbox{Win} \mbox{ and }A_i) \pause 
 = P(7) + P(11) \pause 
 = \frac{6}{36} + \frac{2}{36} 
 = \frac{8}{36} 
 = \frac{2}{9}.
\]
\end{example}

\end{frame}



\subsection{Bayes' Rule}
\frame{\frametitle{Bayes' Rule}
	\begin{theorem}[Bayes' Rule]
	If $A$ and $B$ are events in $E$ with $P(B)>0$, \pause then \alert{Bayes' Rule} states
	\[ P(A|B) = \frac{P(B|A)P(A)}{P(B)}\onslide<7->{= \frac{P(B|A)P(A)}{P(B|A)P(A)+P(B|A^c)P(A^c)}} \]
	\end{theorem}
	
	\vspace{0.48in} \pause
	
	\begin{example}[Craps Bayes' Rule]
	\[ P(7|\mbox{Win}) 
	\pause = \frac{P(\mbox{Win}|7)P(7)}{P(\mbox{Win})} \pause
	= \frac{1\cdot P(7)}{P(\mbox{Win})} \pause 
	= \frac{6/36}{8/36} = \frac{6}{8} \]
	\end{example}
}



\subsection{Application to Down Syndrome screening}
\frame{\frametitle{Down Syndrome screening}
    If a pregnant woman has a test for Down syndrome and it is positive, what is the probability that the child will have Down syndrome? \pause Let $D$ indicate a child with Down syndrome and $D^c$ the opposite. \pause Let `+' indicate a positive test result and $-$ a negative result.

    \vspace{0.1in} \pause

    \[ \begin{array}{rl}
    \mbox{sensitivity} &= P(+|D) \hspace{0.06in}= 0.94 \pause \\
    \mbox{specificity} &= P(-|D^c) = 0.77 \pause \\
    \mbox{prevalence} & = P(D)\hspace{0.23in} = 1/1000 \pause \\
    \\ \\
    P(D|+) &= \frac{P(+|D)P(D)}{P(+)} \pause = \frac{P(+|D)P(D)}{P(+|D)P(D)+P(+|D^c)P(D^c)} \pause
    = \frac{0.94\cdot 0.001}{0.94\cdot 0.001+0.23\cdot 0.999} \pause \\
    &\approx 1/250 \pause \\ \\
    P(D|-) &\approx 1/10,000 
    \end{array} \]
}



\section{Bayesian statistics}
\begin{frame}
\frametitle{A Bayesian statistician}

Let 
\begin{itemize}[<+->]
\item $y$ be the data we will collect from an experiment, 
\item $K$ be everything we know for certain about the world (aside from $y$), and
\item $\theta$ be anything we don't know for certain.
\end{itemize}

\vspace{0.2in} \pause

My definition of a Bayesian statistician is an individual who makes decisions based on the probability distribution of those things we don't know conditional on what we know, \pause i.e. 
\[ p(\theta|y, K). \]
\end{frame}


\begin{frame}
\frametitle{Bayesian statistics (with explicit conditioning)}
{\small
\begin{itemize}[<+->]
\item Parameter estimation:
\[ p(\theta|y,M) \]
where $M$ is a model with parameter (vector) $\theta$ and $y$ is data assumed to come from model $M$ with true parameter $\theta_0$. 
\item Hypothesis testing/model comparison:
\[ p(M_j|y,\mathcal{M}) \]
where $\mathcal{M}$ is a set of models with $M_j \in \mathcal{M}$ for $i=1,2,\ldots$ and $y$ is data assumed to come from some model $M_0\in\mathcal{M}$. 
\item Prediction:
\[ p(\tilde{y}|y,M) \]
where $\tilde{y}$ is unobserved data and $y$ and $\tilde{y}$ are both assumed to come from $M$. \pause Alternatively, 
\[ p(\tilde{y}|y,\mathcal{M}) \]
where $y$ and $\tilde{y}$ are both assumed to come from some $M_0\in\mathcal{M}$.
\end{itemize}
}
\end{frame}




\begin{frame}
\frametitle{Bayesian statistics (with implicit conditioning)}
{\small
\begin{itemize}
\item Parameter estimation:
\[ p(\theta|y) \]
where $\theta$ is the unknown parameter (vector) and $y$ is the data. 
\item Hypothesis testing/model comparison:
\[ p(M_j|y) \]
where $M_j$ is one of a set of models under consideration and $y$ is data assumed to come from one of those models. 
\item Prediction:
\[ p(\tilde{y}|y) \]
where $\tilde{y}$ is unobserved data and $y$ and $\tilde{y}$ are both assumed to come from the same (set of) model(s). 
\end{itemize}
}
\end{frame}





\begin{frame}
\frametitle{Bayes' Rule}

Bayes' Rule applied to a partition $P=\{A_1,A_2,\ldots\}$, 
\[ P(A_i|B) = \frac{P(B|A_i)P(A_i)}{P(B)} = \frac{P(B|A_i)P(A_i)}{\sum_{i=1}^\infty P(B|A_i)P(A_i)} \]

\vspace{0.2in} \pause

Bayes' Rule also applies to probability density (or mass) functions, e.g. 
\[ p(\theta|y) =\frac{p(y|\theta)p(\theta)}{p(y)} = \frac{p(y|\theta)p(\theta)}{\int p(y|\theta)p(\theta) d\theta}  \]
where the integral plays the role of the sum in the previous statement.
\end{frame}




\subsection{Parameter estimation}
\begin{frame}
\frametitle{Parameter estimation}
Let $y$ be data from some model with unknown parameter $\theta$. \pause Then
\[ p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)}= \frac{p(y|\theta)p(\theta)}{\int p(y|\theta)p(\theta) d\theta} \]
\pause and we use the following terminology 
\begin{center}
\begin{tabular}{ll}
Terminology & Notation \\
\hline 
Posterior & $p(\theta|y)$ \\
Prior & $p(\theta)$ \\
Model & $p(y|\theta)$ \\
Prior predictive distribution & $p(y)$ \\
(marginal likelihood) & \\
\hline
\end{tabular}
\end{center}

\vspace{0.1in} \pause

If $\theta$ is discrete (continuous), 

\hspace{0.2in} then $p(\theta)$ and $p(\theta|y)$ are probability mass (density) functions.

\pause

If $y$ is discrete (continuous), 

\hspace{0.2in}  then $p(y|\theta)$ and $p(y)$ are probability mass (density) functions.
\end{frame}





\subsection{Example: exponential model}
\begin{frame}
\frametitle{Example: exponential model}
Let $Y|\theta\sim Exp(\theta)$, then this defines the likelihood, \pause i.e. 
\[ p(y|\theta) = \theta e^{-\theta y}. \]
\pause
Let's assume a convenient prior $\theta \sim Ga(a, b)$, \pause then 
\[ p(\theta) = \frac{b^{a}}{\mathrm{\Gamma}(a)} \theta^{a-1} e^{-b \theta}. \]
\pause 
The prior predictive distribution is 
\[ p(y) = \int p(y|\theta)p(\theta) d\theta = \frac{b^{a}}{\mathrm{\Gamma}(a)}\frac{\mathrm{\Gamma}(a+1)}{(b+y)^{a+1}}. \]
\pause 
The posterior is 
\[ p(\theta|y) = \frac{p(y|\theta)p(\theta)}{p(y)} = \frac{(b+y)^{a+1}}{\mathrm{\Gamma}(a+1)} \theta^{a+1-1} e^{-(b+y) \theta}, \]
\pause
thus $\theta|y \sim Ga(a+1,b+y)$. 
\end{frame}

\begin{frame}[fragile]
\frametitle{}

<<echo=TRUE>>=
a = 1; b = 1; y = 0.5
@

<<>>=
d = data.frame(x = seq(0,3,by=0.1)) %>% 
  mutate(prior = dgamma(x,a,b),
         "normalized likelihood" = dgamma(x, 1, y),
         posterior = dgamma(x, a+length(y), b+sum(y)))

m <- d %>% gather(Distribution, density, -x)

ggplot(m, aes(x, density, group = Distribution, linetype = Distribution, color= Distribution)) +
  geom_line() +
  theme_bw()
@
\end{frame}

% Consider eliminating this as well as the more data example
\begin{frame}
\frametitle{A shortcut}
If 
\[ p(y) = \int p(y|\theta)p(\theta) d\theta < \infty, \]
\pause 
then we can actually use the following to find the posterior
\[ p(\theta|y) \propto p(y|\theta) p(\theta) \]
\pause
where the $\propto$ signifies that terms not involving $\theta$ (or anything on the left of the conditioning bar) are irrelevant and can be dropped. 

\vspace{0.2in} \pause

In the exponential example
\[ 
p(\theta|y) 
\propto p(y|\theta)p(\theta) 
\propto \theta e^{-\theta y} \theta^{a-1} e^{-b \theta} 
= \theta^{a+1-1} e^{-(b+y)\theta} 
\]
\pause 
where we can recognize $p(\theta|y)$ as the \alert{kernel} of a $Ga(a+1, b+y)$ distribution \pause and thus $\theta|y \sim Ga(a+1, b+y)$ and $p(y)<\infty$. 
\end{frame}


\begin{frame}
\frametitle{Independent data}

Suppose $Y_i|\theta \stackrel{ind}{\sim} Exp(\theta)$ for $i=1,\ldots,n$ and $y=(y_1,\ldots,y_n)$, then 
\[ p(y|\theta) = \prod_{i=1}^n p(y_i|\theta) = \theta^n e^{-\theta n\overline{y}} \]
\pause
Then 
\[ p(\theta|y) \propto p(y|\theta)p(\theta) \propto \theta^{a+n-1} e^{-\left(b+n\overline{y}\right) \theta}\]
\vspace{0.1in} \pause
where $n\overline{y} = \sum_{i=1}^n y_i$. We recognize this as the kernel of a gamma, i.e. $\theta|y \sim Ga(a+n, b+n\overline{y})$. 

\end{frame}


\begin{frame}[fragile]
\frametitle{}

<<echo=TRUE>>=
a = 1; b = 1; set.seed(20141121); y = rexp(10, 2)
@

<<>>=
d = data.frame(x = seq(0,5,by=0.1)) %>% 
  mutate(prior = dgamma(x,a,b),
         "normalized likelihood" = dgamma(x, length(y), sum(y)),
         posterior = dgamma(x, a+length(y), b+sum(y)))

m <- d %>% gather(Distribution, density, -x)

ggplot(m, aes(x, density, group = Distribution, linetype = Distribution, color= Distribution)) +
  geom_line() +
  theme_bw()
@
\end{frame}



\begin{frame}
\frametitle{Bayesian learning (in parameter estimation)}
% Update slide
So, Bayes' Rule provides a formula for updating from prior beliefs to our posterior beliefs based on the data we observe, \pause i.e.

\[ p(\theta|y) = \frac{p(y|\theta)}{p(y)}p(\theta) \propto p(y|\theta)p(\theta) \]

\pause Suppose we gather $y_1,\ldots,y_n$ sequentially (and we assume $y_i$ independent conditional on $\theta$), \pause then we have 

\[ \begin{array}{rl}
p(\theta|y_1) & \propto p(y_1|\theta)p(\theta) \pause \\
p(\theta|y_1,y_2) & \propto p(y_2|\theta)p(\theta|y_1) 
\end{array} \]
\pause 
and 
\[ p(\theta|y_1,\ldots,y_i) \propto p(y_i|\theta)p(\theta|y_1,\ldots,y_{i-1}) \]

\pause
So Bayesian learning is 
\[ p(\theta) \to p(\theta|y_1) \to p(\theta|y_1,y_2) \to \cdots \to p(\theta|y_1,\ldots,y_n). \]
\end{frame}


\subsection{Model comparison}
\begin{frame}
\frametitle{Model comparison}

Formally, to compare models (or average over models), we use
\[ p(M_j|y) \propto p(y|M_j)p(M_j) \]
\pause where 
\begin{itemize}[<+->]
\item $p(y|M_j)$ is the likelihood of the data when model $M_j$ is true
\item $p(M_j)$ is the prior probabability for model $M_j$ 
\item $p(M_j|y)$ is the posterior probability for model $M_j$
\end{itemize}

\vspace{0.2in} \pause

Thus, a Bayesian approach provides a natural way to learn about models, i.e. $p(M_j) \to p(M_j|y)$.

\end{frame}



\subsection{Prediction}
\begin{frame}
\frametitle{Prediction}

Let $y$ be observed data and $\tilde{y}$ be unobserved data from a model with parameter $\theta$
\pause
where $\tilde{y}$ is conditionally independent of $y$ given $\theta$ 
\pause
(true for many of the models we will discuss this semester)
\pause
, then 
\[ \begin{array}{rl}
p(\tilde{y}|y) 
&= \int p(\tilde{y},\theta|y) d\theta \pause \\
&= \int p(\tilde{y}|\theta,y) p(\theta|y) d\theta \pause \\
&= \int p(\tilde{y}|\theta) p(\theta|y) d\theta 
\end{array} \]
\pause where $p(\theta|y)$ is the posterior we obtained using Bayesian parameter estimation techniques.
\end{frame}


\begin{frame}
\frametitle{Example: exponential distribution}

From previous, let $y_i \stackrel{ind}{\sim} Exp(\theta)$ and $\theta \sim Ga(a,b)$, then $\theta|y \sim Ga(a+n,b+n\overline{y})$. \pause Suppose we are interested in predicting a new value $\tilde{y}\sim Exp(\theta)$ \pause (conditionally independent of $y=(y_1,\ldots,y_n)$ given $\theta$). \pause Then we have 

\[ \begin{array}{rl}
p(\tilde{y}|y) 
&= \int p(\tilde{y}|\theta) p(\theta|y) d\theta \pause \\
&= \int \theta e^{-\theta\tilde{y}} \frac{(b+n\overline{y})^{a+n}}{\mathrm{\Gamma}(a+1)} \theta^{a+n-1} e^{-\theta (b+n\overline{y})} d\theta \pause \\
&= \frac{(b+n\overline{y})^{a+n}}{\mathrm{\Gamma}(a+n)} \int \theta^{a+n+1-1} e^{-\theta (b+n\overline{y}+\tilde{y})} d\theta \pause \\
&= \frac{(b+n\overline{y})^{a+n}}{\mathrm{\Gamma}(a+n)} \frac{\mathrm{\Gamma}(a+n+1)}{(b+n\overline{y}+\tilde{y})^{a+n+1}} \pause \\
&= \frac{(a+n)(b+n\overline{y})^{a+n}}{(\tilde{y}+b+n\overline{y})^{a+n+1}}
\end{array} \]
This is the \href{http://en.wikipedia.org/wiki/Lomax_distribution}{Lomax distribution} for $\tilde{y}$ with parameters $a+n$ and $b+n\overline{y}$.

\end{frame}



\section{What is probability?}
\begin{frame}
\frametitle{What is probability?}

\pause 

Consider the following three typical uses of the word ``probability'':
\begin{itemize}[<+->]
\item What is the probability I will win on the come-out roll in craps?
\item What is the probability my unborn child has Down's syndrome given that they tested positive in an initial screening?
\item What is the probability the Green Bay Packers will win this year's superbowl?
\end{itemize}
\end{frame}


\subsection{Frequency interpretation}
\begin{frame}
\frametitle{Win on the come-out roll in craps}

To win on the come-out roll in craps requires that the sum of two fair six-sided die is either a 7 or an 11. \pause We calculated this probability earlier (based on equal probabilities of all simple outcomes) to be 2/9. \pause We likely meant that if we were to repeatedly roll the die, the long term proportion of wins (7s and 11s) would be 2/9\pause, i.e. 
\[ \mbox{if }X_i = \left\{ 
\begin{array}{ll} 1 & \mbox{if win on roll $i$} \\ 0 & \mbox{otherwise} \end{array} 
\right.
\pause\quad\mbox{then}\quad \lim_{n\to\infty} \frac{\sum_{i=1}^n X_i}{n} \to \frac{2}{9}.
\]

\begin{definition}
The \alert{frequency} interpretation of probability is based on the relative frequency of an event (assumed to be performed in an identical manner).
\end{definition}
\end{frame}

\begin{frame}
\frametitle{Win on the come-out roll in craps}

\begin{definition}
The \alert{frequency} interpretation of probability is based on the relative frequency of an event (assumed to be performed in an identical manner).
\end{definition}

\vspace{0.2in} \pause

Two problems with this frequency interpretation: \pause
\begin{itemize}
\item You cannot possibly throw the dice in an identical manner. \pause
\item If I knew enough physics, I could model each throw \pause and tell you exactly what the result would be\pause, i.e. the only randomness is because the throws are not identical.
\end{itemize}
\end{frame}


\begin{frame}
\frametitle{Down's syndrome}

What is the probability my unborn child has Down's syndrome given that they tested positive in an initial screening?

\vspace{0.2in} \pause

Here the frequency interpretation makes no sense for two reasons:\pause
\begin{itemize}
\item There is only one child and thus no repeat of the experiment.
\item There is no randomness: either the child has Down's syndrome or does not.
\end{itemize}

\vspace{0.2in} \pause

Instead, we only have our own uncertainty about whether the child has Down's syndrome.
\end{frame}




\begin{frame}
\frametitle{Down's syndrome}

Also, why are we only conditioning on the positive test result, shouldn't we condition on everything else that is important, e.g. age. \pause Then the probability we care about is 

\[ P(D|+,\mbox{mother is 33}) = \frac{P(+|D,\mbox{mother is 33})P(D|\mbox{mother is 33})}{P(+|\mbox{mother is 33})}\]
Now the specificity, sensitivity, and prevalence are all the relative frequency of the event for this subpopulation.

\vspace{0.2in} \pause

But what about other measured variables, e.g. Caucasian, lives in MN, of Scandanavian descent, etc. \pause Taken to its logical extreme, each probability becomes a statement about one single event\pause, e.g. for this individual. 

\end{frame}



\begin{frame}
\frametitle{Superbowl Champions}

What is the probability the Green Bay Packers win the Superbowl?

\vspace{0.2in} \pause

By similar arguments:
\begin{itemize}
\item There is only one Superbowl this year and only one Green Bay Packers. \pause
\item Is the world random? \pause i.e. do we have free will? \pause If not, then (with enough time, computing power, money, etc) we could model the world and know what the result will be. \pause If yes, is there an objective probability that we could be estimating?
\end{itemize}

\end{frame}



\subsection{Personal belief}
\begin{frame}
\frametitle{Personal belief}

\begin{definition}
A \alert{subjective probability} describes an individual's personal judgement about how likely a particular event is to occur.
\end{definition}
{\tiny \url{http://www.stats.gla.ac.uk/glossary/?q=node/488}}

\vspace{0.2in} \pause

\begin{remark}
Coherence of bets. The probability $p$ you assign to an event $E$ is the fraction at which you would exchange $p$ for a return of 1 if $E$ occurs.
\end{remark}

\vspace{0.2in} \pause

Rational individuals can differ about the probability of an event by having different knowledge, i.e. $P(E|K_1) \ne P(E|K_2)$. \pause But given enough data, we might have $P(E|K_1,y) \approx P(E|K_2,y)$. 

\end{frame}



\begin{frame}
\frametitle{Personal belief}

Using a personal belief definition of probability, it is easy to reconcile the use of probability in common language:

{\tiny
\begin{itemize}[<+->]
\item What is the probability I will win on the come-out roll in craps?
\item What is the probability my unborn child has Down's syndrome given that they tested positive in an initial screening?
\item What is the probability the Green Bay Packers will win this year's superbowl?
\item What is the probability that global climate change is primarily driven by human activity?
\item What is the probability the Higgs Boson exists?
\end{itemize}
}

\vspace{0.2in} \pause

and in the mathematical notation:
\begin{itemize}[<+->]
\item $p(\theta) \to p(\theta|y)$
\item $p(H_1) \to p(H_1|y)$
\item $p(\tilde{y}|y)$
\end{itemize}

\end{frame}





\section{Why or why not Bayesian?}
\begin{frame}
\frametitle{Why or why not Bayesian?}

Why do a Bayesian analysis?
\begin{itemize}[<+->]
\item Incorporate prior knowledge via $p(\theta)$
\item Coherent, i.e. everything follows from specifying $p(\theta|y)$
\item Interpretability of results, e.g. the probability the parameter is in 
$(L,U)$ is 95\%
\end{itemize}

\vspace{0.2in} \pause

Why not do a Bayesian analysis?
\begin{itemize}[<+->]
\item Need to specify $p(\theta)$ 
\item Computational cost
\item Does not guarantee coverage, i.e. how well do the procedures work over all 
their uses (although \emph{frequentist matching} priors are specifically 
designed to ensure frequentist properties, e.g. coverage)
\end{itemize}
\end{frame}

\end{document}
