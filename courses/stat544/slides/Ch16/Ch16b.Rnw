\documentclass[handout]{beamer}

\input{../frontmatter}
\input{../commands}

\title{Generalized linear mixed effects model}
\subtitle{Sow culling time}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=5, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE>>=
library(reshape2)
library(plyr)
library(dplyr)
library(ggplot2)
library(xtable)
library(rstan)
library(mcmcse)
library(coda)
@

<<set_seed>>=
set.seed(2)
@

\frame{\maketitle}


\begin{frame}
\frametitle{Outline}

\begin{itemize}
\item Mixed effect Poisson regression
  \begin{itemize}
  \item Modeling
  \item Estimation via Stan
  \item Posterior
  \end{itemize}
\item Decision making
  \begin{itemize}
  \item Maximize utility
  \end{itemize}
\end{itemize}

\end{frame}

% Probably should model both the dam and sire (which are the granddam and grandsire for the litter)

\section{Sow culling time}
\frame{\frametitle{Sow culling time}
From Caitlyn Abell:
\begin{quote}
I have attached the data file with 2,868 records from one farm. The
contemporary group (cg) is farm, year and season. There are
columns for number born alive (nba), number born dead (nbd), and
parity.  One thing you could look at would be improvement over time or differences of performance between the
parities [litters]. I think determining the optimal culling time for a sow given her past
history would be interesting. 
\end{quote}

\vspace{0.2in} \pause

Primary question of interest: when should a sow be removed from breeding?
}


\begin{frame}[fragile]
<<data, cache=TRUE, echo=TRUE>>=
d = read.table("Ch16b-farm62.txt", header=T)
d$cg = d$farm = d$yearmo = d$nbd = d$dam = NULL
d = plyr::rename(d, c("sire"="grandsire")) |>
  mutate(sowid = factor(sowid), grandsire = factor(grandsire))
@

<<data_summary, dependson="data", echo=TRUE>>=
head(d)
summary(d)
dim(d); nlevels(d$sowid); nlevels(d$grandsire)
@
\end{frame}


\begin{frame}[fragile]
<<exploratory, dependson="data">>=
summary(factor(d$parity))
ggplot(d, aes(x=nba,y=after_stat(density))) +
  geom_histogram(binwidth=1) + 
  facet_wrap(~parity, scales='free_y')
@
\end{frame}




\frame{\frametitle{Model}
Let $y_i$ be the number born alive for the $i^{th}$ litter. \pause Assume
\[ \begin{array}{ll@{\qquad}l}
y_i &\stackrel{ind}{\sim} Po( e^{\mu_i} ) & i=1,\ldots,n \pause \\
\mu_i &= \rho_{p[i]} + \alpha_{s[i]} + \beta_{g[i]} \pause \\
\end{array} \]
where
\begin{itemize}
\item $p[i]$ is the parity for the $i^{th}$ litter, \pause
\item $s[i]$ is the sow for the $i^{th}$ litter, \pause and
\item $g[i]$ is the grandsire for the $i^{th}$ litter. \pause
\end{itemize}  
The hierarchical structure treats $\alpha$ and $\beta$ as random effects, i.e.
\[ \begin{array}{ll@{\qquad}l}
\alpha_s &\stackrel{iid}{\sim} N(0, \sigma^2_\alpha) & s=1,\ldots,n_{sows} \pause \\
\beta_g &\stackrel{iid}{\sim} N(0, \sigma^2_\beta) & g=1,\ldots,n_{grandsires}. \pause
\end{array} \]
The prior is 
\[ p(\rho_1,\ldots,\rho_6, \sigma_\alpha,\sigma_\beta) \propto Ca^+(\sigma_\alpha;0,1) Ca^+(\sigma_\beta;0,1) \]
}



\begin{frame}[fragile]
<<model, tidy=FALSE, echo=TRUE>>=
model = "
data {
  int<lower=1> n;
  int<lower=1> np;
  int<lower=1> ns;
  int<lower=1> ng;
  int<lower=0> y[n];
  int<lower=1, upper=np> parity[n];
  int<lower=1, upper=ns> sow[n];
  int<lower=1, upper=ng> grandsire[n];
}

parameters {
  real rho[np];     // implicit prior over whole real line
  real alpha[ns];
  real beta[ng];
  real<lower=0> sigma_alpha;
  real<lower=0> sigma_beta;
}

model {
  for (i in 1:n) {
    y[i] ~ poisson(exp(rho[parity[i]]+alpha[sow[i]]+beta[grandsire[i]]));
  }

  // Random effects
  alpha ~ normal(0, sigma_alpha);
  beta ~ normal(0, sigma_beta);

  sigma_alpha ~ cauchy(0,1);
  sigma_beta  ~ cauchy(0,1);
}"
@
\end{frame}

<<compile_model, cache=TRUE, message=FALSE, dependson="model">>=
m <- stan_model(model_code = model)
@

\begin{frame}[fragile]
<<run_mcmc, dependson=c("data","compile_model"), cache=TRUE, echo=TRUE>>=
d = d[d$parity!=7,]
dat = list(y = d$nba, 
           parity = d$parity,
           sow = as.numeric(d$sowid),
           grandsire = as.numeric(d$grandsire))
dat$n  = length(dat$y)
dat$np = max(dat$parity)
dat$ns = max(dat$sow)
dat$ng = max(dat$grandsire)

time = system.time(r <- sampling(object = m, 
                                 data = dat, 
                                 pars = c("rho","alpha","beta","sigma_alpha","sigma_beta"), 
                                 iter = 10000,
                                 thin = 5))
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Run time and summary}
<<stan_summary, cache=TRUE, dependson="run_mcmc", echo=TRUE>>=
time
s = summary(r)$summary
@

<<dependson="stan_summary", eval=FALSE>>=
summary(r, pars=c("rho","sigma_alpha","sigma_beta","lp__"))$summary
@

\end{frame}



\begin{frame}[fragile]
<<dependson='run_mcmc'>>=
plot(r)
@
\end{frame}



\begin{frame}[fragile]
<<parity, dependson="stan_summary">>=
wr = grep("rho",rownames(s))
erho = exp(s[wr,c(4,6,8)])

plot(wr, 1:dat$np, xlim=range(erho[wr,]), ylim=c(0,dat$np+1), ylab="Parity", 
     xlab="Expected number born alive", type="n")
segments(erho[wr,1], 1:dat$np, erho[wr,3], 1:dat$np)
points(erho[wr,2],1:dat$np, pch=19, cex=.5)
@
\end{frame}


\begin{frame}[fragile]
<<sow, dependson="stan_summary", cache=TRUE>>=
wd = grep("alpha\\[",rownames(s))
alpha = as.data.frame(s[wd,c(4,6,8)])

names(alpha) = c("lb","median","ub")
alpha$sowid = levels(d$sowid)

sow_max_parity = ddply(d, .(sowid), summarize, parity=max(parity))

alpha_plot = merge(alpha, sow_max_parity)

# ggplot(merge(alpha,sow_max_parity), 
#        aes(x=sowid, y=median, ymin=lb, ymax=ub)) +
#   geom_pointrange() + 
#   facet_wrap(~parity, scales='free_x') 

ordr = order(alpha_plot$median)
alpha_plot = alpha_plot[ordr,]

opar = par(mfrow=c(2,3))
for (i in 1:6) {
  tmp = alpha_plot[alpha_plot$parity==i,]
  n.dam = nrow(tmp)
  plot(tmp$median, 1:n.dam, 
       xlim=range(alpha_plot$lb, alpha_plot$ub), 
       ylim=c(0,n.dam+1), 
       ylab="Ordered dams", 
       xlab="Effect (log-scale)",
       main=paste("Max parity",i),
       type="n", yaxt='n')
  abline(v=c(-.1,.1), lty=2)
  segments(tmp$lb, 1:n.dam, tmp$ub, 1:n.dam, col="gray")
  lines(tmp$median, 1:n.dam)
}
par(opar)
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Best and worst performing sows with max parity 4 and 5}

NBA for best and worst performing sows with max parity of 4

<<dependson='sow'>>=
tmp = alpha_plot[alpha_plot$parity==4,]
sows = tmp$sowid[c(which.min(tmp$median), which.max(tmp$median))]
dcast(d[d$sowid %in% sows,c("sowid","nba","parity")], sowid~parity, value.var='nba')
@


\vspace{0.2in} \pause

NBA for best and worst performing sows with max parity of 5

<<dependson='sow'>>=
tmp = alpha_plot[alpha_plot$parity==5,]
sows = tmp$sowid[c(which.min(tmp$median), which.max(tmp$median))]
dcast(d[d$sowid %in% sows,c("sowid","nba","parity")], sowid~parity, value.var='nba')
@


\end{frame}


\begin{frame}[fragile]
<<sire, dependson="stan_summary">>=
ws = grep("beta",rownames(s))
beta = s[ws,c(4,6,8)]
n.sire = nrow(beta)
ordr = order(beta[,2])
beta = beta[ordr,]

plot(beta[,2], 1:n.sire, xlim=range(beta), ylim=c(0,n.sire+1), ylab="Grandsire (ordered by posterior median)", 
     xlab="Effect (log-scale)",type="n")
segments(beta[,1], 1:n.sire, beta[,3], 1:n.sire, col="gray")
lines(beta[,2], 1:n.sire)
@
\end{frame}



\begin{frame}[fragile]
<<standard_deviations, dependson="run_mcmc", cache=TRUE>>=
sigmas = extract(r, c("sigma_alpha","sigma_beta"))
par(mfrow=c(1,2))
hist(sigmas$sigma_alpha, prob=TRUE, xlim=c(0,0.1), 
     main="Sow sd")
curve(dcauchy(x,0,10)/2, col='red', add=TRUE, lwd=2)
hist(sigmas$sigma_beta,  prob=TRUE, xlim=c(0,0.1), 
     main="Grandsire sd")
curve(dcauchy(x,0,10)/2, col='red', add=TRUE, lwd=2)
@
\end{frame}





\subsection{Culling time}
\frame{\frametitle{Culling time}
Primary question of interest: when should a sow be removed from breeding?	

\vspace{0.2in} \pause

Who is expected to have more progeny: \pause
\begin{itemize}
\item a current sow $s$ \pause
\item a new sow
\end{itemize}

\pause

{\small
Current sow (for progeny $p$ and grandsire $g$):
\[ \begin{array}{rl}
E[\tilde{y}_s|y] &= E\large[E[\tilde{y}_s|\rho,\alpha,\beta]|y \large] \pause \\
&= E\left[ \left. e^{\rho_p+\alpha_s+\beta_g}\right|y\right] \pause \\
&\approx \frac{1}{K} \sum_{k=1}^K e^{\rho_p^{(k)}+\alpha_s^{(k)}+\beta_g^{(k)}}
\end{array} \]
\pause New sow (for progeny 1 and random grandsire):
\[ \begin{array}{rl}
E[\tilde{y}_{new}|y] &= \approx \frac{1}{K} \sum_{k=1}^K e^{\rho_1^{(k)}+\alpha_{new}^{(k)}+\beta_{new}^{(k)}}
\end{array} \]
where $\alpha_{new}^{(k)} \sim N(0,[\sigma_{\alpha}^{(k)}]^2)$ and $\beta_{new}^{(k)} \sim N(0,[\sigma_{\beta}^{(k)}]^2)$.
}
}

\frame{\frametitle{Simulated answer}
For MCMC iterations $k=1,\ldots,K$, \pause 
\begin{enumerate}
\item Obtain the $k^{th}$ \emph{joint draw} from the posterior for $\rho_p^{(k)}$, $\rho_1^{(k)}$, $\alpha_s^{(k)}$, $\beta_g^{(k)}$, $\sigma^{(k)}_\alpha$, and $\sigma^{(k)}_\beta$. 
\item Calculate $\mu^{(k)}_{d} = e^{\rho_p^{(k)}+\alpha_s^{(k)}+\beta_g^{(k)}}$. \pause 
\item Calculate $\mu^{(k)}_{new} = e^{\rho_p^{(k)}+\alpha_{new}^{(k)}+\beta_{new}^{(k)}}$ where 
  \begin{enumerate}
  \item $\alpha_{new}^{(k)} \sim N\left(0,\left[\sigma_{\alpha}^{(k)}\right]^2\right)$ and
  \item $\beta_{new}^{(k)} \sim N\left(0,\left[\sigma_{\beta}^{(k)}\right]^2\right)$.
  \end{enumerate} \pause 
\item Calculate $\delta^{(k)} = \mu_{new}^{(k)} - \mu_s^{(k)}$.
\end{enumerate}

\vspace{0.2in} \pause

So $\delta^{(k)}$ is a realization of the expected difference in the number of progeny between a new sow and current sow $d$.
}



\begin{frame}[fragile]
<<zero_nba, dependson="run_mcmc", echo=TRUE>>=
sow_summary = ddply(d, .(sowid), summarize, 
                    max_parity = max(parity),
                    sum_nba    = sum(nba),
                    mean_nba   = sum_nba/max_parity)

# Find a sow with 0 born alive in parity 1 (and no other data)
sow = which(sow_summary$max_parity==1 & sow_summary$sum_nba==0)[1]
grandsire = as.numeric(d$sire[d$sowid==sow_summary$sowid[sow]]); grandsire = 2 # no idea why

# Expected nba in parity 2 for sow with 0 born alive in first parity
alphas <- extract(r, "alpha")$alpha
betas  <- extract(r, "beta")$beta
rhos   <- extract(r, "rho")$rho
exp_nba_old2 <- exp(rhos[, 2] + alphas[, sow] + betas[, grandsire])

# Expected nba in parity 1 for random sow
alpha_new   <- rnorm(nrow(rhos), 0, sigmas$sigma_alpha)
beta_new    <- rnorm(nrow(rhos), 0, sigmas$sigma_beta)
exp_nba_new <- exp(rhos[, 1] + alpha_new + beta_new)
@
\end{frame}


\begin{frame}[fragile]
<<zero_nba_run, dependson="zero_nba", echo=TRUE>>=
hist(exp_nba_new - exp_nba_old2, 100, main=expression(paste(delta," (new-old)")))
@
\end{frame}



\begin{frame}[fragile]
<<parity_four, dependson="run_mcmc", fig.width=8, echo=TRUE>>=
# Replace sow with 23 born alive after 4 parities?
sow = which(sow_summary$max_parity==4 & sow_summary$sum_nba==23)[1]
grandsire = as.numeric(d$sire[d$sowid==sow_summary$sowid[sow]]); grandsire = 2 # no idea why

# Expected nba in parity 3 for sow with 0 born alive in first parity
exp_nba_old5 = exp(rhos[,5]+alphas[,sow]+betas[,grandsire])

# Difference in expected nba
hist(exp_nba_new-exp_nba_old5, 100, main=expression(paste(delta," (new-old)")))
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Estimated number born alive}

Estimates of the number born alive for each sow with Monte Carlo uncertainty:

<<est_nba, dependson=c("zero_nba","parity_four")>>=
exp_nba = data.frame(new = exp_nba_new, old2 = exp_nba_old2, old5 = exp_nba_old5)
ddply(melt(exp_nba), .(variable), function(x) as.data.frame(mcse(x$value)))
@

\pause

Estimates of the expected difference with Monte Carlo uncertainty:

<<difference_expected progeny, dependson=c("zero_nba","parity_four"), echo=TRUE>>=
delta = rbind(as.data.frame(mcse(exp_nba_old2-exp_nba_new)),
              as.data.frame(mcse(exp_nba_old5-exp_nba_new)),
              as.data.frame(mcse(exp_nba_old5-exp_nba_old2)))
rownames(delta) = c("parity2-new","parity5-new","parity5-parity2")
delta
@
\end{frame}

\subsection{Utility function}
\frame{\frametitle{Utility functions}
Suppose the only cost difference is in the number of progeny, \pause then $U(\tilde{y}_i) = u_1 \tilde{y}_i$ \pause and want 
\[ \max_{i\in \{d, new\}} E[U(\tilde{y}_i)|y] \]
\pause or, equivalently, pick $new$ if
\[ E[U(\tilde{y}_{new})|y] - E[U(\tilde{y}_s)|y] > 0 \] 
\pause 
But, since expectation is a linear operator,
\[ \begin{array}{ll} 
E[U(\tilde{y}_{new})|y] - E[U(\tilde{y}_s)|y] &= E[U(\tilde{y}_{new})-U(\tilde{y}_s)|y] \pause \\
&= E[u_1 \tilde{y}_{new} - u_1 \tilde{y}_s|y] \pause \\
&= u_1 E[\tilde{y}_{new}|y] - u_1 E[\tilde{y}_s|y] \pause \\
&= u_1 E[\delta|y] \\
\end{array} \]

\pause So $u_1$ just scales our posterior expectation for the difference. 
}


\frame{\frametitle{Utility functions}
Suppose the utility function also involves moving a new sow in, \pause then $U(\tilde{y}_i) = u_1 \tilde{y}_i - u_2\I(i=new)$ \pause and you should pick $new$ if 
\[ E[U(\tilde{y}_{new})|y] - E[U(\tilde{y}_s)|y] = u_1 E[\delta|y] -u_2 > 0. \] 

\vspace{0.2in} \pause 

Now suppose an older sow (or this particular sow) needs more medications, \pause then $U(\tilde{y}_i) = u_1 \tilde{y}_i - u_2\I(i=new) - u_3\I(i=d)$ \pause and you should pick $new$ if 
\[ E[U(\tilde{y}_{new})|y] - E[U(\tilde{y}_s)|y] = u_1 E[\delta|y] - u_2 + u_3 > 0. \] 


\vspace{0.2in} \pause

Now, the decision will depend on the individual utilities $u_1$, $u_2$, and $u_3$. 
}

\frame{\frametitle{Cost functions}
So far, all cost functions have been linear in $\tilde{y}$\pause, but suppose $U(\tilde{y}_i)$ is a complicated function of $\tilde{y}_i$. \pause Then to pick $new$, we want
\[ E[U(\tilde{y}_{new})|y]-E[U(\tilde{y}_s)|y] > 0 \]
\pause This may be analytically intractable, but we can easily simulate from it. \pause Suppose 
\[ U(\tilde{y}_i) = \tilde{y}_i + 0.1(\tilde{y}_i-10) \I(\tilde{y}_i>10) - 0.2\I(i=new). \]

}

\begin{frame}
\frametitle{New data realizations}

To estimate these utility functions, we will need predictive simulations $\tilde{y}$ for the old sow and the new sow. 

\vspace{0.2in} \pause

We can obtain these simulations via 

\begin{itemize}
\item Old sow (progeny $p$ and average grand-sire):
\[ \tilde{y}_s^{(k)} \sim Po\left(e^{\rho_p^{(k)}+\alpha_s^{(k)}}\right) \]
\item New sow (average grand-sire):
\[ \tilde{y}_{new}^{(k)} \sim Po\left(e^{\rho_1^{(k)}+\alpha_{new}^{(k)}}\right) \]
\end{itemize}
where $e^{\rho_p^{(k)}+\alpha_s^{(k)}}$ and $e^{\rho_1^{(k)}+\alpha_{new}^{(k)}}$ are simulations previously drawn.
\end{frame}

\subsection{Summary}
\frame{\frametitle{Summary}
Lecture demonstrated
\begin{itemize}[<+->]
\item mixed effect Poisson regression model,
\item implementation in Stan,
\item posterior summaries, and
\item using the analysis to make a decision regarding sow culling time.
\end{itemize}
}


\end{document}
