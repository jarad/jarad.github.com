\documentclass[handout,aspectratio=169]{beamer}

\input{../frontmatter}
\input{../commands}

\title{Model checking}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment    = NA, 
               fig.width  = 5, 
               fig.height = 3, 
               size       ='tiny', 
               out.width  ='0.8\\textwidth', 
               fig.align  ='center', 
               message    = FALSE,
               echo       = FALSE,
               cache      = TRUE)
options(width = 120)
@

<<packages, message=FALSE, warning=FALSE, cache=FALSE>>=
library("tidyverse"); theme_set(theme_bw())
library("xtable")

library("rstan")
rstan_options(auto_write = TRUE)
options(mc.cores = parallel::detectCores())
@



\frame{\maketitle}

\begin{frame}
\frametitle{Outline}

We assume $p(y|\theta)$ and $p(\theta)$, so it would be prudent to determine if these assumptions are reasonable. 

\vspace{0.2in} \pause

\begin{itemize}
\item (Prior) sensitivity analysis 
\item Posterior predictive checks
  \begin{itemize}
  \item Graphical checks
  \item Posterior predictive pvalues
  \end{itemize}
\end{itemize}
\end{frame}




\section{Prior sensitivity analysis}
\begin{frame}
\frametitle{Prior sensitivity analysis}

Since a prior specifies our prior belief, we may want to check to determine whether our conclusions would change if we held different prior beliefs. \pause Suppose a particular scientific question can be boiled down to 
\[ Y_i \stackrel{ind}{\sim} Ber(\theta) \]
\pause 
and that there is wide disagreement about the value for $\theta$ such that the following might reasonably characterize different individual beliefs before the experiment is run: \pause
\begin{itemize}
\item Skeptic: $\theta\sim Be(1,100)$ 
\item Agnostic: $\theta\sim Be(1,1)$
\item Believer: $\theta\sim Be(100,1)$
\end{itemize}
\pause
An experiment is run and the posterior under these different priors are compared. 

\end{frame}


\begin{frame}
\frametitle{Posteriors}

<<posteriors>>=
prior <- tribble(
  ~type, ~a, ~b,
  "skeptic", 1, 100,
  "agnostic", 1, 1,
  "believer", 100, 1
) |>
  mutate(
    type = factor(type, 
                  levels = type)
  )

p <- 0.9
d <- expand_grid(prior,
                 n = c(0, 10^(1:5)),
                 x = seq(0,1,by=0.01)) |>
  mutate(
    density = dbeta(x,
                    a + p*n,
                    b + (1-p)*n)
  )
@

<<posteriors-plot, dependson="posteriors">>=
ggplot(d, aes(x        = x,
              y        = density,
              col      = type, 
              linetype = type)) + 
  geom_line() +
  facet_wrap(~n, 
             scales='free',
             labeller = label_both) + 
  labs(x = expression(theta), 
       y = expression(paste("p(",theta,"|y)")))
@
\end{frame}



\begin{frame}[fragile]
\frametitle{Hierarchical variance prior}

Recall the normal hierarchical model
\[ y_i \stackrel{ind}{\sim} N(\theta_i,s_i^2), \quad \theta_i\stackrel{ind}{\sim} N(\mu,\tau^2) \]
\pause 
which results in the posterior distribution for $\tau$ of 
\[ p(\tau|y) \propto p(\tau) V_\mu^{1/2} \prod_{i=1}^\I (s_i^2+\tau^2)^{-1/2} \exp\left( -\frac{(y_{i}-\hat{\mu})^2}{2(s_i^2+\tau^2)} \right) \]

 \pause

As an attempt to be non-informative, consider an $IG(\epsilon,\epsilon)$ prior for $\tau^2$. \pause As an alternative, consider $\tau \sim Unif(0,C)$ or $\tau\sim Ca^+(0,C)$ \pause where $C$ is problem specific, but is chosen to be relatively large for the particular problem. 

 \pause

The \href{https://github.com/stan-dev/rstan/wiki/RStan-Getting-Started}{8-schools example} has the following data:

<<data, results='asis'>>=
d = data.frame(y = c(28,  8, -3,  7, -1,  1, 18, 12),
               s = c(15, 10, 16, 11,  9, 11, 10, 18))
print(xtable(t(d), digits=0))
@


\end{frame}

\begin{frame}
\frametitle{Posterior for 8-schools example}
Reproduction of \href{http://projecteuclid.org/euclid.ba/1340371048}{Gelman 2006} and more:
<<eight-schools, echo=FALSE, fig.width=8, warning=FALSE, dependson="data">>=
dinvgamma = function(x, a, b) dgamma(1/x,a,b)/x^2
dsqrtinvgamma = function(x, a, b) dinvgamma(x^2, a, b)*2*x

tau_log_posterior = function(tau, y, si2) 
{
  spt <- si2+tau^2
  Vmu <- 1/sum(1/spt)
  mu  <- sum(y/spt)*Vmu
  0.5*log(Vmu)+sum(-0.5*log(spt)-(y-mu)^2/(2*spt))
}

V_tau_log_posterior <- Vectorize(tau_log_posterior,"tau")



h <- 0.001
e <- 0.001

df <- data.frame(x = seq(0, 20-h, by = h) + h/2) |>
  mutate(
    log_like     = V_tau_log_posterior(x, d$y, d$s^2),
    'IG(10,10)'  = log(dsqrtinvgamma(x,10,10)),
    'IG( 1, 1)'  = log(dsqrtinvgamma(x,1,1)),
    'IG( e, e)'  = log(dsqrtinvgamma(x,e,e)),
    'Unif(0,20)' = 0,
    'Ca^+(0,10)'  = dcauchy(x, 0, 10, log=TRUE),
    'N^+(0,20)'   = dnorm(  x, 0, 20, log=TRUE)
  ) |>
  pivot_longer(
    `IG(10,10)`:`N^+(0,20)`,
    names_to  = "Prior",
    values_to = "log_prior"
  ) |>
  mutate(
    Prior = factor(Prior,
                   levels = c(
                     'IG(10,10)',
                     'IG( 1, 1)',
                     'IG( e, e)',
                     'Unif(0,20)',
                     'Ca^+(0,10)',
                     'N^+(0,20)'
                   )),
    log_posterior = log_like + log_prior,
    
    prior     = exp(log_prior - max(log_prior)),
    prior     = prior / sum(prior) / h,
    
    posterior = exp(log_posterior - max(log_posterior)),
    posterior = posterior / sum(posterior) / h
  ) |>
  pivot_longer(
    prior:posterior,
    names_to = "Distribution",
    values_to = "density"
  )
@  

<<eight-schools-plot, dependson="eight-schools">>=
ggplot(df, 
       aes(
         x        = x, 
         y        = density, 
         color    = Distribution, 
         linetype = Distribution, 
         group    = Distribution)) +
  geom_line() + 
  facet_wrap(
    ~Prior, 
    scales = 'free') 
@
\end{frame}


\begin{frame}
\frametitle{Summary}

For a default prior on a variance ($\sigma^2$) or standard deviation ($\sigma$),
use 

\begin{enumerate}
\item Easy to remember.
  \begin{itemize}
  \item Half-Cauchy on the standard deviation ($\sigma \sim Ca^+(0,C)$) \pause
  \item Half-normal on the standard deviation ($\sigma \sim N^+(0,C)$) \pause
  \end{itemize}
\item Harder to remember
  \begin{itemize}
  \item Data-level variance 
    \begin{itemize}
    \item Use default prior ($p(\sigma^2)\propto 1/\sigma^2$) \pause 
    \end{itemize}
  \item Hierarchical standard deviation
    \begin{itemize}
    \item Use uniform prior (Unif$(0,C)$) if there are enough reps (5 or more) of that parameter. \pause 
    \item Use half-Cauchy prior ($Ca^+(0,C)$) otherwise.\pause 
    \item Use half-normal prior ($N^+(0,C)$) otherwise.
    \end{itemize}
  \end{itemize}
\end{enumerate}
\end{frame}

\begin{frame}
\frametitle{Summary - notes}
When assigning the values for $C$
\begin{itemize}
\item For a uniform prior (Unif$(0,C)$) make sure $C$ is large enough to capture any reasonable value for the standard deviation.
\item For a half-Cauchy prior ($Ca^+(0,C)$) err on the side of making $C$ too small since the heavy tails will let the data tell you if the standard deviation needs to be larger whereas a value of $C$ that is too large will put too much weight toward large values of the standard deviation and make the prior more informative.
\item For a half-normal prior ($Ca^+(0,C)$) err on the side of making $C$ too large since the light tails will not allow the data to tell you if the standard deviation needs to be larger whereas a value of $C$ that is too small will put too much weight toward small values of the standard deviation and make the prior more informative.
\end{itemize}
\end{frame}


\section{Posterior predictive checks}
\begin{frame}
\frametitle{Posterior predictive checks}
  Let $y^{rep}$ be a replication of $y$, \pause then 
  \[ p(y^{rep}|y) = \int p(y^{rep}|\theta,y) p(\theta|y) d\theta \pause = \int p(y^{rep}|\theta) p(\theta|y) d\theta. \]
  \pause where $y$ is the observed data and $\theta$ are the model parameters.
  
  \vspace{0.2in} \pause
  
  To simulate a full replication:
  \begin{enumerate}[<+->]
  \item Simulate $\theta^{(j)}\sim p(\theta|y)$ and 
  \item Simulate $y^{rep,j} \sim p(y|\theta^{(j)})$.
  \end{enumerate}
  
  \vspace{0.2in} \pause 
  
  To assess model adequacy:
  \begin{itemize}
  \item Compare plots of replicated data to the observed data. \pause
  \item Calculate posterior predictive pvalues.
  \end{itemize}
\end{frame}



\subsection{Airline example{}}
\begin{frame}[fragile]
\frametitle{Airline accident data}
  Let 
  \begin{itemize}
  \item $y_i$ be the number of fatal accidents in year $i$
  \item $x_i$ be the number of 100 million miles flown in year $i$
  \end{itemize}
  \pause
  Consider the model 
  \[ Y_i \stackrel{ind}{\sim} Po(x_i\lambda) \qquad p(\lambda)\propto 1/\sqrt{\lambda}. \]
  \pause
\footnotesize
<<airline-accident-data, results='asis'>>=
d <- data.frame(year            = 1976:1985, 
                fatal_accidents  = c(24,25,31,31,22,21,26,20,16,22),
                passenger_deaths = c(734,516,754,877,814,362,764,809,223,1066),
                death_rate       = c(0.19,0.12,0.15,0.16,0.14,0.06,0.13,0.13,0.03,0.15))
d$miles_flown <- d$passenger_deaths/d$death_rate # 100 million miles
print(xtable(d, digits=0, include.rownames=FALSE))
@
\end{frame}



\begin{frame}[fragile]
\frametitle{Posterior replications of the data}
  Under Jeffreys prior, the posterior is 
  \[ \lambda|y \sim Ga(0.5+n\overline{y}, n\overline{x}). \]
  So to obtain a replication of the data, do the following \pause
  \begin{enumerate}
  \item $\lambda^{(j)} \sim Ga(0.5+n\overline{y}, n\overline{x})$ \pause and 
  \item $y^{rep,j}_i \stackrel{ind}{\sim} Po(x_i\lambda^{(j)})$ for $i=1,\ldots,n$.
  \end{enumerate}

<<airline-accident-replicates, dependson="airline-accident-data">>=
# Jeffreys prior
a <- 0.5 + sum(d$fatal_accidents)
b <- 0   + sum(d$miles_flown)

# Replicate data
rep <- data.frame(
  .n = 1:19,
  lambda = rgamma(19, a, b)
) |>
  expand_grid(d) |>
  mutate(
    fatal_accidents = rpois(n(), lambda * miles_flown)
  ) |>
  select(-lambda)

id <- sample(20,1) # Choose a random spot to insert observed data set
if (id == 20) {
  d$.n <- 20
  rep <- rbind(rep,d)
} else {
  rep$.n[rep$.n == id] <- 20
  d$.n <- id
  rep <- rbind(rep,d) 
}
@
\end{frame}



\begin{frame}[fragile]
<<airline-accident-histograms, message=FALSE, dependson="airline-accident-replicates">>=
ggplot(rep, 
       aes(
         x    = fatal_accidents, 
         fill = factor(1))) + 
  geom_histogram(binwidth=1) +
  facet_wrap(~.n) +
  theme(legend.position="none")
@
\end{frame}



\begin{frame}[fragile]
<<airline-accident-histograms-observed, message=FALSE, dependson="airline-accident-replicates">>=
ggplot(rep, 
       aes(
         x = fatal_accidents, 
         fill = .n==id)) + 
  geom_histogram(binwidth=1) +
  facet_wrap(~.n) +
  theme(legend.position="none")
@
\end{frame}

\begin{frame}[fragile]
\frametitle{How might this model not accurately represent the data?}
  Let 
  \begin{itemize}
  \item $y_i$ be the number of fatal accidents in year $i$
  \item $x_i$ be the number of 100 million miles flown in year $i$
  \end{itemize}
  
  Consider the model 
  \[ Y_i \stackrel{ind}{\sim} Po(x_i\lambda) \qquad p(\lambda)\propto 1/\sqrt{\lambda}. \]
  
\footnotesize
<<results='asis', dependson="airline-accident-data">>=
print(xtable(d, digits=0, include.rownames=FALSE))
@
\end{frame}



\begin{frame}[fragile]
<<replicates-scatterplot, dependson="airline-accident-replicates">>=
# change random data location
old_id <- id
id <- sample(20,1) # Choose a random spot to insert observed data set
rep$.n[rep$.n==old_id] <- 21
rep$.n[rep$.n==id    ] <- old_id
rep$.n[rep$.n==21    ] <- id


g <- ggplot(rep, 
           aes(
             x = year, 
             y = fatal_accidents, 
             col = factor(1))) + 
  geom_point() + 
  facet_wrap(~.n) +
  theme(legend.position="none")
g
@
\end{frame}


\begin{frame}[fragile]
<<replicates-scatterplot-with-regression-line, dependson="replicates-scatterplot">>=
g <- g + stat_smooth(method="lm", formula=y~x)
g
@
\end{frame}


\begin{frame}[fragile]
<<replicate-scatterplot-with-observed, dependson="replicates-scatterplot-with-regression-line">>=
g + aes(col=.n==id)
@
\end{frame}



\subsection{Posterior predictive pvalues}
\begin{frame}
\frametitle{Posterior predictive pvalues}
  To quantify the discrepancy between observed and replicated data: \pause
  \begin{enumerate}
  \item Define a test statistic $T(y,\theta)$. \pause
  \item Define the posterior predictive pvalue
  \[ p_B = P(T(y^{rep},\theta)\ge T(y,\theta)|y) \]
  \pause where $y^{rep}$ and $\theta$ are random. \pause Typically this pvalue is calculated via simulation, \pause i.e. 
  \[ \begin{array}{rl}
  p_B
  &= E_{y^{rep},\theta}[\mathrm{I}(T(y^{rep},\theta)\ge T(y,\theta))|y] \pause \\
  &= \int \int \mathrm{I}(T(y^{rep},\theta)\ge T(y,\theta)) p(y^{rep}|\theta) p(\theta|y) dy^{rep} d\theta \pause \\
  &\approx \frac{1}{J} \sum_{j=1}^J \mathrm{I}(T(y^{rep,j},\theta^{(j)})\ge T(y,\theta^{(j)})) 
  \end{array} \]
  \pause where $\theta^{(j)} \sim p(\theta|y)$ and $y^{rep,j} \sim p(y|\theta^{(j)})$. 
   
  \end{enumerate}
  \pause Small \alert{or large} pvalues are (possible) cause for concern. 
\end{frame}






\begin{frame}[fragile]
\frametitle{Posterior predictive pvalue for slope}
  Let 
  \[ Y_i^{obs} = \beta_0^{obs}+\beta_1^{obs}\, i \]
  where 
  \begin{itemize}
  \item $Y_i^{obs}$ is the observed number of fatal accidents in year $i$ \pause and 
  \item $\beta_1^{obs}$ be the test statistic. 
  \end{itemize}
  
  \vspace{0.2in} \pause 

  Now, generate replicate data $y^{rep}$ and fit 
  \[ Y_i^{rep} = \beta_0^{rep} + \beta_1^{rep} i.\]
  \pause
  Now compare $\beta_1^{obs}$ to the distribution of $\beta_1^{rep}$.

<<slope, cache=TRUE>>=
rep <- data.frame(
  beta1 = replicate(1000, {
    lambda <- rgamma(1, a, b)
    d$fatal_accidents <- rpois(nrow(d), lambda*d$miles_flown)
    coefficients(lm(fatal_accidents~year, d))[2]
  })
)
observed_slope <- coefficients(lm(fatal_accidents ~ year,d))[2]
@
\end{frame}



\begin{frame}[fragile]
<<slope_plot, dependson="slope", fig.width=8, echo=TRUE>>=
mean(rep$beta1 > observed_slope) 
ggplot(rep, aes(x=beta1)) + geom_histogram(binwidth=0.1) + 
  geom_vline(xintercept=observed_slope, color="red") +
  theme_bw()
@
\end{frame}


\subsection{Update model}
\begin{frame}
\frametitle{Consider a linear model for the $\lambda_i$}
  Consider the model 
  \[ \begin{array}{rl}
  Y_i &\stackrel{ind}{\sim} Po(x_i \lambda_i) \pause  \\
  \log(\lambda_i) &= \beta_0+\beta_1 i
  \end{array} \]
  \pause where
  \begin{itemize}[<+->]
  \item $Y_i$ is the number of fatal accidents in year $i$
  \item $x_i$ is the number of 100 million miles flown in year $i$
  \item $\lambda_i$ is the accident rate in year $i$
  \end{itemize}
  
  \vspace{0.2in} \pause
  
  Here the $\lambda_i$ are a deterministic function of year, but (possibly) different each year.
\end{frame}




\begin{frame}[fragile]
\frametitle{Stan linear model for accident rate}
<<stan-model, echo=TRUE, results='hide'>>=
model = "
data {
  int<lower=0> n;
  int<lower=0> y[n];
  vector<lower=0>[n] x;
}
transformed data {
  vector[n] log_x;
  log_x = log(x); # both x and logx need to be vectors 
}
parameters {
  real beta[2];
}
transformed parameters {
  vector[n] log_lambda;
  for (i in 1:n) log_lambda[i] = beta[1] + beta[2]*i;
}
model {
  y ~ poisson_log(log_x + log_lambda); # _log indicates mean on log scale
}
"
@
\end{frame}

\begin{frame}[fragile]
\frametitle{Stan run}
<<stan, dependson=c("stan-model","airline-accident-data"), echo=TRUE, message=FALSE>>=
m <- stan_model(model_code = model) # compile model
r <- sampling(m, 
              list(n = nrow(d), 
                      y = d$fatal_accidents, 
                      x = d$miles_flown),
              iter = 10000)
@
\end{frame}

\begin{frame}[fragile]
<<stan-posteriors, dependson='stan', echo=TRUE>>=
r
@
\end{frame}


\begin{frame}[fragile]
\frametitle{Posterior predictive pvalue: slope}
<<stan-rep, dependson='stan', echo=TRUE>>=
# Need to update to eliminate plyr dependency
library("plyr")
log_lambda <- extract(r, "log_lambda")[["log_lambda"]]
reps <- plyr::adply(log_lambda, 1, function(a) {
  d <- data.frame(
    yrep = rpois(nrow(d), d$miles_flown * exp(a)),
    year = 1:10)
})

rep_slopes = plyr::daply(reps, .(iterations), function(d) {
  slopes = coefficients(lm(yrep ~ year, d))[2]
})
@

<<posterior-predictive-pvalue, echo=TRUE, dependson='stan-rep'>>=
# Posterior predictive pvalue: slope
mean(rep_slopes > observed_slope)
@
\end{frame}

\begin{frame}
<<posterior-predictive-pvalue-plot, dependson='stan-rep'>>=
ggplot(data.frame(slopes = rep_slopes), 
       aes(x = slopes)) + 
  geom_histogram(binwidth = 0.1) + 
  geom_vline(
    xintercept = observed_slope, 
    color      = 'red') 
@
\end{frame}


\end{document}
