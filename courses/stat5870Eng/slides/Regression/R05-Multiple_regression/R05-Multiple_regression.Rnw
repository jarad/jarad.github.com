\documentclass[t,aspectratio=169,handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

\input{../../frontmatter}
\input{../../commands}

\title{R05 - Multiple Regression}

% \setbeamertemplate{background}
% {\includegraphics[width=\paperwidth,height=\paperheight,keepaspectratio]{video_overlay}}

<<options, echo=FALSE, warning=FALSE, message=FALSE>>=
options(width=120)
opts_chunk$set(comment=NA, 
               fig.width=6, 
               fig.height=2.5, 
               size='tiny', 
               out.width='\\textwidth', 
               fig.align='center', 
               echo=FALSE,
               message=FALSE)
@

<<libraries, message=FALSE, warning=FALSE, echo=FALSE>>=
library("tidyverse"); theme_set(theme_bw())
library("Sleuth3")
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@


\begin{document}

\begin{frame}
\maketitle
\end{frame}


\section{Multiple regression model}

\frame{\frametitle{Multiple regression}
  Recall the simple linear regression model is 
	\[ Y_i \stackrel{ind}{\sim} N(\mu_i, \sigma^2), \pause \quad \mu_i = \beta_0+\beta_1 X_i \]
	\pause
	The \alert{multiple regression model} has mean
	\[ \mu_i = \beta_0+\beta_1 X_{i,1}+\cdots + \beta_p X_{i,p} \]
	
	\pause where for observation $i$ 
  \begin{itemize}
  \item $Y_i$ is the response \pause and 
  \item $X_{i,p}$ is the $p^{th}$ explanatory variable.
  \end{itemize}
  % 
  % \vspace{0.2in} \pause
  % 
  % We may also write
  % \[ Y_i \stackrel{ind}{\sim} N(\mu_i,\sigma^2) \quad\mbox{ or }\quad 
  %    Y_i = \mu_i + e_i, \, e_i \stackrel{iid}{\sim} N(0,\sigma^2) \]
  % where 
  % \[ \mu_i=\beta_0+\beta_1 X_{i,1}+\cdots + \beta_p X_{i,p}. \]
  
}



\frame{\frametitle{Explanatory variables}
  There is a lot of flexibility in the mean
\[ \mu_i =  \beta_0+\beta_1 X_{i,1}+\cdots + \beta_p X_{i,p} \]
\pause
  as there are many possibilities for the explanatory variables $X_{i,1},\ldots,X_{i,p}$:

  \pause
  
  
	\begin{itemize} \small
	\item Functions ($f(X)$) \pause
	\item Dummy variables for categorical variables ($X_1=\I()$) \pause
  \item Higher order terms ($X^2$) \pause
	\item Additional explanatory variables ($X_1,X_2$) \pause
	\item Interactions ($X_1X_2$) \pause
    \begin{itemize}
    \item Continuous-continuous \pause
    \item Continuous-categorical \pause
    \item Categorical-categorical \pause
    \end{itemize}
	\end{itemize}
	
}


\subsection{Parameter interpretation}
\frame{\frametitle{Parameter interpretation}
  Model:
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_{i,1}+\cdots + \beta_p X_{i,p}, \sigma^2) \]
	
	\vspace{0.2in} \pause
	
	
	The interpretation is 
	\begin{itemize}
	\item $\beta_0$ is the expected value of the response $Y_i$ when \alert{all} explanatory variables are zero. \pause
	\item $\beta_p,\,p\ne 0$ is the expected increase in the response for a one-unit increase in the $p^{th}$ explanatory variable \alert{when all other explanatory variables are held constant}. \pause
	\item $R^2$ is the proportion of the variability in the response explained by the model
	\end{itemize}
	
}


\subsection{Parameter estimation and inference}
\begin{frame}
\frametitle{Parameter estimation and inference}

\tiny

Let 
\[ 
y = X\beta + \epsilon
\]
where 
\begin{itemize}
\item $y = (y_1,\ldots,y_n)^\top$
\item $X$ is $n\times p$ with $i$th row $X_i = (1,X_{i,1},\ldots,X_{i,p})$
\item $\beta = (\beta_0,\beta_1,\ldots,\beta_p)^\top$
\item $\epsilon = (\epsilon_1,\ldots,\epsilon_n)^\top$
\end{itemize}
\pause
Then we have 
\[ \begin{array}{rl}
\hat\beta &= (X^\top X)^{-1}X^\top y \\
Var(\hat\beta) &= \sigma^2(X^\top X)^{-1} \\
r &= y-X\hat\beta \\
\hat\sigma^2 &= \frac{1}{n-(p+1)}r^\top r \\
\end{array} \]
\pause

Confidence/credible intervals and (two-sided) \pvalue{}s are constructed using 
\[
\hat\beta_j \pm t_{n-(p+1),1-a/2} SE(\hat\beta_j)
\quad\mbox{and}\quad
\mbox{pvalue} = 2P\left(T_{n-(p+1)}>\left|\frac{\hat\beta_j-b_j}{SE(\hat\beta_j)}\right|\right)
\]
where $T_{n-(p+1)} \sim t_{n-(p+1)}$ and $SE(\hat\beta_j)$ is the $j$th diagonal element of 
$\hat\sigma^2(X^\top X)^{-1}$.

\end{frame}


\subsection{Higher order terms ($X^2$)}
\begin{frame}
\frametitle{Galileo experiment}

\vspace{-0.4in}

<<fig.height=3.5>>=
curve(ifelse(x>0,-x^2+1,NA), -1, 1, axes=FALSE, frame.plot=TRUE, 
      xlab="", ylab="", ylim=c(0,1.1),
      lty=2)
axis(1, c(0,1), c("0","Distance"))
axis(2, c(0,1), c("0","Height"))
rect(-1,0,0,1, density = 1)
points(0,1.03,pch=19, cex=2)
arrows(-0.3,1.03,-0.1,1.03, length=0.1)
text(-0.45,1.03,"force")
@

\end{frame}


\begin{frame}
\frametitle{Galileo data ({\tt Sleuth3::case1001})}

<<>>=
ggplot(Sleuth3::case1001, aes(Height, Distance)) +
  geom_point() 
@

\end{frame}




\begin{frame}
\frametitle{Higher order terms ($X^2$)}

Let 
\begin{itemize}
\item $Y_i$ be the distance for the $i^{th}$ run of the experiment and
\item $H_i$ be the height for the $i^{th}$ run of the experiment.
\end{itemize}

\pause


Simple linear regression assumes
\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 H_i\phantom{ +\beta_2 H_i^2 + \beta_3 H_i^3}, \sigma^2) \]
\pause
The quadratic multiple regression assumes
\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 H_i +\beta_2 H_i^2\phantom{+ \beta_3 H_i^3}, \sigma^2) \]
\pause
The cubic multiple regression assumes 
\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 H_i +\beta_2 H_i^2 + \beta_3 H_i^3, \sigma^2) \]

\end{frame}



\begin{frame}[fragile]
\frametitle{R code and output}

<<tidy=FALSE, echo=TRUE>>=
# Construct the variables by hand
m1 = lm(Distance ~ Height,                             case1001)
m2 = lm(Distance ~ Height + I(Height^2),               case1001)
m3 = lm(Distance ~ Height + I(Height^2) + I(Height^3), case1001)

coefficients(m1)
coefficients(m2)
coefficients(m3)
@

\end{frame}




<<echo=FALSE>>=
# Multiple plot function
#
# ggplot objects can be passed in ..., or to plotlist (as a list of ggplot objects)
# - cols:   Number of columns in layout
# - layout: A matrix specifying the layout. If present, 'cols' is ignored.
#
# If the layout is something like matrix(c(1,2,3,3), nrow=2, byrow=TRUE),
# then plot 1 will go in the upper left, 2 will go in the upper right, and
# 3 will go all the way across the bottom.
#
multiplot <- function(..., plotlist=NULL, file, cols=1, layout=NULL) {
  require(grid)
  
  # Make a list from the ... arguments and plotlist
  plots <- c(list(...), plotlist)
  
  numPlots = length(plots)
  
  # If layout is NULL, then use 'cols' to determine layout
  if (is.null(layout)) {
    # Make the panel
    # ncol: Number of columns of plots
    # nrow: Number of rows needed, calculated from # of cols
    layout <- matrix(seq(1, cols * ceiling(numPlots/cols)),
                     ncol = cols, nrow = ceiling(numPlots/cols))
  }
  
  if (numPlots==1) {
    print(plots[[1]])
    
  } else {
    # Set up the page
    grid.newpage()
    pushViewport(viewport(layout = grid.layout(nrow(layout), ncol(layout))))
    
    # Make each plot, in the correct location
    for (i in 1:numPlots) {
      # Get the i,j matrix positions of the regions that contain this subplot
      matchidx <- as.data.frame(which(layout == i, arr.ind = TRUE))
      
      print(plots[[i]], vp = viewport(layout.pos.row = matchidx$row,
                                      layout.pos.col = matchidx$col))
    }
  }
}

@


\begin{frame}
\frametitle{Galileo experiment (Sleuth3::case1001)}

<<echo=FALSE>>=
g = ggplot(case1001, aes(x=Height, y=Distance)) + geom_point(size=3)
multiplot(
  g + theme_bw(),
  g + stat_smooth(method="lm")                                    + theme_bw(),
  g + stat_smooth(method="lm", formula = y ~ x + I(x^2))          + theme_bw(),
  g + stat_smooth(method="lm", formula = y ~ x + I(x^2) + I(x^3)) + theme_bw(),
  layout = matrix(1:4,2,byrow=TRUE)
)
@

\end{frame}






% \begin{frame}[fragile]
% \frametitle{R code and output}
% 
% <<tidy=FALSE, echo=TRUE>>=
% # Let R construct the variables for you
% m = lm(Distance~poly(Height, 3, raw=TRUE), case1001)
% summary(m)
% @
% 
% \end{frame}






\subsection{Additional explanatory variables ($X_1+X_2$)}
\frame{\frametitle{Longnose Dace Abundance}
\pause
From \url{http://udel.edu/~mcdonald/statmultreg.html}: 
{\scriptsize
	\begin{quote}
I extracted some data from the Maryland Biological Stream Survey. ... The [response] variable is the number of Longnose Dace ... per 75-meter section of [a] stream. The [explanatory] variables are ... the maximum depth (in cm) of the 75-meter segment of stream; nitrate concentration (mg/liter) .... 	
	\end{quote}
	}
	
	\pause
	
	
Consider the model 
	\[ Y_i \stackrel{ind}{\sim} N(\beta_0+\beta_1 X_{i,1}+\beta_2 X_{i,2}, \sigma^2) \]
	\pause where 
	\begin{itemize}[<+->]
	\item $Y_i$: count of Longnose Dace in stream $i$
	\item $X_{i,1}$: maximum depth (in cm) of stream $i$
	\item $X_{i,2}$: nitrate concentration (mg/liter) of stream $i$
	\end{itemize}
	
}



\begin{frame}[fragile]
\frametitle{Exploratory}

<<echo=FALSE>>=
longnosedace <- structure(list(stream = structure(1:67, .Label = c("BASIN_RUN", 
"BEAR_BR", "BEAR_CR", "BEAVER_DAM_CR", "BEAVER_RUN", "BENNETT_CR", 
"BIG_BR", "BIG_ELK_CR", "BIG_PIPE_CR", "BLUE_LICK_RUN", "BROAD_RUN", 
"BUFFALO_RUN", "BUSH_CR", "CABIN_JOHN_CR", "CARROLL_BR", "COLLIER_RUN", 
"CONOWINGO_CR", "DEAD_RUN", "DEEP_RUN", "DEER_CR", "DORSEY_RUN", 
"FALLS_RUN", "FISHING_CR", "FLINTSTONE_CR", "GREAT_SENECA_CR", 
"GREENE_BR", "GUNPOWDER_FALLS", "HAINES_BR", "HAWLINGS_R", "HAY_MEADOW_BR", 
"HERRINGTON_RUN", "HOLLANDS_BR", "ISRAEL_CR", "LIBERTY_RES", 
"LITTLE_ANTIETAM_CR", "LITTLE_BEAR_CR", "LITTLE_CONOCOCHEAGUE_CR", 
"LITTLE_DEER_CR", "LITTLE_FALLS", "LITTLE_GUNPOWDER_R", "LITTLE_HUNTING_CR", 
"LITTLE_PAINT_BR", "MAINSTEM_PATUXENT_R", "MEADOW_BR", "MILL_CR", 
"MORGAN_RUN", "MUDDY_BR", "MUDLICK_RUN", "NORTH_BR", "NORTH_BR_CASSELMAN_R", 
"NORTHWEST_BR", "NORTHWEST_BR_ANACOSTIA_R", "OWENS_CR", "PATAPSCO_R", 
"PINEY_BR", "PINEY_CR", "PINEY_RUN", "PRETTYBOY_BR", "RED_RUN", 
"ROCK_CR", "SAVAGE_R", "SECOND_MINE_BR", "SENECA_CR", "SOUTH_BR_CASSELMAN_R", 
"SOUTH_BR_PATAPSCO", "SOUTH_FORK_LINGANORE_CR", "TUSCARORA_CR"
), class = "factor"), count = c(13L, 12L, 54L, 19L, 37L, 2L, 
72L, 164L, 18L, 1L, 53L, 16L, 32L, 21L, 23L, 18L, 112L, 25L, 
5L, 26L, 8L, 15L, 11L, 11L, 87L, 33L, 22L, 98L, 1L, 5L, 1L, 38L, 
30L, 12L, 24L, 6L, 15L, 38L, 84L, 3L, 18L, 63L, 239L, 234L, 6L, 
76L, 25L, 8L, 23L, 16L, 6L, 100L, 80L, 28L, 48L, 18L, 36L, 19L, 
32L, 3L, 106L, 62L, 23L, 2L, 26L, 20L, 38L), acreage = c(2528L, 
3333L, 19611L, 3570L, 1722L, 583L, 4790L, 35971L, 25440L, 2217L, 
1971L, 12620L, 19046L, 8612L, 3896L, 6298L, 27350L, 4145L, 1175L, 
8297L, 7814L, 1745L, 5046L, 18943L, 8624L, 2225L, 12659L, 1967L, 
1172L, 639L, 7056L, 1934L, 6260L, 424L, 3488L, 3330L, 2227L, 
8115L, 1600L, 15305L, 7121L, 5794L, 8636L, 4803L, 1097L, 9765L, 
4266L, 1507L, 3836L, 17419L, 8735L, 22550L, 9961L, 4706L, 4011L, 
6949L, 11405L, 904L, 3332L, 575L, 29708L, 2511L, 18422L, 6311L, 
1450L, 4106L, 10274L), do2 = c(9.6, 8.5, 8.3, 9.2, 8.1, 9.2, 
9.4, 10.2, 7.5, 8.5, 11.9, 8.3, 8.3, 8.2, 10.4, 8.6, 8.5, 8.7, 
7.7, 9.9, 6.8, 9.4, 7.6, 9.2, 8.6, 9.1, 9.7, 8.6, 8.3, 9.5, 6.4, 
10.5, 9.5, 8.3, 9.3, 9.1, 6.8, 9.6, 10.2, 9.7, 9.5, 9.4, 8.4, 
8.5, 8.3, 9.3, 8.9, 7.4, 8.3, 7.4, 8.2, 8.4, 8.6, 8.9, 8.3, 9.3, 
9.2, 9.8, 8.4, 6.8, 7.7, 10.2, 9.9, 7.6, 7.9, 10, 9.3), maxdepth = c(80L, 
83L, 96L, 56L, 43L, 51L, 91L, 81L, 120L, 46L, 56L, 37L, 120L, 
103L, 105L, 42L, 65L, 51L, 57L, 60L, 160L, 48L, 109L, 50L, 78L, 
41L, 65L, 50L, 73L, 26L, 60L, 85L, 133L, 62L, 44L, 67L, 54L, 
110L, 56L, 85L, 58L, 34L, 150L, 93L, 53L, 130L, 68L, 51L, 121L, 
48L, 63L, 107L, 79L, 61L, 52L, 100L, 70L, 39L, 73L, 33L, 73L, 
60L, 45L, 46L, 60L, 96L, 90L), no3 = c(2.28, 5.34, 0.99, 5.44, 
5.66, 2.26, 4.1, 3.2, 3.53, 1.2, 3.25, 0.61, 2.93, 1.57, 2.77, 
0.26, 6.95, 0.34, 1.3, 5.26, 0.44, 2.19, 0.73, 0.25, 3.37, 2.3, 
3.3, 7.71, 2.62, 3.53, 0.25, 2.34, 2.41, 3.49, 2.11, 0.81, 0.33, 
3.4, 3.54, 2.6, 0.51, 1.19, 3.31, 5.01, 1.71, 4.38, 2.05, 0.84, 
1.32, 0.29, 1.56, 1.41, 1.02, 4.06, 4.7, 4.57, 2.17, 6.81, 2.09, 
2.47, 0.63, 4.17, 1.58, 0.64, 2.96, 2.62, 5.45), so4 = c(16.75, 
7.74, 10.92, 16.53, 5.91, 8.81, 5.65, 17.53, 8.2, 10.85, 11.12, 
18.87, 11.31, 16.09, 12.79, 17.63, 14.94, 44.93, 21.68, 6.36, 
20.24, 10.27, 7.1, 14.21, 7.51, 9.72, 5.98, 26.44, 4.64, 4.46, 
9.82, 11.44, 13.77, 5.82, 13.37, 8.16, 7.6, 9.22, 5.69, 6.96, 
7.41, 12.27, 5.95, 10.98, 15.77, 5.74, 12.77, 16.3, 7.36, 2.5, 
13.22, 14.45, 9.07, 9.9, 5.38, 17.84, 10.17, 9.2, 5.5, 7.61, 
12.28, 10.75, 8.37, 21.16, 8.84, 5.45, 24.76), temp = c(15.3, 
19.4, 19.5, 17, 19.3, 12.9, 16.7, 13.8, 13.7, 14.3, 22.2, 16.8, 
18, 15, 18.4, 18.2, 24.1, 23, 21.8, 19.1, 22.6, 14.3, 19, 18.5, 
21.3, 20.5, 18, 16.8, 20.5, 20.1, 24.5, 12, 21, 20.2, 24, 14.9, 
24, 20.5, 19.5, 17.5, 16, 17.5, 18.1, 24.3, 13.1, 16.9, 17, 21, 
18.5, 18, 20.8, 23, 21.8, 19.7, 18.9, 18.6, 23.6, 19.2, 17.7, 
18, 21.4, 17.7, 20.1, 18.5, 18.6, 15.4, 15)), .Names = c("stream", 
"count", "acreage", "do2", "maxdepth", "no3", "so4", "temp"), class = "data.frame", row.names = c(NA, 
-67L))

m <- longnosedace %>%
  tidyr::gather(variable, value, -stream, -count, -acreage)

ggplot(m %>% filter(variable %in% c("maxdepth","no3")), aes(x=value,y=count)) + 
  geom_point(size=2) + 
  facet_wrap(~variable, scales="free") +
  theme_bw()
@

\end{frame}





\begin{frame}[fragile]
\frametitle{R code and output}

<<echo = TRUE>>=
m <- lm(count ~ maxdepth + no3, longnosedace)
summary(m)
@

\end{frame}


\frame{\frametitle{Interpretation}
\small

	\begin{itemize}
	\item Intercept ($\beta_0$): The expected count of Longnose Dace when maximum depth and nitrate concentration are both zero is -18. \pause
	\item Coefficient for maxdepth ($\beta_1$): Holding nitrate concentration constant, each cm increase in maximum depth is associated with an additional 0.48 Longnose Dace counted on average. \pause
	\item Coefficient for no3 ($\beta_2$): Holding maximum depth constant, each mg/liter increase in nitrate concentration is associated with an addition 8.3 Longnose Dace counted on average. \pause
	\item Coefficient of determination ($R^2$): The model explains 19\% of the variability in the count of Longnose Dace.
	\end{itemize}
	
}



% \subsection{Categorical variables ($X_1=\I()$)}
% \begin{frame}[fragile]
% \frametitle{Using a categorical variable as an explanatory variable.}
% 
% <<echo=FALSE>>=
% opar = par(mar=c(5,5,0,0)+.1)
% plot(Lifetime~jitter(I(as.numeric(Diet)-1)), case0501, xaxt='n', pch=19, cex.lab=1.5, 
%      xlab="Diet", col='gray')
% axis(1, seq(0,nlevels(case0501$Diet)-1), levels(case0501$Diet), cex=1.5)
% 
% yy = with(case0501, by(Lifetime, Diet, mean))
% segments((0:5)-.3, yy, (0:5)+.3, yy, col='red', lwd=2)
% par(opar)
% @
% 
% \end{frame}
% 
% \frame{\frametitle{Regression with a categorical variable}
% 
% 	\begin{itemize}
% 	\item Choose one of the levels as the \alert{reference} level, e.g. N/N85 \pause
% 	\item Construct dummy variables using indicator functions, i.e.  
%   \[ \I(A) = \left\{ \begin{array}{ll} 1 & A\mbox{ is TRUE} \\ 0 & A\mbox{ is FALSE} \end{array}\right.\]
%   
%   \pause 
%   
%   for the other levels, \pause e.g.
% 	\[ \begin{array}{ll} 
% 	X_{i,1} = \I(\mbox{diet for observation $i$ is N/R40})\pause \\
% 	X_{i,2} = \I(\mbox{diet for observation $i$ is N/R50})\pause \\
% 	X_{i,3} = \I(\mbox{diet for observation $i$ is NP})\pause \\
% 	X_{i,4} = \I(\mbox{diet for observation $i$ is R/R50})\pause \\
% 	X_{i,5} = \I(\mbox{diet for observation $i$ is lopro})\pause
% 	\end{array} \] 
% 	\item \pause Estimate the parameters of a multiple regression model using these dummy variables.
% 	\end{itemize}
% 	
% }
% 
% 
% 
% 
% \begin{frame}[fragile]
% \frametitle{R code and output}
% 
% <<>>=
% # by default, R uses the alphabetically first group as the reference level
% case0501$Diet = relevel(case0501$Diet, ref='N/N85') 
% 
% m = lm(Lifetime~Diet, case0501)
% summary(m)
% @
% 
% \end{frame}
% 
% 
% \begin{frame}
% \frametitle{Interpretation}
% % \begin{itemize}[<+->]
% % \item $\beta_0 = E[Y_i| \mbox{reference level}]$, i.e. expected response for the reference level
% % 
% % {\color{gray}
% % Note: the only way $X_{i,1}=\cdots=X_{i,p}=0$ is if all indicators are zero, i.e. at the reference level. 
% % }
% % 
% % \item $\beta_p, p>0$: expected change in the response moving from the reference level to the level associated with the $p^{th}$ dummy variable
% % 
% % {\color{gray}
% % Note: the only way for $X_{i,p}$ to increase by one and all other indicators to stay constant is if initially $X_{i,1}=\cdots=X_{i,p}=0$ and now $X_{i,p}=1$
% % }
% % \end{itemize}
% % 
% % \vspace{0.2in} \pause
% % 
% % For example, 
% \begin{itemize}
% \item The expected lifetime for mice on the N/N85 diet is 32.7 weeks. \pause
% \item The expected increase in lifetime for mice on the N/R40 diet compared to the N/N85 diet is 12.4 weeks. \pause
% \item The model explains 45\% of the variability in mice lifetimes.
% \end{itemize}
% \end{frame}
% 
% 
% \begin{frame}[fragile]
% \frametitle{Using a categorical variable as an explanatory variable.}
% 
% <<echo=FALSE>>=
% opar = par(mar=c(5,5,0,4)+.1)
% plot(Lifetime~jitter(I(as.numeric(Diet)-1)), case0501, xaxt='n', pch=19, cex.lab=1.5, 
%      xlab="Diet", col='gray')
% axis(1, seq(0,nlevels(case0501$Diet)-1), levels(case0501$Diet), cex=1.5)
% 
% axis(4, yy[1], expression(beta[0]), las=1, cex.axis=1.5)
% yy = with(case0501, by(Lifetime, Diet, mean))
% abline(h=yy[1], lwd=2)
% segments((0:5)-.3, yy, (0:5)+.3, yy, col='red', lwd=2)
% arrows(1:5,yy[1],1:5,yy[-1],col='red', lwd=4)
% text(1:5, (yy[2:6]+yy[1])/2, expression(beta[1],beta[2],beta[3],beta[4],beta[5]), pos=4, col='red', cex=1.5, offset=1)
% par(opar)
% @
% 
% \end{frame}



\section{Interactions ($X_1X_2$)}
\begin{frame}
\frametitle{Interactions}
Why an interaction? \pause
\begin{quote}
Two explanatory variables are said to \alert{interact} if the effect that one 
of them has on the mean response depends on the value of the other. 
\end{quote}

\pause


For example, 
\begin{itemize}
\item Longnose dace count: The effect of nitrate (no3) on longnose dace count depends on the maxdepth. \pause (Continuous-continuous) \pause
\item Energy expenditure: The effect of mass depends on the species type. \pause (Continuous-categorical) \pause
\item Crop yield: the effect of tillage method depends on the fertilizer brand \pause (Categorical-categorical) \pause
\end{itemize}

\end{frame}



\subsection{Continuous-continuous interaction}
\begin{frame}
\frametitle{Continuous-continuous interaction}

For observation $i$, let 
\begin{itemize}
\item $Y_i$ be the response 
\item $X_{i,1}$ be the first explanatory variable and
\item $X_{i,2}$ be the second explanatory variable. 
\end{itemize}

\vspace{0.2in} \pause

The mean containing only \alert{main effects} is 
\[ \mu_i = \beta_0 + \beta_1X_{i,1}+\beta_2X_{i,2}.\phantom{+\beta_3X_{i,1}X_{i,2}} \]
\pause
The mean with the \alert{interaction} is 
\[ \mu_i = \beta_0 + \beta_1X_{i,1}+\beta_2X_{i,2}+\beta_3X_{i,1}X_{i,2}.  \]

\end{frame}


\begin{frame}
\frametitle{Intepretation - main effects only}

Let $X_{i,1}=x_1$ and $X_{i,2}=x_2$, then we can rewrite the line ($\mu$) as 

\[ \mu = (\beta_0+\beta_2x_2) + \beta_1 x_1 \hspace{2in} \]
which indicates that the intercept of the line for $x_1$ depends on the value of $x_2$. 

\vspace{0.2in} \pause


Similarly,

\[ \mu = (\beta_0+\beta_1x_1) + \beta_2 x_2 \]
which indicates that the intercept of the line for $x_2$ depends on the value of $x_1$.

\end{frame}



\begin{frame}
\frametitle{Intepretation - with an interaction}

Let $X_{i,1}=x_1$ and $X_{i,2}=x_2$, then we can rewrite the mean ($\mu$) as 

\[ \mu = (\beta_0+\beta_2x_2) + (\beta_1+\beta_3x_2) x_1 \]
which indicates that both the intercept and slope for $x_1$ depend on the value of $x_2$. 

\vspace{0.2in} \pause


Similarly,

\[ \mu = (\beta_0+\beta_1x_1) + (\beta_2+\beta_3x_1) x_2 \]
which indicates that both the intercept and slope for $x_2$ depend on the value of $x_1$.

\end{frame}


% \begin{frame}[fragile]
% \frametitle{Visualizing the models}
% 
% <<echo=FALSE>>=
% opar = par(mfrow=c(1,2))
% b = c(1,1,10,1)
% xx = seq(0,1,length=101)*10
% plot(0,0,type='n', xlim=range(xx), ylim=c(0,50), xlab=expression(x[1]), ylab=expression(mu), las=2,
%      main="Main effects only")
% x2s = 0:2
% for (i in seq_along(x2s)) abline(b[1]+b[3]*x2s[i], b[2], col=i, lty=i, lwd=2)
% lgnd = c(bquote(x[2]==.(x2s[1])),
%          bquote(x[2]==.(x2s[2])),
%          bquote(x[2]==.(x2s[3])))
% legend("topleft", as.expression(lgnd), col=1:length(x2s), lty=1:length(x2s))
% 
% plot(0,0,type='n', xlim=range(xx), ylim=c(0,50), xlab=expression(x[1]), ylab=expression(mu), las=2,
%      main="with an interaction")
% for (i in seq_along(x2s)) abline(b[1]+b[3]*x2s[i], b[2]+b[4]*x2s[i], col=i, lty=i, lwd=2)
% par(opar)
% @
% 
% \end{frame}


% \begin{frame}
% \begin{itemize}
% \item $\beta_0$: expected response when explanatory variables are zero
% \item $\beta_1+\beta_3x_2$: expected change in the response for each unit change in $X_{i,1}$ when \alert{$X_{i,2}=x_2$}
% \item $\beta_2+\beta_3x_1$: expected change in the response for each unit change in $X_{i,2}$ when \alert{$X_{i,1}=x_1$}
% \end{itemize}
% 
% \pause 
% 
% Proof:
% \[ \begin{array}{l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l}
% E[Y_i|X_{i,1}=&x_1+1&, X_{i,2}=x_2] &= \beta_0 +&\beta_1 (&x_1+1)&+ \beta_2x_2 &+ \beta_3 (&x_1+1)&x_2 \\
% E[Y_i|X_{i,1}=&x_1&, X_{i,2}=x_2] &= \beta_0 +&\beta_1 & x_1 & + \beta_2 x_2 &+ \beta_3 & x_1 & x_2 \\
% \hline
% \multicolumn{3}{c}{\mbox{Diff}} &= &\beta_1 &&&+  \beta_3 &&x_2
% \end{array} \]
% \pause
% \[ \begin{array}{l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l}
% E[Y_i|X_{i,1}=x_1, X_{i,2}=&x_2+1&] &= \beta_0 +&\beta_1 x_1+ &\beta_2 (&x_2+1) &+ \beta_3 x_1& (&x_2+1) \\
% E[Y_i|X_{i,1}=x_1, X_{i,2}=&x_2&] &= \beta_0 +&\beta_1 x_1  + &\beta_2 &x_2 &+ \beta_3 x_1 & &x_2 \\
% \hline
% \multicolumn{3}{c}{\mbox{Diff}}&= &&\beta_2 &&+  \beta_3 x_1
% \end{array} \]
% \end{frame}


% \begin{frame}
% \frametitle{Intepretation}
% 
% \begin{itemize}
% \item $\beta_0$: expected response when explanatory variables are zero
% \item $\beta_1+\beta_3x_2$: expected change in the response for each unit change in $X_{i,1}$ when \alert{$X_{i,2}=x_2$}
% \item $\beta_2+\beta_3x_1$: expected change in the response for each unit change in $X_{i,2}$ when \alert{$X_{i,1}=x_1$}
% %\item $\beta_3X_{i,2}$: expected change in the effect of $X_{i,1}$ on the response when \alert{$X_{i,2}$ is not zero}
% %\item $\beta_3X_{i,1}$: expected change in the effect of $X_{i,2}$ on the response when \alert{$X_{i,1}$ is not zero}
% \end{itemize}
% 
% \pause 
% 
% Proof:
% \[ \begin{array}{l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l}
% E[Y_i|X_{i,1}=&x_1+1&, X_{i,2}=x_2] &= \beta_0 +&\beta_1 (&x_1+1)&+ \beta_2x_2 &+ \beta_3 (&x_1+1)&x_2 \\
% E[Y_i|X_{i,1}=&x_1&, X_{i,2}=x_2] &= \beta_0 +&\beta_1 & x_1 & + \beta_2 x_2 &+ \beta_3 & x_1 & x_2 \\
% \hline
% \multicolumn{3}{c}{\mbox{Diff}} &= &\beta_1 &&&+  \beta_3 &&x_2
% \end{array} \]
% \pause
% \[ \begin{array}{l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l@{}l}
% E[Y_i|X_{i,1}=x_1, X_{i,2}=&x_2+1&] &= \beta_0 +&\beta_1 x_1+ &\beta_2 (&x_2+1) &+ \beta_3 x_1& (&x_2+1) \\
% E[Y_i|X_{i,1}=x_1, X_{i,2}=&x_2&] &= \beta_0 +&\beta_1 x_1  + &\beta_2 &x_2 &+ \beta_3 x_1 & &x_2 \\
% \hline
% \multicolumn{3}{c}{\mbox{Diff}}&= &&\beta_2 &&+  \beta_3 x_1
% \end{array} \]
% 
% \end{frame}



\begin{frame}[fragile]
\frametitle{R code and output - main effects only}

<<>>=
mM = lm(count ~ no3 + maxdepth, longnosedace)
summary(mM)
@

\end{frame}


\begin{frame}[fragile]
\frametitle{R code and output - with an interaction}

<<>>=
mI = lm(count ~ no3*maxdepth, longnosedace)
summary(mI)
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Visualizing the model}

<<echo=FALSE>>=
newdata = expand.grid(maxdepth = c(26,63,160), no3 = c(0,8))
me = lm(count ~ no3 + maxdepth, data = longnosedace)
int = lm(count ~ no3 * maxdepth, data = longnosedace)

fit = newdata %>% 
  mutate(`Main effects` = predict(me, newdata = newdata),
         `Interaction`  = predict(int, newdata = newdata)) %>%
  tidyr::gather(model,count, `Main effects`, `Interaction`) %>%
  dplyr::mutate(model = factor(model, levels = c("Main effects","Interaction")))


ggplot(fit, aes(x = no3, y = count, color = maxdepth, group = maxdepth)) + 
  geom_line() +
  facet_grid(.~model) + 
  theme_bw()
@

\end{frame}









\subsection{Continuous-categorical interaction}
\begin{frame}
\frametitle{In-flight energy expenditure (Sleuth3::case1002)}

<<>>=
mM <- lm(log(Energy) ~ log(Mass) + Type, case1002)
ggplot(case1002, aes(x = Mass, y = Energy, color = Type, shape = Type)) + 
  geom_point() +
  scale_x_log10() + 
  scale_y_log10() +
  theme_bw() +
  theme(legend.position = "bottom")
@

\end{frame}




\begin{frame}
\frametitle{Continuous-categorical interaction}

Let category A be the reference level. For observation $i$, let 
\begin{itemize}
\item $Y_i$ be the response 
\item $X_{i,1}$ be the continuous explanatory variable, 
\item $B_i$ be a dummy variable for category B, and 
\item $C_i$ be a dummy variable for category C.
\end{itemize}

\vspace{0.2in} \pause

The mean containing only \alert{main effects} is 
\[ \mu_i = \beta_0 + \beta_1 X_{i,1}+\beta_2 B_i+\beta_3 C_i.\phantom{+\beta_4 X_{i,1}B_i+\beta_5 X_{i,1}C_i} \]
\pause
The mean with the \alert{interaction} is 
\[ \mu_i = \beta_0 + \beta_1 X_{i,1}+\beta_2 B_i+\beta_3 C_i+\beta_4 X_{i,1}B_i+\beta_5 X_{i,1}C_i. \]

\end{frame}


\begin{frame}
\frametitle{Interpretation for the main effect model}

The mean containing only \alert{main effects} is 
\[ \mu_i = \beta_0 + \beta_1 X_{i,1}+\beta_2 B_i+\beta_3 C_i.\phantom{+\beta_4 X_{i,1}B_i+\beta_5 X_{i,1}C_i} \]

\vspace{0.2in} \pause

For each category, the line is 
\[ \begin{array}{c|l@{}lll}
\mbox{Category} & \multicolumn{4}{c}{\mbox{Line } (\mu)} \\
\hline
A & &\beta_0 &+ &\beta_1 X \\
B & (&\beta_0 + \beta_2) &+ &\beta_1 X \\
C & (&\beta_0 + \beta_3) &+ &\beta_1 X \\
\hline
\end{array} \]
\pause
Each category has a different intercept, but a common slope.

\end{frame}







\begin{frame}
\frametitle{Interpretation for the model with an interaction}

The model with an \alert{interaction} is 
\[ \mu_i = \beta_0 + \beta_1 X_{i,1}+\beta_2 B_i+\beta_3 C_i+\beta_4 X_{i,1}B_i+\beta_5 X_{i,1}C_i \]

\vspace{0.2in} \pause

For each category, the line is
\[ \begin{array}{c|l@{}ll@{}l@{}l}
\mbox{Category} & \multicolumn{5}{c}{\mbox{Line } (\mu)} \\
\hline
A &  &\beta_0            &+  &\beta_1           &X \\
B & (&\beta_0 + \beta_2) &+ (&\beta_1+\beta_4) &X \\
C & (&\beta_0 + \beta_3) &+ (&\beta_1+\beta_5) &X \\
\hline
\end{array} \]
\pause
Each category has its own intercept and its own slope. 

\end{frame}


% \begin{frame}[fragile]
% \frametitle{Visualizing the models}
% 
% <<echo=FALSE, fig.height=4>>=
% b = c(0,3,7)
% opar = par(mar=c(5,6,4,2)+.1, mfrow=c(1,2))
% 
% plot(0, 0, type='n', xlim=c(0,10), ylim=c(0,15), axes=F, frame=TRUE, 
%      xlab="Continuous explanatory variable", ylab="Expected response",
%      main="Main effects only", xaxs='i')
% for (i in 1:length(b)) abline(b[i],1, col=i, lty=i, lwd=2)
% axis(2, b, expression(beta[0],beta[0]+beta[2],beta[0]+beta[3]), las=1)
% loc=c(1,3,6)
% arrows(loc[1],b[1]+loc[1], loc[1], b[2]+loc[1], code=3, length=0.1)
% text(loc[1], b[2]/2+loc[1], expression(beta[2]), pos=4)
% arrows(loc[2], b[1]+loc[2], loc[2], b[3]+loc[2], code=3, length=0.1)
% text(loc[2], mean(b[c(1,3)])+loc[2]+1, expression(beta[3]), pos=4)
% arrows(loc[3], b[2]+loc[3], loc[3], b[3]+loc[3], code=3, length=0.1)
% text(loc[3], mean(b[2:3])+loc[3], expression(beta[3]-beta[2]), pos=4)
% 
% segments(5, 5, 8, 5)
% segments(8, 5, 8, 8)
% text(8, 6.5, expression(beta[1]), pos=4)
% 
% b0 = c(0, 10, 13)
% b1 = c(1, .5, -0.3)
% plot(0, 0, type='n', xlim=c(0,10), ylim=c(0,15), axes=F, frame=TRUE, 
%      xlab="Continuous explanatory variable", ylab="",
%      main="with an interaction", xaxs='i')
% 
% x1 = 5
% x2 = 8
% i = 1
% for (i in 1:length(b)) {
%   abline(b0[i],b1[i], col=i, lty=i, lwd=2)
%   segments(x1, b0[i]+b1[i]*x1, x2, b0[i]+b1[i]*x1, col=i, lty=i)
%   segments(x2, b0[i]+b1[i]*x1, x2, b0[i]+b1[i]*x2, col=i, lty=i)
% }
% axis(2, b0, expression(beta[0],beta[0]+beta[2],beta[0]+beta[3]), las=1)
% text(8, b0+b1*(x1+x2)/2, expression(beta[1], beta[1]+beta[4], beta[1]+beta[5]), pos=4)
% par(opar)
% @
% 
% \end{frame}




\begin{frame}[fragile]
\frametitle{R code and output - main effects only}

<<echo = TRUE>>=
summary(mM <- lm(log(Energy) ~ log(Mass) + Type, case1002))
@

\end{frame}



\begin{frame}[fragile]
\frametitle{R code and output - with an interaction}

<<echo = TRUE>>=
summary(mI <- lm(log(Energy) ~ log(Mass) * Type, case1002))
@

\end{frame}



\begin{frame}[fragile]
\frametitle{Visualizing the models}

<<echo=FALSE>>=
newdata = expand.grid(Mass = c(1,250), Type = levels(case1002$Type))

fit = newdata %>% 
  mutate(`Main effects` = predict(mM, newdata = newdata),
         `Interaction`  = predict(mI, newdata = newdata)) %>%
  tidyr::gather(model, Energy, `Main effects`, `Interaction`) %>%
  dplyr::mutate(model = factor(model, levels = c("Main effects","Interaction")),
                Energy = exp(Energy)) # not sure why predict doesn't do the exp()


ggplot(fit, aes(x = Mass, y = Energy, color = Type, linetype = Type)) + 
  geom_line() +
  scale_x_log10() + 
  scale_y_log10() +
  facet_grid(.~model) + 
  theme_bw() +  
  theme(legend.position = "bottom")
@

\end{frame}





\subsection{Categorical-categorical interaction}
\begin{frame}
\frametitle{Seaweed regeneration (Sleuth3::case1301 subset)}

<<>>=
case1301_subset = case1301 %>% filter(Block %in% c("B1","B2") & Treat %in% c("L","Lf","LfF"))

ggplot(case1301_subset, aes(x = Treat, y = Cover, 
                            color = Block, shape = Block)) +
  geom_jitter(height = 0, width = 0.05, size = 2) +
  theme_bw() + 
  theme(legend.position = "bottom")
@

\end{frame}





\begin{frame}
\frametitle{Categorical-categorical}

Let category A and type 0 be the reference level. For observation $i$, let 
\begin{itemize}
\item $Y_i$ be the response, 
\item $1_i$ be a dummy variable for type 1, 
\item $B_i$ be a dummy variable for category B, and 
\item $C_i$ be a dummy variable for category C.
\end{itemize}

\vspace{0.2in} \pause

The mean containing only main effects is 
\[ \mu_i = \beta_0 + \beta_1 1_i + \beta_2 B_i + \beta_3 C_i.\phantom{ + \beta_4 1_i B_i + \beta_5 1_i C_i} \]
\pause
The mean with an interaction is 
\[ \mu_i = \beta_0 + \beta_1 1_i + \beta_2 B_i + \beta_3 C_i + \beta_4 1_i B_i + \beta_5 1_i C_i. \]

\end{frame}


% \begin{frame}
% \frametitle{Interpretation for the main effects model}
% The mean containing only main effects is 
% \[ \mu_i = \beta_0 + \beta_1 1_i + \beta_2 B_i + \beta_3 C_i.\phantom{ + \beta_4 1_i B_i + \beta_5 1_i C_i} \]
% 
% \vspace{-0.1in} \pause
% 
% 
% \begin{itemize}
% \item $\beta_0$ is the expected response for category A and type 0
% \item $\beta_1$ is the change in response for moving from type 0 to type 1
% \item $\beta_2$ is the change in response for moving from category A to category B
% \item $\beta_3$ is the change in response for moving from category A to category C
% \end{itemize}
% 
% \end{frame}



\begin{frame}
\frametitle{Interpretation for the main effects model}
The mean containing only main effects is 
\[ \mu_i = \beta_0 + \beta_1 1_i + \beta_2 B_i + \beta_3 C_i.\phantom{ + \beta_4 1_i B_i + \beta_5 1_i C_i} \]

\vspace{-0.1in} \pause


The means in the \alert{main effect model} are 
\[ \begin{array}{c|ccc} 
& \multicolumn{3}{c}{\mbox{Category}} \\
\mbox{Type} & A & B & C \\
\hline
0 & \beta_0 \phantom{{}+\beta_1}\, & \beta_0 \phantom{{}+\beta_1}\,+\beta_2 & \beta_0 \phantom{{}+\beta_1}\,+\beta_3 \\
1 & \beta_0+\beta_1 & \beta_0+\beta_1+\beta_2 & \beta_0+\beta_1+\beta_3 \\
\end{array} \]

\end{frame}




% 
% \begin{frame}
% \frametitle{Interpretation for the model with an interaction}
% 
% \small
% 
% The mean with an interaction is 
% \[ \mu_i = \beta_0 + \beta_1 1_i + \beta_2 B_i + \beta_3 C_i + \beta_4 1_i B_i + \beta_5 1_i C_i. \]
% 
%  \pause
% 
% 
% {\footnotesize
% \begin{itemize}
% \item $\beta_0$ is the expected response for category A and type 0 \pause
% \item $\beta_1$ is the change in response for moving from type 0 to type 1 for category A \pause
% \item $\beta_2$ is the change in response for moving from category A to category B for type 0
% \item $\beta_3$ is the change in response for moving from category A to category C for type 0 \pause
% \item $\beta_4$ is the difference in change in response for moving from category A to category B for type 1 compared to type 0 \pause
% \item $\beta_5$ is the difference in change in response for moving from category A to category C for type 1 compared to type 0
% \end{itemize}
% }
% 
% \end{frame}



\begin{frame}
\frametitle{Interpretation for the model with an interaction}

\small

The mean with an interaction is 
\[ \mu_i = \beta_0 + \beta_1 1_i + \beta_2 B_i + \beta_3 C_i + \beta_4 1_i B_i + \beta_5 1_i C_i. \]

\pause
 
The means are 
\[ \begin{array}{c|lll} 
& \multicolumn{3}{c}{\mbox{Category}} \\
\mbox{Type} & A & B & C \\
\hline
0 & \beta_0 \phantom{{}+\beta_1} 
& \beta_0 \phantom{{}+\beta_1} + \beta_2\phantom{{}+\beta_4} 
& \beta_0 \phantom{{}+\beta_1} + \beta_3\phantom{{}+\beta_5} \\
1 & \beta_0 + \beta_1 
& \beta_0+\beta_1+\beta_2+\beta_4 
& \beta_0+\beta_1+\beta_3+\beta_5 \\
\end{array} \]
\pause
This is equivalent to a \alert{cell-means model} where each combination has its
own mean.

\end{frame}




% \begin{frame}[fragile]
% \frametitle{Visualizing the models}
% 
% <<echo=FALSE>>=
% mus = function(b, cats=c("A","B","C"), types=c(0,1)) {
%   d = data.frame(type=rep(types, each=3),
%                  category = rep(cats, 2))
%   if (length(b) == 4) {
%   d$mu = c(b[1],      b[1]     +b[3], b[1]     +b[4],
%            b[1]+b[2], b[1]+b[2]+b[3], b[1]+b[2]+b[4])
%   } else {
%   d$mu = c(b[1],      b[1]     +b[3],      b[1]     +b[4],
%            b[1]+b[2], b[1]+b[2]+b[3]+b[5], b[1]+b[2]+b[4]+b[6])
%   }
%   d
% }
% opar = par(mfrow=c(1,2))
% d = mus(c(4,2,-5,-3))
% interaction.plot(d$category, d$type, d$mu, type='b', pch=1:2, lty=1:2, legend=FALSE,
%      xlab="Category", ylab=expression(mu), main="Main effect only", trace.label="Type")
% legend("topright",paste("Type=",0:1), lty=1:2, pch=1:2)
% d = mus(c(4,2,-1,-3, 2, -3))
% interaction.plot(d$category, d$type, d$mu, type='b', pch=1:2, lty=1:2, legend=FALSE,
%      xlab="Category", ylab=expression(mu), main="with interaction", trace.label="Type")
% par(opar)
% @
% 
% \end{frame}





\begin{frame}[fragile]
\frametitle{R code and output - main effects only}

<<>>=
summary(mM <- lm(Cover ~ Block + Treat, case1301_subset))
@

\end{frame}


\begin{frame}[fragile]
\frametitle{R code and output - with an interaction}

<<>>=
summary(mI <- lm(Cover ~ Block * Treat, case1301_subset))
@

\end{frame}


\begin{frame}[fragile]
\frametitle{Visualizing the models}

<<echo=FALSE>>=
newdata = case1301_subset %>% select(Block,Treat) %>% unique()

fit = newdata %>% 
  mutate(`Main effects` = predict(mM, newdata = newdata),
         `Interaction`  = predict(mI, newdata = newdata)) %>%
  tidyr::gather(model, Cover, `Main effects`, `Interaction`) %>%
  dplyr::mutate(model = factor(model, levels = c("Main effects","Interaction"))) 


ggplot(fit, aes(x = Treat, y = Cover, 
                color = Block, linetype = Block, group = Block, shape = Block)) + 
  geom_line() +
  geom_point() + 
  facet_grid(.~model) + 
  theme_bw() +  
  theme(legend.position = "bottom")
@

\end{frame}



\begin{frame}
\frametitle{When to include interaction terms}

From The Statistical Sleuth (3rd ed) page 250:
\begin{itemize}
\item when a question of interest pertains to an interaction
\item when good reason exists to suspect an interaction or
\item when interactions are proposed as a more general model for the purpose of examining the goodness of fit of a model without interaction.
\end{itemize}

\end{frame}



\subsection{Summary}
\begin{frame}
\frametitle{Multiple regression explanatory variables}

The possibilities for explanatory variables are 
  \begin{itemize}
  \item Higher order terms ($X^2$)
	\item Additional explanatory variables ($X_1$ and $X_2$)
	\item Dummy variables for categorical variables ($X_1=\I()$)
	\item Interactions ($X_1X_2$)
    \begin{itemize}
    \item Continuous-continuous
    \item Continuous-categorical
    \item Categorical-categorical
    \end{itemize}
	\end{itemize}
  
  \pause
  
  
  We can also combine these explanatory variables, e.g. 
  \begin{itemize}[<+->]
  \item including higher order terms for continuous variables along with dummy variables for categorical variables and 
  \item including higher order interactions ($X_1X_2X_3$). 
  \end{itemize}

\end{frame}

\end{document}



