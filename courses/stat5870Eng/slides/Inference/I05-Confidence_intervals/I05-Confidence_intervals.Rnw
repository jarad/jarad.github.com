\documentclass[aspectratio=169,handout]{beamer}

\usepackage{verbatim,multicol,amsmath}

\input{../../frontmatter}
\input{../../commands}

\title{I05 - Confidence intervals}

% \setbeamertemplate{background}
% {\includegraphics[width=\paperwidth,height=\paperheight,keepaspectratio]{video_overlay}}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=2.5, 
               size='tiny', 
               out.width='\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library("plyr")
library("dplyr")
library("tidyr")
library("ggplot2")
theme_set(theme_bw())
@

<<set_seed, echo=FALSE>>=
set.seed(2)
@

\begin{document}

\begin{frame}[t]
\maketitle
\end{frame}


\section{Exact confidence intervals}
\begin{frame}[t]
\frametitle{Exact confidence intervals}

The \alert{coverage} of an interval estimator is the probability the interval 
will contain the true value of the parameter 
\emph{when the data are considered to be random}.
\pause
If an interval estimator has $100(1-a)\%$ coverage, 
then we call it a $100(1-a)\%$ \alert{confidence interval}
\pause
and $1-a$ is the \alert{confidence level}.

\vspace{0.2in} \pause


That is, we calculate
\[ 1-a = P(L < \theta < U) \]
where $L$ and $U$ are random because they depend on the data.
\pause
Thus \alert{confidence} is a statement about the \alert{procedure}.

\end{frame}


\subsection{Normal mean}
\begin{frame}[t]
\frametitle{Normal model}

\small

If $Y_i \ind N(\mu,\sigma^2)$ and we assume the default prior 
$p(\mu,\sigma^2) \propto 1/\sigma^2$, 
\pause 
then a $100(1-a)\%$ credible interval for $\mu$ 
\pause 
is given by 
\[ 
\overline{y} \pm t_{n-1,a/2}s/\sqrt{n}.
\]
\pause
When the data are considered random
\[ 
T_{\visible<5->{n-1}} = \frac{\overline{Y}-\mu}{S/\sqrt{n}} \sim \pause t_{n-1}(0,1)
\]
\pause

thus the probability $\mu$ is within our credible interval is
\[ \begin{array}{rl}
\multicolumn{2}{l}{P\left( \overline{Y}-t_{n-1,a/2}S/\sqrt{n} < \mu < \overline{Y}+t_{n-1,a/2}S/\sqrt{n}\right)} \pause \\
&= P\left( -t_{n-1,a/2} < \frac{\overline{Y}-\mu}{S/\sqrt{n}} < t_{n-1,a/2}\right) \pause \\
&= P\left( -t_{n-1,a/2} < T_{n-1} < t_{n-1,a/2}\right) \pause \\
&= 1-a.
\end{array} \]
\pause
Thus, this $100(1-a)\%$ credible interval is also a $100(1-a)\%$ confidence interval.

\end{frame}


\subsection{Yield data example}
\begin{frame}[t]
\frametitle{Yield data example}
<<data, echo = FALSE>>=
y <- read.csv("../I04-Normal_model/yield.csv")$yield
@

<<data_example, dependson="data", echo = FALSE>>=
n <- length(y)
ybar <- mean(y)
s <- sd(y)
a <- .05
t_crit <- qt(1-a/2, df = n-1)
L <- ybar - t_crit*s/sqrt(n)
U <- ybar + t_crit*s/sqrt(n)
@

Recall the corn yield example from I04 with $\Sexpr{n}$ randomly selected 
fields in Iowa whose 
sample average yield is $\Sexpr{round(ybar)}$ and sample standard 
deviation is $\Sexpr{round(s)}$. 
\pause
Then a $\Sexpr{100*(1-a)}\%$ confidence interval for the mean corn yield on
Iowa farms is 
\[
\Sexpr{round(ybar)}\pm \Sexpr{round(t_crit,2)}\times \Sexpr{round(s)}/\sqrt{\Sexpr{n}}
= (\Sexpr{round(L)},\Sexpr{round(U)}).
\]
% \pause
% This \alert{confidence interval} tells us nothing about the true mean yield of fields 
% in Iowa.
% \pause
% Instead, it tells us that if we use this \alert{procedure} repeatedly on 
% different data sets, then $\Sexpr{100*(1-a)}\%$ of the time, the interval
% will contain the true parameter.
% \pause
% But because this confidence interval happens to correspond to a 
% \alert{credible interval}, it does tell us what we should \alert{believe} about
% the true mean yield.
\end{frame}



\section{Approximate confidence intervals}
\subsection{Standard error}
\begin{frame}[t]
\frametitle{Standard error}

The \alert{standard error of an estimator} is an \emph{estimate} of the standard deviation
of the estimator (when the data are considered random). 

\vspace{0.1in} \pause

If $Y \sim Bin(n,\theta)$, then 
\[ 
\hat{\theta} = \frac{Y}{n} 
\pause \qquad \mbox{has} \qquad
SE[\hat{\theta}] = \sqrt{\frac{\hat\theta(1-\hat\theta)}{n}}.
\]
\pause
If $Y_i \ind N(\mu,\sigma^2)$, then
\[
\hat\mu = \overline{Y} 
\pause \qquad \mbox{has} \qquad
SE[\hat\mu] = S/\sqrt{n}.
\]

\end{frame}


\subsection{Approximate confidence intervals}
\begin{frame}[t]
\frametitle{Approximate confidence intervals}

\small

If an \alert{unbiased} estimator has an asymptotic normal distribution, 
\pause
then we can construct an \alert{approximate} $100(1-a)$\% confidence interval
for $E[\hat\theta] = \theta$ using 
\[ 
\hat{\theta} \pm z_{a/2} SE[\hat\theta].
\]
where $SE[\hat\theta]$ is the \alert{standard error} of the estimator
\pause
and $P(Z > z_{a/2}) = a/2$.

\vspace{0.1in} \pause


This comes from the fact that if 
$\hat\theta \stackrel{\cdot}{\sim} N(\theta,SE[\hat\theta]^2)$, \pause then
\[ \begin{array}{rl}
\multicolumn{2}{l}{P\left( \hat{\theta} - z_{a/2} SE(\hat\theta) < \theta < \hat\theta + z_{a/2} SE(\hat\theta) \right)} \pause \\
&= P\left( -z_{a/2} < \frac{\hat\theta-\theta}{SE(\hat\theta)} < z_{a/2} \right) \pause \\
% &= P\left( -z_{a/2} < \frac{\hat\theta-\theta}{\sqrt{Var[\hat\theta]}} < z_{a/2} \right) \pause \\
&\approx P\left( -z_{a/2} < Z < z_{a/2} \right) \pause \\
&= 1-a.
\end{array} \]



\end{frame}



\subsection{Normal mean}
\begin{frame}[t]
\frametitle{Normal example}

If $Y_i \ind N(\mu,\sigma^2)$ and we have the estimator
$\hat\mu = \overline{Y}$, then
\[
E[\hat\mu] = \mu
\qquad \mbox{and} \qquad
SE[\hat\mu] = S/\sqrt{n}
\]

\pause

Thus an \alert{approximate} $100(1-a)$\% confidence interval
for $\mu=E[\hat\mu]$ is
\[
\hat\mu \pm z_{a/2} SE[\hat\mu] = \overline{Y} \pm z_{a/2} S/\sqrt{n}.
\]
\pause

Note that this is almost identical to the \alert{exact} $100(1-a)$\%
confidence interval for $\mu$,
\[
\phantom{\hat\mu \pm z_{a/2} SE[\hat\mu] = }\quad\overline{Y} \pm t_{n-1,a/2} S/\sqrt{n}
\]
\pause
and when $n$ is large $z_{a/2} \approx t_{n-1,a/2}$.

\end{frame}



\subsection{Critical values}
\begin{frame}[t]
\frametitle{T critical values vs Z critical values}

<<critical_values_comparison>>=
d <- expand.grid(n = 10^(1:3), a = 1-c(.9,.95,.99)) %>%
  group_by(n, a) %>%
  mutate(z_crit = qnorm(1-a/2),
         t_crit = qt(   1-a/2, df=n-1)) %>%
  ungroup() %>%
  mutate(n = as.factor(n))

ggplot(d, aes(z_crit, t_crit, group=n, linetype=n, color=n)) +
  geom_line() +
  geom_abline(intercept = 0, slope = 1, color='gray') +
  # coord_fixed() +
  labs(x = "z critical values", y = "t critical values") 
@

\end{frame}




\subsection{Binomial proportion}
\begin{frame}[t]
\frametitle{Approximate confidence interval for binomial proportion}

\scriptsize

If $Y\sim Bin(n,\theta)$, then an \alert{approximate} $100(1-a)$\% confidence
interval for $\theta$ is
\[
\hat\theta \pm z_{a/2} \sqrt{\frac{\hat\theta (1-\hat\theta)}{n}}.
\]
\pause
where $\hat\theta = Y/n$ \pause
since

\[ E[\hat\theta] = E\left[ \frac{Y}{n} \right] = \theta \]
\pause
and 
\[ 
SE[\hat\theta] = \sqrt{\frac{\hat\theta(1-\hat\theta)}{n}}.
\]

\end{frame}


\subsection{Gallup poll example}
\begin{frame}[t]
\frametitle{Gallup poll example}

In a Gallup poll dated 2017/02/19, 32.1\% of respondents of the 1,500 randomly 
selected U.S. adults indicated that they were ``engaged at work''.
\pause
Thus an approximate 95\% confidence interval for the proportion of all U.S.
adults is
\[
0.321 \pm 1.96 \times \sqrt{\frac{.321(1-.321)}{1500}} \pause = (0.30, 0.34).
\]
\end{frame}



\section{Summary}
\begin{frame}[t]
\frametitle{Confidence interval summary}

\small

\[ \begin{array}{lclll}
\mbox{Model} & \mbox{Parameter} & \mbox{Estimator} & \mbox{Confidence Interval} & \mbox{Type} \pause \\
\hline
Y_i \ind N(\mu,\sigma^2) & \mu & \hat\mu=\overline{y} & \hat\mu \pm t_{n-1,a/2}s/\sqrt{n} & \mbox{exact} \pause \\
Y_i \ind N(\mu,\sigma^2) &\mu & \hat\mu=\overline{y} & \hat\mu \pm \quad\,\,\,\, z_{a/2}s/\sqrt{n} & \mbox{approximate} \pause \\
Y \sim Bin(n,\theta) & \theta & \hat\theta=y/n & \hat{\theta} \pm z_{a/2} \sqrt{\hat\theta(1-\hat\theta)/n} & \mbox{approximate} \pause \\
Y_i \ind Ber(\theta) & \theta & \hat\theta=\overline{y} & \hat{\theta} \pm z_{a/2} \sqrt{\hat\theta(1-\hat\theta)/n} & \mbox{approximate} \\
\hline
\end{array} \]

\vspace{0.1in} \pause

The Bayesian credible intervals we discuss provide approximate confidence intervals. For example, for binomial data the following is an approximate confidence interval:

<<binomial-credible-interval, eval=FALSE, echo=TRUE>>=
qbeta(c(a/2, 1-a/2), 1 + y, 1 + n - y)
@

\vspace{0.1in} \pause

\alert{Approximate} means that the coverage will get
closer to the desired probability,
i.e. $100(1-a)$\%, as the sample size gets larger.

\end{frame}

\end{document}



