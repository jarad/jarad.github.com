\documentclass[aspectratio=169,handout]{beamer}

\input{../../frontmatter}
\input{../../commands}

\title{P5 - Multiple random variables}

% \setbeamertemplate{background}
% {\includegraphics[width=\paperwidth,height=\paperheight,keepaspectratio]{video_overlay}}

\begin{document}

<<options, results='hide', echo=FALSE, purl=FALSE>>=
opts_chunk$set(comment=NA, 
               fig.width=6, fig.height=4.4, 
               size='tiny', 
               out.width='0.8\\textwidth', 
               fig.align='center', 
               message=FALSE,
               echo=FALSE,
               cache=TRUE)
options(width=120)
@

<<libraries, message=FALSE, warning=FALSE, cache=FALSE>>=
library("dplyr")
library("ggplot2")
library("tidyr")
@

<<set_seed>>=
set.seed(2)
@

\frame{\maketitle}

\section{Multiple random variables}
\subsection{Discrete random variables}
\begin{frame}[t]
\frametitle{Multiple discrete random variables}

If $X$ and $Y$ are two discrete variables, \pause
their \alert{joint probability mass function} is defined as
\[
p_{X,Y}(x,y) = P( X = x \cap Y = y) \pause = P( X = x, Y = y) . 
\]
% If $X\in \mathbb{R}^n$ is a discrete random vector. 
% Its \alert{joint probability mass function} is defined as 
% \[ 
% p_X(x) = P(X=x) = P(X_1=x_1, X_2=x_2, \ldots, X_n=x_n).
% \]
\end{frame}



\begin{frame}[t]
\frametitle{CPU example}
A box contains 5 PowerPC G4 processors of different speeds:
\begin{center}
\begin{tabular}{cc}
\# & speed\\
\hline
2 & 400 mHz \\
1 & 450 mHz \\
2 & 500 mHz
\end{tabular}
\end{center}
\pause
Randomly select two processors out of the box (without replacement) 
\pause 
and let
\begin{itemize}
\item $X$ be speed of the first selected processor \pause and 
\item $Y$ be speed of the second selected processor.
\end{itemize}
\end{frame}


\begin{frame}[t]
\frametitle{CPU example - outcomes}

\begin{tabular}{l|lccccc}
	&	\multicolumn{5}{c}{1st processor ($X$)}\\
&	$\Omega$ & $400_{1}$ & $400_{2}$ & $450$ & $500_{1}$ & $500_{2}$
\\ \hline
&	$400_{1} $ & - & x & x & x & x  \\
&	$400_{2} $ & x & - & x & x & x  \\
	2nd processor ($Y$) &	$450$ & x & x & - & x & x  \\
&	$500_{1}$ &   x & x & x & - & x \\
&	$500_{2}$ & x & x & x & x & -
\end{tabular}

\vspace{0.1in} \pause

Reasonable to believe each outcome is equally probable.
\end{frame}

\begin{frame}[t]
\frametitle{CPU example - joint pmf}

Joint probability mass function for $X$ and $Y$:
\begin{center}
\begin{tabular}{ll|ccc}
& & \multicolumn{3}{c}{1st processor ($X$)} \\
 & mHz  & 400 & 450 & 500  \\ \hline
&  400 & 2/20 & 2/20 & 4/20 \\
2nd processor ($Y$) & 450 & 2/20 & 0/20 & 2/20 \\
&  500  & 4/20 & 2/20 & 2/20
\end{tabular}
\end{center}

\vspace{0.1in} \pause

\bc
\begin{itemize}
\item What is $P(X=Y)$? \pause
\item What is $P(X>Y)$?
\end{itemize}
\nc\ec

\end{frame}





\begin{frame}[t]
\frametitle{CPU example - probabilities}

\bc
What is the probability that $X=Y$?

\vspace{0.1in} \pause

\[ \begin{array}{rl}
\multicolumn{2}{l}{P(X=Y)} \pause \\
&= p_{X,Y}(400,400) + p_{X,Y}(450, 450) + p_{X,Y}(500,500) \pause \\
&= 2/20+0/20+2/20 \pause = 4/20 \pause = 0.2
\end{array} \]

\vspace{0.1in} \pause

What is the probability that $X>Y$?

\vspace{0.1in} \pause

\[ \begin{array}{rl}
\multicolumn{2}{l}{P(X>Y)} \\
&= p_{X,Y}(450,400) + p_{X,Y}(500, 400)+ p_{X,Y}(500, 450) \pause \\
&= 2/20+4/20+2/20 = 8/20  = 0.4
\end{array} \]
\nc\ec
\end{frame}






\subsection{Expectations}
\begin{frame}[t]
\frametitle{Expectation}

The \alert{expected value} of a function $h(x,y)$ is 
\[ 
E[h(X,Y)] = \sum_{x,y} h(x,y) \, p_{X,Y}(x,y).
\]

\end{frame}



\begin{frame}[t]
\frametitle{CPU example - expected absolute speed difference}

What is $E[|X-Y|]$?

\vspace{0.1in} \pause

Here, we have the situation $E[|X-Y|] = E[h(X,Y)]$, 
\pause with $h(X,Y) = |X - Y|$. \pause
Thus, we have 
\[ \begin{array}{rc@{}l}
	\multicolumn{3}{l}{E[|X-Y|]} \pause \\  
	&=& \sum_{x,y} |x-y| \, p_{X,Y}(x,y) = \pause \\ \\
	&=& |400 - 400| \cdot 0.1 + |400 - 450| \cdot 0.1 + |400 - 500| \cdot
	0.2 \pause \\
	&&+ |450 - 400| \cdot 0.1 + |450 - 450| \cdot 0.0 + |450 - 500| \cdot
	0.1 \pause \\
	&&+ |500 - 400| \cdot 0.2 + |500 - 450| \cdot 0.1 +  |500 - 500| \cdot
	0.1 \pause \\ \\
	&=& 0 + 5 + 20 + 5 + 0 + 5 + 20 + 5 + 0 \pause = 60.
\end{array} \hspace{2in} \]

\end{frame}


\subsection{Marginal distribution}
\begin{frame}[t]
\frametitle{Marginal distribution}

For discrete random variables $X$ and $Y$, 
\pause
the \alert{marginal probability mass functions} are 
\[ \begin{array}{rl}
p_X(x) &= \sum_y p_{X,Y}(x,y) \pause \qquad \mbox{and} \\
p_Y(y) &= \sum_x p_{X,Y}(x,y) \\
\end{array} \]
\pause

\end{frame}


\begin{frame}[t]
\frametitle{Marginal distribution}

\small

Joint probability mass function for $X$ and $Y$:
\begin{center}
\begin{tabular}{ll|ccc}
& & \multicolumn{3}{c}{1st processor ($X$)} \\
 & mHz  & 400 & 450 & 500  \\ \hline
&  400 & 2/20 & 2/20 & 4/20 \\
2nd processor ($Y$) & 450 & 2/20 & 0/20 & 2/20 \\
&  500  & 4/20 & 2/20 & 2/20
\end{tabular}
\end{center}

\vspace{0.1in} \pause

\bc
{\small
Summing the rows within each column provides  
    \[
    \begin{array}{c||ccc}
	x & 400 & 450 & 500  \\ \hline
	p_{X}(x) & 0.4 & 0.2 & 0.4 \\
    \end{array} \]
    
    \pause
    
Summing the columns within each row provides
    \[ 
    \begin{array}{c||ccc}
	y & 400 & 450 & 500 \\ \hline
	p_{Y}(y) & 0.4 & 0.2 & 0.4 \\
    \end{array}
    \]
}
\nc\ec
\end{frame}



\subsection{Independence}
\begin{frame}[t]
\frametitle{CPU example - independence} 

Are $X$ and $Y$ independent? 


\vspace{0.2in} \pause

$X$ and $Y$ are \alert{independent} if 
$p_{x,y}(x,y) = p_X(x)p_Y(y)$ for all $x$ and $y$. \pause

\vspace{0.1in} \pause

Since 
\[ 
p_{X,Y}(450,450) = 0 \pause \neq 0.2 \cdot 0.2 = p_{X}(450) \cdot p_{Y}(450) \pause
\]
they are {\bf not} independent. 

\end{frame}


\subsection{Covariance}
\begin{frame}[t]
\frametitle{Covariance}

The \alert{covariance} between two random variables $X$ and $Y$ is
\[ Cov[X,Y] = E[ (X-\mu_X) (Y-\mu_Y) ]\]
\pause
where
\[ \mu_X = E[X] \qquad \mbox{and} \qquad \mu_Y = E[X]. \]

\vspace{0.2in} \pause

\bc
If $Y = X$ in the above definition, then $Cov[X,X] = Var[X]$.
\nc\ec
\end{frame}


\begin{frame}[t]
\frametitle{CPU example - covariance}
Use marginal pmfs to compute:
\[ E[X] = E[Y] = 450 \qquad \mbox{and} \qquad Var[X] = Var[Y] = 2000. \]

\pause

\bc
The covariance between $X$ and $Y$ is:
{\small
\[ \begin{array}{rcl}
\multicolumn{3}{l}{Cov[X,Y]} \\
&=& \sum_{x,y} (x-E[X])(y-E[Y]) p_{X,Y}(x,y) = \pause \\ \\
&=& (400 - 450)(400-450) \cdot 0.1 \\
&&+ (450 - 450)(400-450) \cdot 0.1 \\
&&+\cdots \\
&&+   (500-450)(500-450) \cdot 0.1 \pause \\ \\
&=& 250 + 0 - 500 + 0 + 0 + 0 -500 + 250 + 0 \pause \\
&=& -500.
\end{array} \]
}
\nc\ec
\end{frame}


\subsection{Correlation}
\begin{frame}[t]
\frametitle{Correlation}

The \alert{correlation} between two variables $X$ and $Y$ is
\[ 
\rho[X,Y] = \frac{Cov[X,Y]}{\sqrt{Var[X] \cdot Var[Y]}} \pause 
= \frac{Cov[X,Y]}{SD[X] \cdot SD[Y]}.
\]
\end{frame}

\begin{frame}[t]
\frametitle{Correlation properties}

\begin{itemize}
\item $\rho$ is between -1 and 1 \pause
\item if $\rho$ = 1 or -1, $Y$ is  a linear function of $X$: \pause 
  \begin{itemize}
  \item $\rho = \phantom{-}1 \implies Y = mX + b$ with $m > 0$, \pause 
	\item $\rho = -1 \implies Y = mX + b$ with $m < 0$, \pause
  \end{itemize}
\item $\rho$ is a measure of linear association between $X$ and $Y$ \pause
  \begin{itemize}
  \item $\rho$ near $\pm 1$ indicates a strong linear relationship, \pause 
  \item $\rho$ near 0 indicates a lack of linear association.
  \end{itemize}
\end{itemize}
\end{frame}


\begin{frame}[t]
\frametitle{CPU example - correlation}

Recall
\[ Cov[X,Y] = -500 \qquad \mbox{and} \qquad Var[X] = Var[Y] = 2000. \]

\pause

\bc
The correlation is 
    \[
    \rho[X,Y] = \frac{Cov[X,Y]}{\sqrt{Var[X]\cdot Var[Y]}} =
    \frac{-500}{\sqrt{2000\cdot 2000}} = -0.25,
    \]
    \pause
and thus there is a weak negative (linear) association.
\nc\ec
\end{frame}






\subsection{Continuous random variables}
\begin{frame}[t]
\frametitle{Continuous random variables}

Suppose $X$ and $Y$ are two continuous random variables with 
\alert{joint probability density function} $p_{X,Y}(x,y)$. \pause
Probabilities are calculated by integrating this function. \pause
For example,
\[ P(a<X<b, c<Y<d) \pause = \int_c^d \int_a^b p_{X,Y}(x,y) \, dx \, dy. \]


\vspace{0.1in} \pause 

Then the \alert{marginal probability density functions} are 
\[ \begin{array}{rl}
p_X(x) &= \int p_{X,Y}(x,y) \, dy \\
p_Y(y) &= \int p_{X,Y}(x,y) \, dx.
\end{array} \hspace{2in} \]

\end{frame}


\begin{frame}[t]
\frametitle{Continuous random variables}

Two continuous random variables are \alert{independent} if 
\[ 
p_{X,Y}(x,y) = p_X(x)\, p_Y(y).
\]
\pause
The expected value is 
\[ 
E[h(X,Y)] = \int \int h(x,y) \, p_{X,Y}(x,y) \, dx \, dy.
\]
\end{frame}


\subsection{Properties of variances and covariances}
\begin{frame}[t]
\frametitle{Properties of variances and covariances}

For any random variables $X$, $Y$, $W$ and $Z$,
\[ \begin{array}{rl}
Var[aX+bY+c] &= a^2 Var[X] + b^2 Var[Y] + 2ab Cov[X,Y] \pause \\ \\
Cov[aX+bY,cZ+dW] &= acCov[X,Z] + adCov[X,W] \\
&\,+ bc Cov[Y,Z] + bd Cov[Y,W] \pause \\ \\
Cov[X,Y] &= Cov[Y,X] \\
\rho[X,Y] &= \rho[Y,X]
\end{array} \]

\pause

\bc
If $X$ and $Y$ are independent, then 
\[ \begin{array}{rl}
Cov[X,Y] &= 0 \\
Var[aX+bY+c] &= a^2Var[X] + b^2Var[Y].
\end{array} \]
\nc\ec
\end{frame}


\begin{frame}[t]
\frametitle{Summary}
\begin{itemize}
\item Multiple random variables
  \begin{itemize}
  \item joint probability mass function
  \item marginal probability mass function \pause 
  \item joint probability density function
  \item marginal probability density function \pause
  \item expected value \pause 
  \item covariance
  \item correlation 
  \end{itemize}
\end{itemize}
\end{frame}


\end{document}
